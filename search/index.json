[{"content":" 本文只是对 wubi-symbols 项目的引用，也可以直接去看该项目。\n这是什么 虽然在Fcitx5中可以使用 Ctrl+Shift+Alt+U 来调出Unicode特殊字符输入，但对多数人来说，这仍然不太方便，因此有了本项目。\n本项目利用 参考 一节列出的三个网址提供的信息，把常见的包括Emoji在内的特殊符号和词组关联起来，然后将词组转换为五笔编码，同时将其对应的特殊符号也转换为对应的五笔编码，实现简单快捷高效的用五笔打出特殊符号。\n示例 比如在 symbold/emoji.tsv 中定义了这样一行数据：\n1 U+1F923\t🤣\t笑得满地打滚 笑脸 打滚 地板 大笑 打滚儿 笑出眼泪 笑哭 笑哭了 笑得打滚 笑得打滚儿 笑得满地打滚儿 那么我们可能以五笔词组的方式打出上述任意一个词组，都将可以看到 🤣 这个Emoji符号，比如在五笔98版中：\n旗帜及其他的表情也可以：\n当然，除了Emoji，其实还有大量的符号，比如我们想要直接打出乘号、除号及一些其他特殊符号等等，仍然以五笔98版举例：\n注意事项 自动生成的五笔码是按照五笔规则的最长最完整的键码，如果有些符号对应的词组的五笔码不足4码，你如果想打出来，需要尽可能的按照五笔组字规则打到最长最完整。有时候需要打到补码为止；有的要按照五笔规则补到4位，比如 一 的完整五笔码为 ggll，完整打出 ggll 才会显示和 一 相关联的特殊字符。 部分特殊符号还与英文相关联了，这时只要打出英文即可（超过4位的只打前4位，只有1个键将其重复到4个键，只有2个键的也需要再重复一次到共4个键，如果原本就有三个字母的则不作调整），详细的你可以浏览 symbols 下面的每个文件。 如果上一条规则中关联的英文中含有字母 z，则用 x 代替，比如示例图中的 ㎑ 关联的是 khx。 如何使用 以Fcitx5为例。\n1. 下载特殊符号库 下载 output 下面的文件，或者直接从 release 中下载后解压，对应关系如下：\nwb86.txt: 对应五笔86版 wb98.txt: 对应五笔98版 wbnewage.txt: 对应五笔新世纪版 2. 备份原有自造词 备份原有自造词（不同五笔版本的用户词库有不同的名字）：\n1 libime_tabledict -d -u ~/.local/share/fcitx5/table/\u0026lt;你的词库名\u0026gt;.user.dict ime-dump.txt 3. 合并词库 针对之前有导入过个人词库的情况：如果你要保留Fcitx5自动造的词，那么则将从本仓库下载的词库内容粘贴到 ime-dump.txt 中 [Auto] 这一行之前；如果不保留Fcitx5自动造的词，那么就将 ime-dump.txt 中 [Auto] 之后的内容删除后，将从本仓库下载的词库内容粘贴到 ime-dump.txt 后面。\n4. 导入词库 退出Fcitx5，然后将合并后的词库导入用户词库：\n1 libime_tabledict -u ime-dump.txt ~/.local/share/fcitx5/table/\u0026lt;你的词库名\u0026gt;.user.dict 然后再重启Fcitx5即可使用。\n自己生成 如果觉得特殊符号太多了，可以自己自己将 symbols 下面的文件按照 如何贡献 中列出的数据规则调整后，自己生成，在仓库中运行以下脚本即可：\n需要安装 imewlconverter 和 dos2unix。\n1 ./convert.sh 如何贡献 本仓库内容并不包含全部的特殊字符，如果你希望添加，可以向本仓库PR，提交到 symbols 文件夹即可。数据规则：\n每个 tsv 文件分为3列，每列间以制表符分隔； 第1列为该特殊字符的Unicode编码，此列在生成五笔编码时并不起作用，只是为了区分相近的符号用的； 第2列为该特殊字符本身； 第3列为要与该字符关联的词组，多个词组之间使用半角空格分开，如果想直接与英文字母相关联，则直接输入英文字母，限定3位或4位，过少的重复字母到4位，如出现 z 则用 x 代替。 参考 emojiall fcitx5-chinese-addons symbl ","date":"2024-08-02T00:00:00+08:00","image":"https://evine.win/p/use-wubi-type-special-symbols/assets/image-003_hu13229666221149258413.png","permalink":"https://evine.win/p/use-wubi-type-special-symbols/","title":"Linux下简单快捷高效的用五笔打出特殊符号（含Emoji）"},{"content":"申明 转载需注明本文链接及作者。\n前言 玩PT的能自动化的就得自动化，顾名思义，看本文标题就知道：通过浏览器插件Automa自动向IYUUPlus更新PT站的Cookie信息。IYUUPlus的用户应该知道，有部分站点需要提供Cookie才可以正常辅种，而我们又基本都会在同一个浏览器中既登陆相应的PT站，又会登陆IYUUPlus管理页面。那么我们就可以借助浏览器的一款叫Automa的插件，来完成自动提取浏览器中已经登陆的PT站的Cookie，然后按一定格式要求整理后，通过IYUUPlus的接口自动提交Cookie，以减少用户手工填写的烦恼。\n前提条件 你得自己会抓Cookie查看信息，后面会需要用到。\n使用的浏览器是Firefox、Chrome、Edge或其他任何Chromium内核并可以从Chrome扩展商店安装插件的浏览器。\nIYUUPlus是使用的大卫2024年4月才提交的最新版的iyuuplus-dev，也就是这个仓库：https://github.com/ledccn/iyuuplus-dev。旧的仓库（https://github.com/ledccn/IYUUPlus）当然也可以实现自动化，只是不能直接使用本文提供的我编制好的工作流（需要进行一定的修改才能用）。\n实现流程 安装Automa 详见：https://automa.wiki。Edge和其他任何Chromium内核的浏览器也从Chrome扩展商店安装。安装好后可以在Automa的设置中修改语言为中文。\n导入工作流 方式1（推荐）：直接在Automa市场的这个链接点击“Add to extension”即可：https://www.automa.site/workflow/Hnu6QkG7-uewIAlKIFCsF。通过此方式导入的工作流可以跟随我更新。\n方式2：下载我设计好的工作流模板（点我下载）,如果无法下载，可直接前往我的仓库：devome/files 来自己复制粘贴。打开Automa主面板，选择“新建工作流”旁边下拉菜单里面的“导入工作流”，将刚下载好的json文件导入。\n通过以上两种方式任何一种导入时，Automa都会弹出权限需求，直接授予权限即可，如下图所示。\n导入的工作流如下图所示，每一个工作节点你都可以点击编辑按钮来查看详细信息和设置情况。\n创建全局表格 点击“存储 -\u0026gt; 表格 -\u0026gt; 添加表格”，创建一个名为 cookie 的表格，然后给该表添加一列 content，数据类型为 Text，如下图所示。\n创建全局变量 点击“存储 -\u0026gt; 变量 -\u0026gt; 添加变量”，创建以下两个变量。\niyuuplus_url 其值为你的iyuuplus的访问网址，比如：http://iyuuplus.com:8787。\nsites 其值的形式见下方代码块。这些内容就是IYUUPlus中需要提供Cookie的PT站的一些必要的信息，你有多少个PT站需要提供就输入多少个。编辑好后请在 https://www.json.cn 验证一下你输入的内容是否满足json的格式要求。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [ { \u0026#34;id\u0026#34;: \u0026#34;3\u0026#34;, \u0026#34;site\u0026#34;: \u0026#34;m-team\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://xxxx.com\u0026#34;, \u0026#34;key_content\u0026#34;: \u0026#34;auth\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;4\u0026#34;, \u0026#34;site\u0026#34;: \u0026#34;hdsky\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://yyyy.com\u0026#34;, \u0026#34;key_content\u0026#34;: \u0026#34;c_secure_uid\u0026#34; } ] 各字段的含义如下。\nid: IYUUPlus站点信息中的主键，注意不是站点ID。\nsite: IYUUPlus站点信息中的站点名称。\nurl: 对应的PT站的网址，注意不要带有子路径，对于有多个CDN地址的，只能输入你所使用的那一个地址。\nkey_content: 工作流用来辅助判断抓取到的Cookie是不是登陆后的Cookie的一个字段，如果这个字段存在，那么工作流会认为该PT站已经是登陆成功的状态。你可以在登陆前和登陆后分别用浏览器开发工具抓取一下Cookie，对比一下他们的不同点，然后找一个只有登陆后才有的字段（只能一个），将该字段的名称填到这里。工作流运行时，如果抓取到Cookie不存在所提供的字段，会发出没有登陆的通知提示（这时也不会向IYUUPlus提交该PT站的Cookie）。\n添加的两个全局变量最终的状态是这个样子的。\n关连表格 如下图所示，将上一步添加的表格与工作流关联起来。\n下面是关联好之后的状态。\n运行 通过上述设置，已经可以运行这个工作流了，你可以点击“执行”按钮，然后看看结果，也可以直接去IYUUPlus的管理后台中看看Cookie是否成功更新了。我设置的触发器见下图，你也可以根据你的需要自己再添加其他触发器。如果失败了，请在“日志”中查看具体的错误信息来排故。如果需要询问，需要将工作流、执行日志，以及全局表格和全局变量发给我（注意对隐私信息打码），当然，由于工作流信息实在太多了，我并不一定能保证排查出来。\n我设置了在没有登陆好PT站以及IYUUPlus时，会向系统发送通知，请注意留意相关提示信息。\n某些用户可能存在的问题 如果在准备工作做好以前就点击过“运行”，可能会让3个“插入数据”工作节点的表格关联信息丢失，这时，你需要编辑这3个“插入数据”工作节点，手动将要插入的数据和要插入的列关联起来，如下图所示。 依靠Cookie存在的字段来检测PT站点是否已经登陆，这个判断无法完全保证准确，尤其是那些开启了二次验证的站点。所以用户不应该完全依靠此提示而完全不管到底登陆没登陆。\n用户需要在已经登陆了IYUUPlus和需要Cookie的网站的前提下，才能完成提交动作。\n一些说明 如需理解工作流，请编辑各个工作节点，我在里面都写了注释。同时，也请访问 Automa官方文档 查阅更多信息。\n如果教程中有未提及但又需要注意的点，请在下方评论指出。\n你可以在Automa的设置中备份/同步工作流到自己的账号中，这样可以跨设备同步工作流。\n理论上其他需要提供Cookie的使用场景，比如MoviePilot之类的，也可以用Automa实现，欢迎分享你的工作流。\n","date":"2024-04-26T00:00:00+08:00","image":"https://evine.win/p/auto-update-pt-cookies-in-iyuuplus/pic2_hu1142710454545891375.png","permalink":"https://evine.win/p/auto-update-pt-cookies-in-iyuuplus/","title":"通过浏览器插件Automa自动向IYUUPlus更新PT站的Cookie信息"},{"content":"前言 Proxmox Backup Server （简称PBS）作为一个备份服务器，体验还是不错的，它除了备份PVE的虚拟机外，备份系统重要文件体验也是相当不错：backup-client，现在，我使用它的场景几乎都是备份重要文件，无论内网还是公网，备份起来都非常方便。\n官方当然推荐的方式是独立的物理机了，个人使用在资源有限的前提下使用虚拟机也没有问题，甚至有人把它改造成Docker容器了：ayufan/proxmox-backup-server。不过，在个人使用的前提下，这些使用方式都有其缺点：\n物理机，没有独立的物理机给它造。\n虚拟机，太浪费内存资源，内存资源紧张，能不用虚拟机就不用。\nDocker容器，更新可能会比官方慢很久，并且功能不完整，比如查看PBS系统日志，比如自动续签SSL证书等等，还有就是镜像一更新就要往磁盘写入几百M甚至几G的数据，对SSD不友好。\nLXC容器，配置麻烦，想要直接访问宿主上的磁盘要么麻烦，要么性能下降得厉害。\n还有一种形式，直接在现有NAS系统中安装proxmox-backup-server，但这需要NAS系统是Debian或基于Debian，不过会产生一个新的问题，系统隔离性不好。\n那么有没有一种方式，能规避掉这些缺点呢，有的，那就是 Systemd Container。关于它的详细介绍，见 Arch Wiki 上的 Systemd-nspawn，一些常用命令，以及常见问题该链接中都有，本文没有提及的内容请参考该链接。\nsystemd-nspawn 跟 chroot 命令类似，是个终极版的 chroot。systemd-nspawn 可以在轻量的命名空间容器中运行命令或系统。它比 chroot 强大的地方是，它完全虚拟了文件系统层次结构、进程树、各种 IPC 子系统以及主机名。systemd-nspawn 将容器中各种内核接口的访问限制为只读，像是 /sys, /proc/sys 和 /sys/fs/selinux。网络接口和系统时钟不能从容器内更改，不能创建设备节点。不能从容器中重启宿主机，也不能加载内核模块。相比 LXC 或 Libvirt， systemd-nspawn 更容易配置。\n安装 以下均为 root 用户运行的。\n基础环境 对于 Debian 和基于 Debian 的系统，需要安装 systemd-container 以及 debootstrap：\n1 apt install debootstrap systemd-container 对于 Arch Linux 和基于 Arch Linux 的系统，系统默认安装的 systemd 已经包含了 systemd-container，只需要安装 debootstrap 和 debian-archive-keyring：\n1 pacman -S debootstrap debian-archive-keyring 安装 Debian Base Proxmox Backup Server 基于 Debian，在安装 Proxmox Backup Server 前需要先安装 Debian Base，以本文成文时的 Debian 最新稳定版 bookworm 为例：\n1 2 cd /var/lib/machines debootstrap --include=dbus-broker,systemd-container --components=main bookworm pbs https://deb.debian.org/debian 其中 https://deb.debian.org/debian 可以替换为国内镜像站点（国内高校开源镜像站汇总）。dbus-broker 和 systemd-container 是必须安装的，在 Systemd-nspawn 中有解释。\n配置密码 1 2 3 4 cd /var/lib/machines systemd-nspawn -D ./pbs passwd logout 配置macvlan网卡 还是建议 Proxmox Backup Server 使用和宿主机不一样的 IP，这可以使用MacVLAN来实现，在宿主机上为pbs配置：\n1 2 mkdir -p /etc/systemd/nspawn nano /etc/systemd/nspawn/pbs.nspawn 然后输入以下内容：\n1 2 3 4 5 6 7 8 9 10 11 [Exec] Hostname=pbs [Network] ## eth0是指基于宿主机上的eth0创建MacVLAN网卡，需要修改为自己的，比如 vmbr0, ens18, eno1等等 MACVLAN=eth0 [Files] PrivateUsersChown=yes ## Proxmox Backup Server的备份数据存放位置，类似于Docker的映射，冒号左边是宿主机的路径，右边是容器内的路径，如果之前用过Docker，可以直接用的之前配置的路径 Bind=/mnt/data:/mnt/data 启动 1 2 machinectl start pbs # 启动pbs machinectl shell root@pbs # 进入pbs 配置网络 因为我们使用以MacVLAN网络，所以要单独地为容器配置网络，进入容器后创建并编辑 /etc/network/interfaces.d/macvlan，内容如下，其中的 mv-eth0 是容器中的MacVLAN虚拟网卡名，可以通过输入命令 ip a 查看到。\n1 2 3 auto mv-eth0 iface mv-eth0 inet dhcp iface mv-eth0 inet6 dhcp 这是按照DHCP的方式来配置的，你也可以按照自己的习惯设置为固定IP。\n然后重启网络：\n1 2 systemctl enable --now networking.service systemctl restart networking.service 如果后面仍然无法访问网络，则还需要设置DNS服务器，编辑 /etc/resolv.conf，设置nameserver如下面的形式，你可以改为你所使用的DNS服务器。\n1 nameserver 223.5.5.5 安装 Proxmox Backup Server 进入pbs后，配置 Debian 和 Proxmox Backup Server的仓库源，将 /etc/apt/sources.list 修改为这样（基于 Debian 12 bookworm），其中建议前两行修改为你下载最快 国内源, 帮助文档。\n1 2 3 deb https://deb.debian.org/debian bookworm main contrib deb https://deb.debian.org/debian bookworm-updates main contrib deb https://deb.debian.org/debian-security bookworm-security main contrib 信任 Proxmox 的 keyring（只下载了当前版本 bookworm 的 key）：\n1 2 apt install wget wget http://download.proxmox.com/debian/proxmox-release-bookworm.gpg -O /etc/apt/trusted.gpg.d/proxmox-release-bookworm.gpg 新建 /etc/apt/sources.list.d/pbs.list ，内容如下，也可以修改为你下载最快的 国内源, 帮助文档。\n1 deb http://download.proxmox.com/debian/pbs bookworm pbs-no-subscription 安装 Proxmox Backup Server：\n1 2 apt update apt install proxmox-backup-server 安装完成以后会多产生一个文件 /etc/apt/sources.list.d/pbs-enterprise.list，将其内容注释掉。\n然后就可以愉快的访问 https://\u0026lt;IP\u0026gt;:8007 来配置PBS了，有DDNS的童鞋也可以在webui中设置acme自动更新ssl证书。\n其他 如果想要在 Proxmox Backup Server 可以查看磁盘的SMART信息，则 /etc/systemd/nspawn/pbs.nspawn 下面这样的： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [Exec] Hostname=pbs Capability=CAP_SYS_RAWIO [Network] ## eth0是指基于宿主机上的eth0创建MacVLAN网卡，需要修改为自己的，比如 vmbr0, ens18, eno1等等 MACVLAN=eth0 [Files] PrivateUsersChown=yes ## Proxmox Backup Server的备份数据存放位置，类似于Docker的映射，冒号左边是宿主机的路径，右边是容器内的路径，如果之前用过Docker，可以直接用的之前配置的路径 Bind=/mnt/data:/mnt/data ## 允许 Proxmox Backup Server 查看哪些磁盘的SMART信息，全部映射给它就好 Bind=/dev/sda Bind=/dev/sdb ...其他磁盘 然后对上述设置过的磁盘设置允许容器读取信息：\n1 2 3 systemctl set-property systemd-nspawn@pbs DeviceAllow=\u0026#39;/dev/sda r\u0026#39; systemctl set-property systemd-nspawn@pbs DeviceAllow=\u0026#39;/dev/sdb r\u0026#39; ...其他磁盘 设置pbs容器在宿主机开机时自启： 1 machinectl enable pbs 在容器内默认仍然是宿主机的 hostname ，在容器内可以修改 /etc/hostname 为 pbs。\n如果未来要更新PBS，进入容器后输入 apt update \u0026amp;\u0026amp; apt upgrade 就好了，简单方便。\n使用MacVLAN时，默认情况下宿主机无法访问和自身处在同一个子网下的 Systemd 容器，不在一个子网的可以访问，所以建议将PBS的IP设置在和宿主机不在一个子网下。当然，在一个子网也可以访问，可以在宿主机再额外创建一个macvlan桥来达到目的：\n1 2 3 4 ip link add mymv link eth0 type macvlan mode bridge # mymv是新创建的网桥名称（下同），eth0是上述容器内虚拟MacVLAN网卡桥接的宿主机网卡的名称，此二者按需修改 ip link set dev mymv address \u0026#34;76:d3:4a:8b:81:47\u0026#34; # 新网桥的mac地址你可以按需修改 ip link set mymv up ip route add \u0026#34;10.0.0.30\u0026#34; dev mymv # 10.0.0.30是pbs容器的ip，修改为自己的 在宿主机重启以后，需要再次输入以上命令，如果希望自动化实现，可以根据以下情况的不同来选择。\n宿主机是 Debian 的话，新建 /etc/network/if-up.d/mymv，内容如下，其中 eth0 mymv 76:d3:4a:8b:81:47 10.0.0.30 请根据上文的解释和你的实际情况修改。\n1 2 3 4 5 6 7 8 #!/bin/sh if [ \u0026#34;$IFACE\u0026#34; = \u0026#34;eth0\u0026#34; ]; then ip link add mymv link eth0 type macvlan mode bridge ip link set dev mymv address \u0026#34;76:d3:4a:8b:81:47\u0026#34; ip link set mymv up ip route add 10.0.0.30 dev mymv fi 然后为该脚本增加可执行权限：\n1 chmod +x /etc/network/if-up.d/mymv 宿主机是 Arch Linux 的话，如果使用的网络管理软件是 networkmanager ，可以创建 /etc/NetworkManager/dispatcher.d/10-mymv，内容如下，其中 eth0 mymv 76:d3:4a:8b:81:47 10.0.0.30 请根据上文的解释和你的实际情况修改。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash export LANG=\u0026#39;C\u0026#39; INTERFACE=$1 STATUS=$2 set_ip_route() { if [[ \u0026#34;$INTERFACE\u0026#34; == \u0026#34;eth0\u0026#34; ]]; then ip link add mymv link eth0 type macvlan mode bridge ip link set dev mymv address \u0026#34;76:d3:4a:8b:81:47\u0026#34; ip link set mymv up ip route add 10.0.0.30 dev mymv fi } case \u0026#34;$STATUS\u0026#34; in \u0026#34;up\u0026#34;|\u0026#34;vpn-up\u0026#34;) set_ip_route;; esac exit 0 该脚本同样需要可执行权限：\n1 chmod +x /etc/NetworkManager/dispatcher.d/10-mymv 其他功能详见 Systemd-nspawn。 截图 ","date":"2024-01-23T00:00:00+08:00","image":"https://evine.win/p/install-proxmox-backup-server-with-systemd-container/pic1_hu10254558606837250364.png","permalink":"https://evine.win/p/install-proxmox-backup-server-with-systemd-container/","title":"安装Proxmox Backup Server新姿势，Systemd Container！"},{"content":"我们有时候会需要临时创建一些文件，在Linux中我们一般在/tmp目录下来创建，Debian / PVE 默认不会将/tmp目录挂载到内存中。可以先输入命令检查一下：\n1 df -h 如果上面的命令没有输出类似下面这样的内容，那么就说明/tmp不是挂载在内存中的。\n1 tmpfs 31G 4.6M 31G 1% /tmp 我们可以手动挂载/tmp/到内存中，这样如果临时文件用得多，可以减少磁盘写入量，并提升IO。以root运行下面的命令即可。\n1 2 cp /usr/share/systemd/tmp.mount /etc/systemd/system systemctl enable --now tmp.mount 然后检查一下：\n1 df -h ","date":"2023-11-28T00:00:00+08:00","image":"https://evine.win/p/debian-pve-mount-tmp-in-ram/pve-poster_hu9310090483394246981.jpg","permalink":"https://evine.win/p/debian-pve-mount-tmp-in-ram/","title":"Debian / PVE 在内存中挂载 /tmp"},{"content":" 关键词：爱快 IPv4 / IPv6 ACL / 防火墙 端口转发 设置 安全\n相关概念 引用自爱快帮助文档，不完全理解也没有关系，可以在实践中加深概念理解。\n协议栈：支持选择IPV4或IPV6，在爱快路由3.7.0及以上版本支持。 协议：这条ACL规则所走的协议的类型。 动作：允许或阻断； 方向： 进或转发； [进]：内网或外网进路由。 [转发]：路由接收到内网或外网数据然后把数据进行转发动作。 连接方向匹配: [原始方向]：匹配主动发起方发起访问时的报文。 [应答方向]：匹配被访问方应答时的报文。 源地址：转发与进动作的起始地址。 目的地址：转发与进动作的结束地址。 源端口：允许或阻断的起始端口。 目的端口：特定目标的端口。 进接口：数据来源口。 出接口：目的出口。 IPv4与IPv6的不同 IPv4在爱快系统中设置了端口转发以后，被转发的端口通过任何公网IP都能访问，不太安全，但总得来说只限制在转发的端口范围内。\n而IPv6不存在端口转发的概念，只要在爱快系统中启用了IPv6，那么内网的设备都有全球唯一的IPv6地址，不需要什么设置就能从公网访问。而爱快默认就没有启用IPv6防火墙，意思就是有IPv6地址的设备是几乎完全暴露在公网环境中的，极不安全。\n当然，ISP大概率封掉了一些常见的端口。\nIPv4的ACL/防火墙设置 IPv4要设置ACL/防火墙，由于NAT的存在，只需要针对设置了端口转发/UPNP/DMZ的端口/设备来设置。可以参考这篇教程 ，可以限制SSH/WEBUI/RDP的访问来源IP，提高安全性。\n注意，如要设置ACL，要先设置好端口转发，然后只针对需要提高安全性的转发端口来设置ACL（BT/PT软件IPv4的监听端口只转发不设置ACL）。\nIPv6的ACL/防火墙设置 ACL中允许的优先级高于阻断。\n爱快在3.7.0新增了IPv6 ACL/防火墙的功能，由此终于可以放心的开启IPv6了。爱快3.7.7新增了IPv6分组和MAC分组功能，不过还有BUG，在3.7.8终于稳定了，可以导入分组了简化设置了。\n导入IPv6分组 下载 ipv6group.csv ，然后在爱快 “网络设置 -\u0026gt; 终端分组设置 -\u0026gt; IPv6分组” 处导入。如果下载不下来，可以前往我放在Github上的仓库 https://github.com/devome/files/tree/master/zxipv6wry clone后使用，在该仓库中，你也可以查阅中国完整的IPv6数据及分省数据。\n需要注意的是，由于爱快分组名称的字数有限制，所以“联通”包含“联通”和“网通”，“移动”包含“移动”和“铁通”，“鹏博士”包含“鹏博士”和“长城宽带”。还有部分IPv6数据暂不清楚其分配到什么省份，所以归类为“未知省份”，请在选择来源IPv6分组时根据你的实际需要进行选择。\n设置MAC分组 爱快3.7.7也新增了MAC分组功能，如果你想设置的设备的IPv6地址后缀部分不固定，可以通过MAC来放行IPv6流量，这时，你需要将后面需要设置的设置的MAC地址根据需要形成一个或多个分组，请自行在爱快 “网络设置 -\u0026gt; 终端分组设置 -\u0026gt; MAC分组” 处设置。\nACL规则 默认规则 注：第一条阻断规则的连接方向为原始方向，第二条允许规则的连接方向为关闭。并且由于目前爱快的IPv6 ACL还无法针对性的打开指定本地设备的ICMP协议，所以这样操作以后会默认禁止从公网ping本地的IPv6地址。爱快默认允许，所以上图中第二条规则不设置也可以。\n然后再对有安全性要求的端口/IP来针对性的开放权限。以下举几种情况：\nWEBUI/HTTPS/HTTP/SSH/RDP等 假如8080,20000,30000-30004这几个端口都是同一台设备上运行的WEBUI/SSH/RDP控制端口，只允许你所在省份电信和联通的IPv6地址访问。这个设备有两个IPv6地址（比如一个是DHCPv6分配的，一个是设备自己通过EUI-64自行设置的），分别为：\n1 2 2400:d0a0:38ba:abde:abbb:c1f:fea5:6c4c/64 2400:d0a0:38ba:abde::add/64 设置方式有两种形式，一种是“后缀匹配”，如下图所示（注：后缀式/负掩码写法是一个全0的位串，后面跟着一个全1的位串，表示地址中不变的部分。）：\n另一种形式是 “MAC匹配”，如下图所示（实际上根据下面的说明，这种外网访问内网的MAC匹配过滤是无法生效的，建议只对内网访问外网使用MAC地址匹配过滤）：\n重要提示\n根据 爱快官方人员的说明：IPv6外网主动访问内网，无法做目的mac匹配，只能做后缀匹配也就是IPv6地址匹配。因为外网主动访问的，内网的此终端IPv6地址对应的mac地址，无法立马拿到（这个就涉及内核的发包细节了）。如果是内网主动向外访问，源主机对应的mac地址路由能第一时间就能拿到。\nBT/PT的监听端口 假如33333,44444这两个端口是BT/PT下载软件的下载监听端口，由于上面最开始添加的默认规则阻断了其他公网IPv6访问本地，现在需要将33333,44444在IPv6上暴露出去。假如下载软件的IPv6地址是：\n1 2400:d0a0:38ba:abde:42:aff:fe00:fc/64 同上文所述，后缀匹配（下图仅示意了tcp协议，一般BT/PT需要同时监听tcp和udp协议，而爱快目前不能同时设置tcp+udp，只能分成两条规则，请自行再增加一个udp的规则）：\n完全暴露某台设备 因为某些原因（比如PCDN），假如需要将某些IPv6完全暴露在公网中，那么可以按照上文中 “后缀匹配” 进行设置即可，唯一的不同点是协议选择“任意“，源地址留空，表示全部允许全部源地址的全部协议。\n一点TIPS：可以在局域网网中通过nmap把某台机器开放的端口扫描出来，比如： nmap -6 240e:1234:5678:90ab::1000 -Pn -p 1024-65535，输出会将打开的端口显示出来，知道了哪些端口是打开的，就可以只开放这些端口，而无需开放全部端口。比如，有些系统有个控制台，但可能你并不想把控制台的端口转发到公网上。\n规则验证 另外找台公网机器（不在本地网络中的，用手机蜂窝网临时开个热点也行），安装好nmap（linux直接从仓库中安装，windows的在 这里），比如检测IPv6的某端口开放情况运行下面命令即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ## 检测IPv6某端口的开放情况 nmap -6 \u0026lt;IPv6地址或能解析IPv6的域名\u0026gt; -p \u0026lt;端口\u0026gt; -Pn ## 举例 nmap -6 2400:d0a0:38ba:abde:abbb:c1f:fea5:6c4c -p 8080,20000,30000-30004 -Pn ## 输出 Starting Nmap 7.93 ( https://nmap.org ) at 2023-04-08 20:40 CST Nmap scan report for 2400:d0a0:38ba:abde:abbb:c1f:fea5:6c4c Host is up (0.016s latency). PORT STATE SERVICE 8080/tcp open unknown 20000/tcp filtered unknown 30000/tcp filtered unknown 30001/tcp filtered unknown 30002/tcp open unknown 30003/tcp open unknown 30004/tcp open unknown 假如要检测IPv4的端口开放情况，把命令中的-6更换为-4即可。\nstate状态说明：\nopen: 目标可达并且端口已开放； closed: 目标可达但端口没有打开，一般是没有服务运行在这个端口上； fitered: 目标不可达，也就是被ACL/防火墙阻断了。 你可以启用/停用爱快系统中对应的ACL规则后，运行命令检测端口是否可连接。\n","date":"2023-11-27T00:00:00+08:00","image":"https://evine.win/p/ikuai-set-ipv6-acl-2/pic1_hu12656687762263913986.png","permalink":"https://evine.win/p/ikuai-set-ipv6-acl-2/","title":"爱快 IPv6 ACL/防火墙设置（爱快 3.7.8+）"},{"content":"关于systemd 本系列全部服务都使用 systemd 来启动和管理，在系列中并未过多的说明这些服务如何启动、开启自启、重启、重载、停止、查看日志、筛选日志等等。关于 systemd，阮一峰大佬有详细的教程：Systemd 入门教程，该文详细的介绍了 systemctl 及 journalctl 相关命令的使用方法。\n关于磁盘占用 整套系统配置下来，初始的磁盘占用不到2G。从长远来看，只要不会有需要占用大量磁盘空间的应用程序，16应该是绰绰有余。\n关于内存 安装完这一系列内容，实际上内存使用并没有增加多少，才 340MiB 左右。注意 buffer 和 cache 是可以通过调整参数降低的，这个占用不算真正的占用。 buffer 和 cache 反而是对系统运行有好处的，在内存足够的前提下，不建议清除它们。如果内存真的不够，你可以按照 这个链接 来限制它们。\n如果想要进一步降低内存使用，可以自行动态编译前面所使用到的全部软件包，再使用 upx 来深度压缩，这样处理后能让内存消耗再小一些，能缩减到 300MiB 以下。不过注意 unblocknem 不能这样操作，如果想要减小它的内存占用，请按照 官方仓库 安装 nodejs 后使用源码运行，并调整 unblocknem.service 中的 ExecStart。\n关于DNS 我们在 本系列第（三）篇 使用了 adguardhome mosdns 和 clash 来实现自建DNS服务，在 adguardhome 和 mosdns 中都存在后备，两级后备保证局域网中的设备访问中国大陆的服务不会因为 clash 的代理节点出问题，而导致无法访问。我想这点对家人的使用比较重要，他们大多数都只需要能够访问中国大陆有服务就可以了，他们不会再闹着说“又上不了网了，你咋搞的嘛”。\n在 OpenWRT 中默认是会安装 dnsmasq 的，许多包都会操作 dnsmasq ，这可能也是导致解析不到DNS的原因。 使用 Debian 没有此烦恼，因为压根没有安装 dnsmasq。\n关于网络故障 我们将 nftables 规则绑定到 clash 启动之后才执行，在 本系列第（四）篇 我们是以 ExecStartPost 来让 nftables 规则在 clash 启动之后才执行的。如果 clash 没启动好， nftables 规则也就不会执行，假如这个时候 adguardhome 和 mosdns 都启动好了，由于 mosdns 无法使用 clash 的DNS服务，它会全部切换到后备也就是国内公共DNS服务器去解析，这不会影响家人的上网体验。另一方面，假如 clash 启动好了， nftables 规则也创建好了，可是 clash 的代理节点全部故障了，这个时候，由于我们有绕过中国大陆IP的 nftables 规则，仍然不会影响我们使用境内服务。即使再极端一点，连 nftables 也坏了，因为我们是使用 nftables 脚本来生成的，而不是使用 shell 命令一句一句输入的，所以只会整个 mynftables.nft 脚本中的规则全在或者全不在（有任何一句出错就会全不在），那么全不在就意味着没有任何 nftables 规则，旁路由这时除了DNS，就是一个纯粹的 IPv4 转发器，更不会干扰网络的运行（只会影响特殊服务而已）。\n在 OpenWRT 中许多包都会操作 iptbales 或者 nftables，它们之间可能并没有很好的协调与配合，毕竟分属不同的人开发。并且多数都是以一句一句的 shell 命令来增加的规则，很有可能有些语句生效了，有些语句没有生效，然后导致网络故障。现在我们全部自写 nftables 规则，逻辑清楚，并且只会随着 clash 的启动而启动，而不是脱离 clash 自己单独启动，并且直接采用 nftables 脚本而非 shell 脚本，这样就能避免一些网络故障问题。\n关于IPv6 所配置的旁路由只作为了IPv4的网关，不作为IPv6的网关主要有两个原因，一是IPv6代理并未普及，二是想要旁路由成为IPv6网关异常复杂。不过，仍然保留了中国大陆网址的IPv6访问的能力。局域网中对公网转发的服务也是可以提供IPv6访问的，这点并不影响。在非旁路由所在的子网中，IPv4/IPv6双栈都是默认可用的状态。\n关于软件包 国内的用户使用 OpenWRT 一般是使用 LEDE，如果是自己编译的话，面对繁多的选项无从下手，用别人的 高大全 又老是配置不好，而且还面临不太好升级的问题。一些旧的软件包想要更新，都要先更新固件的编译依赖仓库。\n而使用 Debian 的话，它自带的仓库是极度稳定的，自己想要额外安装的一些软件包，基于这个稳定的环境，运行也更稳定，而且额外安装的软件包可以保持追新。这样基础环境稳定，部分特殊软件追新，让体验更加完美。\n在 本系列第（二）篇 中还提及了一些其他的软件包，这些都是简单地应用，如有需要可自行搜索其帮助文档。\n关于本系列提供的脚本 如果你相对于我的改动较多，你就可能不能直接使用本系列提供的 shell 脚本。如涉及到改动，可能需要你自行修改相关脚本内容，以适应你的环境。若因此脚本出现错误，本人无法提供过多的建议，可能需要你自行排故。\n系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-22T07:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%8D%81%E4%B8%80/ram_hu2248564133320780744.png","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%8D%81%E4%B8%80/","title":"我的家庭网络设计思路，开启debian的旁路由之路（十一）"},{"content":"前言 这已经是 这个系列 的第十篇了，我们将前文要用到的从Github下载的各个软件包，实现更容易的更新和安装。\n脚本 我默认你已经按照 前文（二） 安装好各种必要的软件包了。新建 /usr/local/bin/update-pkgs.sh 内容如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 #!/usr/bin/env bash pkgs=( adguardhome cidr_merger clash mosdns nali subconverter trzsz unblocknem ) declare -A adguardhome adguardhome[cmd]=\u0026#39;adguardhome\u0026#39; adguardhome[reponame]=\u0026#39;AdguardTeam/AdGuardHome\u0026#39; adguardhome[dlname]=\u0026#39;AdGuardHome_linux_amd64.tar.gz\u0026#39; adguardhome[decomp]=\u0026#39;tar --no-same-owner -xf \u0026#34;$dlname\u0026#34; --strip-components 2 --directory=.\u0026#39; adguardhome[install]=\u0026#39;install -ps AdGuardHome /usr/local/bin/${cmd}\u0026#39; adguardhome[install_post]=\u0026#39;systemctl restart ${cmd}.service\u0026#39; adguardhome[local_ver]=\u0026#39;${cmd} --version 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A cidr_merger cidr_merger[cmd]=\u0026#39;cidr-merger\u0026#39; cidr_merger[reponame]=\u0026#39;zhanhb/${cmd}\u0026#39; cidr_merger[dlname]=\u0026#39;${cmd}-linux-amd64\u0026#39; cidr_merger[install]=\u0026#39;install -ps \u0026#34;${dlname}\u0026#34; /usr/local/bin/${cmd}\u0026#39; cidr_merger[local_ver]=\u0026#39;${cmd} -v |\u0026amp; grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A clash clash[cmd]=\u0026#39;clash\u0026#39; clash[reponame]=\u0026#39;MetaCubeX/mihomo\u0026#39; clash[dlname]=\u0026#39;mihomo-linux-amd64-v${remote_ver}.gz\u0026#39; # 这一行默认下载的是 AMD64 v3 架构的包，如若不支持，可以下载名称中带 cgo 或者 compatible 的，说明：https://github.com/MetaCubeX/Clash.Meta/wiki/FAQ clash[decomp]=\u0026#39;gzip -d $dlname\u0026#39; clash[install]=\u0026#39;install -ps mihomo-linux-amd64-v${remote_ver} /usr/local/bin/${cmd}\u0026#39; clash[install_post]=\u0026#39;systemctl restart ${cmd}.service\u0026#39; clash[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34; | head -1\u0026#39; declare -A mosdns mosdns[cmd]=\u0026#39;mosdns\u0026#39; mosdns[reponame]=\u0026#39;IrineSistiana/$cmd\u0026#39; mosdns[dlname]=\u0026#39;${cmd}-linux-amd64.zip\u0026#39; mosdns[decomp]=\u0026#39;unzip -oqq $dlname -d .\u0026#39; mosdns[install]=\u0026#39;install -ps ${cmd} /usr/local/bin/${cmd}\u0026#39; mosdns[install_post]=\u0026#39;systemctl restart ${cmd}.service\u0026#39; mosdns[local_ver]=\u0026#39;${cmd} version 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A nali nali[cmd]=\u0026#39;nali\u0026#39; nali[reponame]=\u0026#39;zu1k/${cmd}\u0026#39; nali[dlname]=\u0026#39;${cmd}-linux-amd64-v${remote_ver}.gz\u0026#39; nali[decomp]=\u0026#39;gzip -d $dlname\u0026#39; nali[install]=\u0026#39;install -ps ${cmd}-linux-amd64-v${remote_ver} /usr/local/bin/${cmd}\u0026#39; nali[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A subconverter subconverter[cmd]=\u0026#39;subconverter\u0026#39; subconverter[reponame]=\u0026#39;tindy2013/${cmd}\u0026#39; subconverter[dlname]=\u0026#39;${cmd}_linux64.tar.gz\u0026#39; subconverter[decomp]=\u0026#39;tar --no-same-owner -xf \u0026#34;$dlname\u0026#34; --strip-components 1 --directory=.\u0026#39; subconverter[install]=\u0026#39;install -ps ${cmd} /usr/local/bin/${cmd}; rm -rf $cmd $dlname /var/lib/$cmd/*; cp -afr base config generate.ini gistconf.ini pref.* profiles rules snippets /var/lib/$cmd/\u0026#39; subconverter[install_post]=\u0026#39;systemctl restart ${cmd}.service\u0026#39; subconverter[local_ver]=\u0026#39;curl -sS http://127.0.0.1:25500/version 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A trzsz trzsz[cmd]=\u0026#39;trzsz\u0026#39; trzsz[reponame]=\u0026#39;${cmd}/${cmd}-go\u0026#39; trzsz[dlname]=\u0026#39;${cmd}_${remote_ver}_linux_x86_64.tar.gz\u0026#39; trzsz[decomp]=\u0026#39;tar --no-same-owner -xf \u0026#34;$dlname\u0026#34; --strip-components 1 --directory=.\u0026#39; trzsz[install]=\u0026#39;install -ps trz /usr/local/bin/trz; install -ps tsz /usr/local/bin/tsz; install -ps $cmd /usr/local/bin/$cmd\u0026#39; trzsz[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A unblocknem unblocknem[cmd]=\u0026#39;unblocknem\u0026#39; unblocknem[reponame]=\u0026#39;UnblockNeteaseMusic/server\u0026#39; unblocknem[dlname]=\u0026#39;unblockneteasemusic-linux-x64\u0026#39; unblocknem[install]=\u0026#39;install -p $dlname /usr/local/bin/$cmd\u0026#39; unblocknem[install_post]=\u0026#39;systemctl restart ${cmd}.service\u0026#39; unblocknem[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; ## 安装软件 update_pkgs() { for pkg in ${pkgs[@]}; do eval cmd=\\${$pkg[cmd]} eval reponame_ori=\\${$pkg[reponame]} eval reponame=$reponame_ori eval dlname_ori=\\${$pkg[dlname]} eval dlurl_ori=\\${$pkg[dlurl]} eval decomp=\\${$pkg[decomp]} eval install=\\${$pkg[install]} eval install_post=\\${$pkg[install_post]} eval local_ver_ori=\\${$pkg[local_ver]} echo \u0026#34;======== 更新 $pkg ========\u0026#34; workdir=\u0026#34;/tmp/software/$pkg\u0026#34; [[ ! -d \u0026#34;$workdir\u0026#34; ]] \u0026amp;\u0026amp; mkdir -p \u0026#34;$workdir\u0026#34; rm -rf \u0026#34;$workdir\u0026#34;/* \u0026amp;\u0026gt;/dev/null cd \u0026#34;$workdir\u0026#34; remote_ver=$(curl -sS https://api.github.com/repos/${reponame}/releases/latest 2\u0026gt;/dev/null | jq -r .tag_name | sed \u0026#39;s|v||\u0026#39; | grep -v \u0026#34;null\u0026#34;) local_ver=$(eval $local_ver_ori) if [[ -n $remote_ver \u0026amp;\u0026amp; $remote_ver != $local_ver ]]; then eval dlname=$dlname_ori eval dlurl=$dlurl_ori if [[ -z $dlurl ]]; then dlurl=\u0026#34;https://github.com/${reponame}/releases/download/v${remote_ver}/${dlname}\u0026#34; fi if [[ -n $local_ver ]]; then echo \u0026#34;\u0026gt;\u0026gt; 即将从 $local_ver 升级至 $remote_ver ...\u0026#34; else echo \u0026#34;\u0026gt;\u0026gt; 未检测到本地版本，即将安装 $remote_ver 版本...\u0026#34; fi echo \u0026#34;\u0026gt;\u0026gt; 开始下载：$dlurl ...\u0026#34; echo \u0026#34;\u0026gt;\u0026gt; 临时保存至：$workdir/${dlname} ...\u0026#34; echo -n \u0026#34;\u0026gt;\u0026gt; 下载进度：\u0026#34; if wget -q --progress=bar:dot --show-progress -O \u0026#34;${dlname}\u0026#34; \u0026#34;$dlurl\u0026#34;; then if [[ -n $decomp ]]; then echo \u0026#34;\u0026gt;\u0026gt; 临时解压至：$workdir ...\u0026#34; eval $decomp fi echo \u0026#34;\u0026gt;\u0026gt; 执行安装命令：$install ...\u0026#34; if eval $install; then if [[ -n $install_post ]]; then echo \u0026#34;\u0026gt;\u0026gt; 执行安装后钩子：$install_post ...\u0026#34; if ! eval $install_post; then echo \u0026#34;\u0026gt;\u0026gt; 安装后钩子执行失败，请检查命令是否正确...\u0026#34; fi fi else echo \u0026#34;\u0026gt;\u0026gt; 安装失败，请检查命令是否正确...\u0026#34; fi else echo \u0026#34;\u0026gt;\u0026gt; 下载失败：$dlurl\u0026#34; fi elif [[ -n $remote_ver \u0026amp;\u0026amp; $remote_ver == $local_ver ]]; then echo \u0026#34;\u0026gt;\u0026gt; 本地版本已经是最新版本 $remote_ver ，无需更新...\u0026#34; else echo \u0026#34;\u0026gt;\u0026gt; 未获取到最新版本，无法更新，请检查网络原因...\u0026#34; fi if [[ -n $(ls $workdir) ]]; then echo \u0026#34;\u0026gt;\u0026gt; 删除临时文件：$workdir/* ...\u0026#34; rm -rf \u0026#34;$workdir\u0026#34;/* \u0026amp;\u0026gt;/dev/null fi echo done } ## 中止时删除临时文件 finish() { rm -rf /tmp/software \u0026amp;\u0026gt;/dev/null } ## 执行主函数 main() { trap finish EXIT if [[ -n \u0026#34;$@\u0026#34; ]]; then pkgs=( $@ ) fi update_pkgs } main \u0026#34;$@\u0026#34; 为它增加可执行权限：\n1 chmod +x /usr/local/bin/update-pkgs.sh 使用 1 2 update-pkgs.sh # 更新或安装 pkgs 数组中的全部软件包 update-pkgs.sh clash nali # 指定更新或安装所输入的软件包 建议还是不要将其加入定时任务来自动更新。\n如果老是获取不到 Github 上的最新版本号，可以尝试将获取版本号那一行改成下面这样，其中的 $GITHUB_TOKEN 为你自己申请的 Github Token（官方说明）。\n1 remote_ver=$(curl -H \u0026#34;Authorization: Bearer $GITHUB_TOKEN\u0026#34; -sS https://api.github.com/repos/${reponame}/releases/latest 2\u0026gt;/dev/null | jq -r .tag_name | sed \u0026#39;s|v||\u0026#39; | grep -v \u0026#34;null\u0026#34;) 说明 全部的软件包需要定义在数组 pkgs 中，并以每个软件包定义一组数组。数组中的键名（不能使用 - ）依次含义为： cmd：如果后面的变量要用到，就需要定义，软件包的命令名。 reponame：Github上的仓库名。 remote_ver：这个键无需你来定义，而是由脚本根据 reponame 去获取的Github上的最新稳定版本号。 dlname：要下载的软件包在Github上Release的名称，可引用前面的键。 dlurl：如果不定义这个键，就采用 https://github.com/${reponame}/releases/download/v${remote_ver}/${dlname}，如果定义了就用所定义的。可引用前面的键。 decomp：如果下载的文件是压缩包，如何解压它，可以引用前面的变量，如不需要解压可不定义。可引用前面的键。 install：如何安装软件包。可引用前面的键。 intall_post：安装后如果需要重启什么服务，可以定义它如何重启。可不定义。可引用前面的键。 local_ver：如何获取本地软件包的版本号。可引用前面的键。 数组中和键的值如果需要使用变量引用，如果最外层用单引号，在 $ 前面无需转义，如果最外层用双引号，在 $ 前面请添加 \\ 转义。\n如果后面的引用了前面的，那么前面的必须定义。\n其他Github上的软件包，你可以用同样的方式定义在脚本中，以实现自动安装或更新。\n其他 比如我还用到另外一组软件包，就是这样子的，你可能注意到不同软件包定义的键不太一样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 pkgs=( act aliyunpan baidupcs cidr_merger ctop gitea influx_cli nali realtek_r8125_dkms tokei timemachine trzsz ) declare -A act act[cmd]=\u0026#39;act\u0026#39; act[reponame]=\u0026#39;nektos/${cmd}\u0026#39; act[dlname]=\u0026#39;${cmd}_Linux_x86_64.tar.gz\u0026#39; act[decomp]=\u0026#39;tar --no-same-owner -xf \u0026#34;$dlname\u0026#34; --directory=.\u0026#39; act[install]=\u0026#39;install -ps ${cmd} /usr/local/bin/${cmd}\u0026#39; act[local_ver]=\u0026#39;${cmd} --version 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A aliyunpan aliyunpan[cmd]=\u0026#39;aliyunpan\u0026#39; aliyunpan[reponame]=\u0026#39;tickstep/${cmd}\u0026#39; aliyunpan[dlname]=\u0026#39;${cmd}-v${remote_ver}-linux-amd64.zip\u0026#39; aliyunpan[decomp]=\u0026#39;unzip -oqq ${dlname} -d .\u0026#39; aliyunpan[install]=\u0026#39;install -ps \u0026#34;${cmd}-v${remote_ver}-linux-amd64/${cmd}\u0026#34; /usr/local/bin/${cmd}\u0026#39; aliyunpan[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A baidupcs baidupcs[cmd]=\u0026#39;baidupcs\u0026#39; baidupcs[reponame]=\u0026#39;qjfoidnh/BaiduPCS-Go\u0026#39; baidupcs[dlname]=\u0026#39;BaiduPCS-Go-v${remote_ver}-linux-amd64.zip\u0026#39; baidupcs[decomp]=\u0026#39;unzip -oqq ${dlname} -d .\u0026#39; baidupcs[install]=\u0026#39;install -ps \u0026#34;${cmd}-v${remote_ver}-linux-amd64/BaiduPCS-Go\u0026#34; /usr/local/bin/${cmd}\u0026#39; baidupcs[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A cidr_merger cidr_merger[cmd]=\u0026#39;cidr-merger\u0026#39; cidr_merger[reponame]=\u0026#39;zhanhb/${cmd}\u0026#39; cidr_merger[dlname]=\u0026#39;${cmd}-linux-amd64\u0026#39; cidr_merger[install]=\u0026#39;install -ps \u0026#34;${dlname}\u0026#34; /usr/local/bin/${cmd}\u0026#39; cidr_merger[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;\u0026amp;1 | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A ctop ctop[cmd]=\u0026#39;ctop\u0026#39; ctop[reponame]=\u0026#39;bcicen/${cmd}\u0026#39; ctop[dlname]=\u0026#39;${cmd}-${remote_ver}-linux-amd64\u0026#39; ctop[install]=\u0026#39;install -ps \u0026#34;${dlname}\u0026#34; /usr/local/bin/${cmd}\u0026#39; ctop[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34; | head -1\u0026#39; declare -A evsieve evsieve[cmd]=\u0026#39;evsieve\u0026#39; evsieve[reponame]=\u0026#39;KarsMulder/${cmd}\u0026#39; evsieve[dlname]=\u0026#39;${cmd}\u0026#39; evsieve[dlurl]=\u0026#39;https://raw.githubusercontent.com/devome/files/master/${cmd}/${cmd}\u0026#39; evsieve[install]=\u0026#39;install -ps \u0026#34;${dlname}\u0026#34; /usr/local/bin/${cmd}\u0026#39; evsieve[install_post]=\u0026#39;systemctl restart ${cmd}.service\u0026#39; evsieve[local_ver]=\u0026#39;${cmd} --version 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A gitea gitea[cmd]=\u0026#39;gitea\u0026#39; gitea[reponame]=\u0026#39;go-${cmd}/${cmd}\u0026#39; gitea[dlname]=\u0026#39;${cmd}-${remote_ver}-linux-amd64\u0026#39; gitea[install]=\u0026#39;install -ps ${cmd}-${remote_ver}-linux-amd64 /usr/local/bin/${cmd}\u0026#39; gitea[install_post]=\u0026#39;systemctl restart ${cmd}.service\u0026#39; gitea[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34; | head -1\u0026#39; declare -A influx_cli influx_cli[reponame]=\u0026#39;influxdata/influx-cli\u0026#39; influx_cli[dlname]=\u0026#39;influxdb2-client-${remote_ver}-amd64.deb\u0026#39; influx_cli[dlurl]=\u0026#39;https://dl.influxdata.com/influxdb/releases/${dlname}\u0026#39; influx_cli[install]=\u0026#39;dpkg -i \u0026#34;${dlname}\u0026#34;\u0026#39; influx_cli[local_ver]=\u0026#39;LC_ALL=C apt list --installed 2\u0026gt;/dev/null | grep -P \u0026#34;influxdb2-cli/.+installed,local\u0026#34; | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A nali nali[cmd]=\u0026#39;nali\u0026#39; nali[reponame]=\u0026#39;zu1k/${cmd}\u0026#39; nali[dlname]=\u0026#39;${cmd}-linux-amd64-v${remote_ver}.gz\u0026#39; nali[decomp]=\u0026#39;gzip -d $dlname\u0026#39; nali[install]=\u0026#39;install -ps ${cmd}-linux-amd64-v${remote_ver} /usr/local/bin/${cmd}\u0026#39; nali[local_ver]=\u0026#39;${cmd} -v | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A realtek_r8125_dkms realtek_r8125_dkms[reponame]=\u0026#39;devome/realtek-r8125-dkms\u0026#39; realtek_r8125_dkms[dlname]=\u0026#39;realtek-r8125-dkms_${remote_ver}_amd64.deb\u0026#39; realtek_r8125_dkms[install]=\u0026#39;dpkg -i \u0026#34;${dlname}\u0026#34;\u0026#39; realtek_r8125_dkms[local_ver]=\u0026#34;LC_ALL=C apt list --installed 2\u0026gt;/dev/null | grep -P \u0026#39;realtek-r8125-dkms/.+installed,local\u0026#39; | awk \u0026#39;{print \\$2}\u0026#39;\u0026#34; declare -A tokei tokei[cmd]=\u0026#39;tokei\u0026#39; tokei[reponame]=\u0026#39;XAMPPRocky/${cmd}\u0026#39; tokei[dlname]=\u0026#39;${cmd}-x86_64-unknown-linux-gnu.tar.gz\u0026#39; tokei[decomp]=\u0026#39;tar --no-same-owner -xf \u0026#34;$dlname\u0026#34; --directory=.\u0026#39; tokei[install]=\u0026#39;install -ps ${cmd} /usr/local/bin/${cmd}\u0026#39; tokei[local_ver]=\u0026#34;\\${cmd} -V 2\u0026gt;/dev/null | awk \u0026#39;{print \\$2}\u0026#39;\u0026#34; declare -A timemachine timemachine[cmd]=\u0026#39;timemachine\u0026#39; timemachine[reponame]=\u0026#39;cytopia/linux-${cmd}\u0026#39; timemachine[dlname]=\u0026#39;v${remote_ver}.tar.gz\u0026#39; timemachine[dlurl]=\u0026#39;https://github.com/${reponame}/archive/refs/tags/${dlname}\u0026#39; timemachine[decomp]=\u0026#39;tar --no-same-owner -xf \u0026#34;$dlname\u0026#34; --strip-components 1 --directory=.\u0026#39; timemachine[install]=\u0026#39;make install\u0026#39; timemachine[local_ver]=\u0026#39;${cmd} -V 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; declare -A trzsz trzsz[cmd]=\u0026#39;trzsz\u0026#39; trzsz[reponame]=\u0026#39;${cmd}/${cmd}-go\u0026#39; trzsz[dlname]=\u0026#39;${cmd}_${remote_ver}_linux_x86_64.tar.gz\u0026#39; trzsz[decomp]=\u0026#39;tar --no-same-owner -xf \u0026#34;$dlname\u0026#34; --strip-components 1 --directory=.\u0026#39; trzsz[install]=\u0026#39;install -ps trz /usr/local/bin/trz; install tsz -ps /usr/local/bin/tsz; install -ps $cmd /usr/local/bin/$cmd\u0026#39; trzsz[local_ver]=\u0026#39;${cmd} -v 2\u0026gt;/dev/null | grep -oP \u0026#34;(\\d+\\.){2}\\d+\u0026#34;\u0026#39; 系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-22T06:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%8D%81/cover_hu12437125556482584613.png","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%8D%81/","title":"我的家庭网络设计思路，开启debian的旁路由之路（十）"},{"content":"前言 OpenWRT 有两个插件：luci-app-serverchan、luci-app-pushbot，可以监测陌生设备上线。当然它们还有些其他功能，但我们只关心“监测陌生设备上线”这一点，那么这两个插件就太臃肿了。并且它们还不能监测非旁路由所在网段，而我却将陌生设备放在了 10.0.1.0/24 中，和旁路由不在同一网段。所以我们简单的改造一下。\n安装和配置 我默认你已经按照 前文（二） 安装好了 arp-scan 了。新建 /usr/local/bin/arp.sh 内容如下，请自行在爱快中限制陌生设备所能使用的IP（参见 前文（一），用假MAC预留好可信任设备的IP位置），并填入下面的 arplist 变量中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #!/usr/bin/env bash ## 要监测的网段，可以写成下面这样，也可以写成 10.0.0.0/24这样，请在爱快中为陌生设备指定网段，可信任设备不要使用该网段的IP arplist=\u0026#34;10.0.1.101-10.0.1.110\u0026#34; arpinfo=$(echo \u0026#34;$arplist\u0026#34; | arp-scan -gxf-) if [[ -n \u0026#34;$arpinfo\u0026#34; \u0026amp;\u0026amp; \u0026#34;$arpinfo\u0026#34; != \u0026#34;$(cat /tmp/arp.txt 2\u0026gt;/dev/null)\u0026#34; ]]; then content=$(echo \u0026#34;$arpinfo\u0026#34; | perl -pe \u0026#39;{s|^|- |; s|\\t| |g; s|\\n|\\\\n\\\\n|g}\u0026#39;) echo \u0026#34;有新的终端连接到了网络：\u0026#34;$arpinfo # notify.sh \u0026#34;有新的终端连接到了网络\u0026#34; \u0026#34;$content\u0026#34; \u0026amp;\u0026gt;/dev/null # 如果需要发送通知请解除注释 echo \u0026#34;$arpinfo\u0026#34; \u0026gt; /tmp/arp.txt elif [[ -z \u0026#34;$arpinfo\u0026#34; \u0026amp;\u0026amp; -f /tmp/arp.txt ]]; then rm /tmp/arp.txt fi exit 0 为其增加可执行权限：\n1 chmod +x /usr/local/bin/arp.sh 如果你需要发送通知，解除上述脚本第10行注释的同时，在第4行之后根据下表选用通知渠道的变量并赋值。\n序号 变量名 说明 1 TG_USER_ID 通知渠道telegram，如需使用需要和 TG_BOT_TOKEN 同时赋值，私聊 @getuseridbot 获取。 2 TG_BOT_TOKEN 通知渠道telegram，如需使用需要和 TG_USER_ID 同时赋值，私聊 @BotFather 获取。 3 TG_PROXY_ADDRESS 给TG机器人发送消息的代理地址，当设置了TG_USER_ID和TG_BOT_TOKEN后可以设置此值，形如：http://192.168.1.1:7890，也可以不设置。 4 TG_PROXY_USER 给TG机器人发送消息的代理的用户名和密码，当设置了TG_PROXY_ADDRESS后可以设置此值，格式为：\u0026lt;用户名\u0026gt;:\u0026lt;密码\u0026gt;，形如：admin:password，如没有可不设置。 5 DD_BOT_TOKEN 通知渠道钉钉，如需使用需要和 DD_BOT_SECRET 同时赋值，机器人设置中webhook链接access_token=后面的字符串（不含=以及=之前的字符）。 6 DD_BOT_SECRET 通知渠道钉钉，如需使用需要和 DD_BOT_TOKEN 同时赋值，机器人设置中只启用加签，加签的秘钥，形如：SEC1234567890abcdefg。 7 IYUU_TOKEN 通知渠道爱语飞飞，通过 这里 获取，爱语飞飞的TOKEN。 8 SCKEY 通知渠道ServerChan，通过 这里 获取。 9 PUSHPLUS_TOKEN 通知渠道PUSH PLUS，填入其token，详见 这里。 10 WORK_WECHAT_BOT_KEY 通知渠道企业微信群机器人，填入机器人设置webhook链接中key=后面的字符串，不含key=。 11 GOTIFY_URL 通知渠道Gotify，填入其通知网址，需要和GOTIFY_APP_TOKEN同时赋值。 12 GOTIFY_APP_TOKEN 通知渠道Gotify，填入其TOKEN，需要和GOTIFY_URL同时赋值。 13 GOTIFY_PRIORITY 通知渠道Gotify，发送消息的优先级。 同时下载 notify.sh 保存为 /usr/local/bin/notify.sh ，并为其增加可执行权限：\n1 chmod +x /usr/local/bin/notify.sh 有许多设备无法被 arp-scan 识别出来制造商，可以编辑 /etc/arp-scan/mac-vendor.txt，手动增加它们的制造商，形式如下（MAC地址仅支持小写字母，不支持大写字母）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 02:42:0a Docker MacVLAN Network 1a:5d:23 ShenZhen Sirivision Communication Technology Co., Ltd. 6e:1c:d5 Huawei Technologies Co., Ltd. 0e:2a:7c:3a:ff:2f QEMU Virtual Machine 1a:38:df:16:2f:fe QEMU Virtual Machine 42:c9:47:6c:bf:d1 QEMU Virtual Machine 46:ee:ec:94:f0:4e QEMU Virtual Machine 54:a7:fb:1a:cc:d3 QEMU Virtual Machine 92:97:84:9b:24:c0 QEMU Virtual Machine 96:52:cc:f2:98:34 QEMU Virtual Machine 9a:6b:93:51:37:92 QEMU Virtual Machine ae:0f:0a:58:0e:47 QEMU Virtual Machine ae:85:36:a9:4b:f0 QEMU Virtual Machine b2:56:a4:68:f8:f5 QEMU Virtual Machine c6:80:e3:62:af:3a QEMU Virtual Machine ee:d7:ce:c1:85:7c QEMU Virtual Machine f6:c7:8b:c9:07:31 QEMU Virtual Machine 然后你再运行 echo \u0026quot;10.0.0.0/22\u0026quot; | arp-scan -xgf- 就可以识别出来了。\n运行 方式一：定时任务 输入 crontab -e ，在 前文（七） 创建的定时任务之后加入一条：\n1 * * * * * arp.sh \u0026gt;\u0026gt; /tmp/arp.log 未来想查看有哪些陌生设备接入，注意重启后该文件会消失，请及时查看。\n1 cat /tmp/arp.log 方式二：systemd 新建脚本 /usr/local/bin/run-arp.sh，内容如下，并增加可执行权限 chmod +x /usr/local/bin/run-arp.sh\n1 2 3 4 while :; do arp.sh sleep 60 done 新建 /etc/systemd/system/arp.service，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [Unit] Description = Detect unknown clients. After = network.target [Service] Environment = PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin Type = simple Restart = always ExecStart = run-arp.sh RestartSec = 60 StartLimitInterval = 0 [Install] WantedBy = multi-user.target 然后启用它即可：\n1 systemctl enable --now arp.service 未来想查看有哪些陌生设备接入：\n1 journalctl -u arp.service 系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-22T05:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%B9%9D/arp-scan_hu17426198552149162382.png","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%B9%9D/","title":"我的家庭网络设计思路，开启debian的旁路由之路（九）"},{"content":"前言 在 前文（一） 中我们提到了会存在 “网关为旁路由的设备在爱快的终端监控中全部显示为旁路由” 这个问题，所以我们需要借助跨三层应用来解决这个问题。\nDebian旁路由安装和配置 我默认你已经按照 前文（二） 安装好了 snmpd 了。打开 /etc/snmp/snmpd.conf，进行以下内容的修改。\n找到以下内容：\n1 #agentaddress 127.0.0.1,[::1] 修改为（我们只监听IPv4）：\n1 agentaddress 10.0.0.2 找到以下内容：\n1 2 view systemonly included .1.3.6.1.2.1.1 view systemonly included .1.3.6.1.2.1.25.1 修改为：\n1 view systemonly included .1 我们旁路由的 snmpd 服务本身只运行在局域网中，所以把全部 snmpd 的全部监控节点打开也没有问题。最后重启一下服务：\n1 systemctl restart snmpd.service 爱快主路由配置 进入爱快管理界面中的 “高级应用 -\u0026gt; 跨三层应用”，然后添加一条信息如下，保存后以旁路由为网关的设备信息就正常显示了。\n系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-22T04:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%85%AB/snmp-client_hu2962314217173893759.png","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%85%AB/","title":"我的家庭网络设计思路，开启debian的旁路由之路（八）"},{"content":"文件准备 nginx 我默认你已经按照 前文（二） 安装好了 nginx 了。新建 /etc/nginx/conf.d/private.conf，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 server { listen 80; server_name 10.0.0.2; charset \u0026#39;utf-8\u0026#39;; root /var/www/html; location / { if ($request_filename ~* ^((.*?\\.(txt|yaml|yml|md|acl|rule|list|ini|xml|conf|vcf|manifest|sig|buildinfo|json))|LICENCE|Packages|sha256sums)$){ more_set_headers \u0026#39;Content-Type: text/plain; charset=utf-8\u0026#39;; } autoindex on; # 索引 autoindex_exact_size on; # 显示文件大小 autoindex_localtime on; # 显示文件时间 } } 如果 nginx 已经启动起来了，那么重新读取下：nginx -s reload；如果 nginx 还没有启动，那么就启动它： systemctl restart nginx.service。\n然后，放在 /var/www/html 下面的文件，可以通过网址 http://10.0.0.2/XXXXX 来下载，也就是说，我们后面创建的 /var/www/html/config_template.yaml 和 /var/www/html/convert_rule.ini 等等文件，可以通过网址 http://10.0.0.2/config_template.yaml http://10.0.0.2/convert_rule.ini 来下载。\nclash配置模板 为 clash 订阅制作适合你自己的模板，根据 clash meta wiki，自行创建 /var/www/html/config_template.yaml。以下是我的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 --- port: 7890 socks-port: 7891 mixed-port: 7893 tproxy-port: 7895 routing-mark: 666 allow-lan: true bind-address: \u0026#34;*\u0026#34; mode: rule log-level: info ipv6: false find-process-mode: \u0026#39;off\u0026#39; external-controller: 0.0.0.0:9090 secret: You_Secret external-ui: ui external-ui-name: xd external-ui-url: \u0026#34;https://github.com/MetaCubeX/metacubexd/archive/refs/heads/gh-pages.zip\u0026#34; unified-delay: true tcp-concurrent: true authentication: - \u0026#34;Evine:ABCDEFGHIJK\u0026#34; experimental: sniff-tls-sni: true geodata-mode: true geodata-loader: standard geox-url: geoip: \u0026#34;https://testingcf.jsdelivr.net/gh/MetaCubeX/meta-rules-dat@release/geoip.dat\u0026#34; geosite: \u0026#34;https://testingcf.jsdelivr.net/gh/MetaCubeX/meta-rules-dat@release/geosite.dat\u0026#34; mmdb: \u0026#34;https://testingcf.jsdelivr.net/gh/MetaCubeX/meta-rules-dat@release/country.mmdb\u0026#34; profile: tracing: true store-selected: true store-fake-ip: true sniffer: enable: true # 嗅探器开关，开启后对 redir-host 类型识别的流量进行强制嗅探，包含Tun、Redir和TProxy或DNS为redir-host # force-dns-mapping: false parse-pure-ip: true # 对所有未获取到域名的流量进行强制嗅探 override-destination: true # 是否使用嗅探结果作为实际访问,默认 true，全局配置,优先级低于 sniffer.sniff 实际配置 # sniff: # TLS 默认如果不配置 ports 默认嗅探 443 # TLS: # ports: [443, 8443] # HTTP: # 需要嗅探的端口, 默认嗅探 80 # ports: [80, 8080-8880] # override-destination: true # 可覆盖 sniffer.override-destination dns: enable: true ipv6: false listen: 0.0.0.0:7874 use-hosts: true enhanced-mode: redir-host default-nameserver: - 101.226.4.6 - 114.114.114.114 - 223.5.5.5 nameserver: - \u0026#34;https://dns.alidns.com/dns-query\u0026#34; - \u0026#34;https://doh.pub/dns-query\u0026#34; - \u0026#34;https://doh.360.cn/dns-query\u0026#34; nameserver-policy: geosite:cn: - \u0026#34;https://dns.alidns.com/dns-query\u0026#34; - \u0026#34;https://doh.pub/dns-query\u0026#34; - \u0026#34;https://doh.360.cn/dns-query\u0026#34; geosite:geolocation-!cn: - \u0026#34;https://1.1.1.1/dns-query\u0026#34; - \u0026#34;https://8.8.8.8/dns-query\u0026#34; fallback: - \u0026#39;https://1.1.1.1/dns-query\u0026#39; - \u0026#39;https://8.8.8.8/dns-query\u0026#39; fallback-filter: geoip: true geoip-code: CN geosite: - gfw ipcidr: - 0.0.0.0/8 - 10.0.0.0/8 - 100.64.0.0/10 - 127.0.0.0/8 - 169.254.0.0/16 - 172.16.0.0/12 - 192.0.0.0/24 - 192.0.2.0/24 - 192.88.99.0/24 - 192.168.0.0/16 - 198.18.0.0/15 - 198.51.100.0/24 - 203.0.113.0/24 - 224.0.0.0/4 - 240.0.0.0/4 - 255.255.255.255/32 domain: - \u0026#34;+.google.com\u0026#34; - \u0026#34;+.facebook.com\u0026#34; - \u0026#34;+.youtube.com\u0026#34; - \u0026#34;+.githubusercontent.com\u0026#34; - \u0026#34;+.googlevideo.com\u0026#34; - \u0026#34;+.msftconnecttest.com\u0026#34; - \u0026#34;+.msftncsi.com\u0026#34; fake-ip-filter: - \u0026#34;+.*\u0026#34; subconverter转换规则 制作自己的 subconverter 转换配置，新建 /var/www/html/convert_rule.ini ，详细的格式见 subconverter外部配置，在 这里 有大量的参考文件。\n下面是我的 /var/www/html/convert_rule.ini，不要照抄，抄了也用不了。还是需要按照上一段提及的材料自行准备适合自己的。注意到我们自己形成了 ruleset=🎶 网易音乐,http://10.0.0.2/clash/neteasemusic.list，用 (^(?!.*网易).*) 在常规节点中排除了我们自建的 UnblockNeteaseMusic 节点，以及设置了专门的分组 custom_proxy_group=🎶 网易音乐，这都是为解锁网易云音乐服务的。另外，还要注意到我们在这个文件中使用 clash_rule_base=http://10.0.0.2/config_template.yaml 来引用了前一步创建的 clash 配置模板。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 [custom] ;设置规则标志位 ruleset=🎯 全球直连,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/LocalAreaNetwork.list ruleset=🎯 全球直连,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/UnBan.list ruleset=⚓ PT站点,http://10.0.0.2/pt.list ruleset=🗺 直连网站,http://10.0.0.2/direct.list ruleset=🌎 强制代理,http://10.0.0.2/proxy.list ruleset=📢 谷歌FCM,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/GoogleFCM.list ruleset=🎯 全球直连,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/GoogleCN.list ruleset=🎯 全球直连,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/SteamCN.list ruleset=Ⓜ️ 微软云盘,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/OneDrive.list ruleset=Ⓜ️ 微软服务,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Microsoft.list ruleset=🍎 苹果服务,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Apple.list ruleset=📲 电报消息,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Telegram.list ruleset=💬 OpenAi,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/OpenAi.list ruleset=🎶 网易音乐,http://10.0.0.2/neteasemusic.list ruleset=🎮 游戏平台,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/Epic.list ruleset=🎮 游戏平台,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/Origin.list ruleset=🎮 游戏平台,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/Sony.list ruleset=🎮 游戏平台,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/Steam.list ruleset=🎮 游戏平台,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/Nintendo.list ruleset=📹 油管视频,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/YouTube.list ruleset=📺 哔哩哔哩,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/BilibiliHMT.list ruleset=📺 哔哩哔哩,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/Ruleset/Bilibili.list ruleset=🌏 国内媒体,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/ChinaMedia.list ruleset=🌍 国外媒体,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/ProxyMedia.list ruleset=🚀 节点选择,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/ProxyGFWlist.list ruleset=🎯 全球直连,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/ChinaDomain.list ruleset=🎯 全球直连,https://raw.githubusercontent.com/ACL4SSR/ACL4SSR/master/Clash/ChinaCompanyIp.list ruleset=🎯 全球直连,[]GEOIP,CN ruleset=🐟 漏网之鱼,[]FINAL ;设置规则标志位 ;设置分组标志位 custom_proxy_group=🚀 节点选择`select`[]♻️ 自动选择`[]🔯 故障转移`[]🔮 负载均衡`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换`[]DIRECT custom_proxy_group=🚀 手动切换`select`(^(?!.*网易).*) custom_proxy_group=♻️ 自动选择`url-test`(^(?!.*网易).*)`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=🔯 故障转移`fallback`(^(?!.*网易).*)`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=🔮 负载均衡`load-balance`(^(?!.*网易).*)`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=⚓ PT站点`select`[]🚀 节点选择`[]♻️ 自动选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换`[]DIRECT custom_proxy_group=🗺 直连网站`select`[]DIRECT`[]🚀 节点选择`[]♻️ 自动选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换 custom_proxy_group=🌎 强制代理`select`[]🚀 节点选择`[]♻️ 自动选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换`[]DIRECT custom_proxy_group=📲 电报消息`select`[]🚀 节点选择`[]♻️ 自动选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换`[]DIRECT custom_proxy_group=💬 OpenAi`select`[]🚀 节点选择`[]♻️ 自动选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换`[]DIRECT custom_proxy_group=📹 油管视频`select`[]🚀 节点选择`[]♻️ 自动选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换`[]DIRECT custom_proxy_group=📺 哔哩哔哩`select`[]🎯 全球直连`[]🇨🇳 台湾节点`[]🇭🇰 香港节点 custom_proxy_group=🌍 国外媒体`select`[]🚀 节点选择`[]♻️ 自动选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`🏴‍☠️ 其他节点`[]🚀 手动切换`[]DIRECT custom_proxy_group=🌏 国内媒体`select`[]DIRECT`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🚀 手动切换 custom_proxy_group=📢 谷歌FCM`select`[]DIRECT`[]🚀 节点选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换 custom_proxy_group=Ⓜ️ 微软云盘`select`[]DIRECT`[]🚀 节点选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换 custom_proxy_group=Ⓜ️ 微软服务`select`[]DIRECT`[]🚀 节点选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换 custom_proxy_group=🍎 苹果服务`select`[]DIRECT`[]🚀 节点选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换 custom_proxy_group=🎮 游戏平台`select`[]DIRECT`[]🚀 节点选择`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换 custom_proxy_group=🎶 网易音乐`select`网易`[]DIRECT custom_proxy_group=🎯 全球直连`select`[]DIRECT`[]🚀 节点选择`[]♻️ 自动选择 custom_proxy_group=🐟 漏网之鱼`select`[]🚀 节点选择`[]♻️ 自动选择`[]DIRECT`[]🇭🇰 香港节点`[]🏴‍☠️ 除香港外`[]🇨🇳 台湾节点`[]🇸🇬 狮城节点`[]🇯🇵 日本节点`[]🇺🇲 美国节点`[]🇰🇷 韩国节点`[]🏴‍☠️ 其他节点`[]🚀 手动切换 custom_proxy_group=🇭🇰 香港节点`url-test`(^(?!.*10x).*(港|HK|Hong Kong))`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=🏴‍☠️ 除香港外`url-test`(^(?!.*(懒人|香港|网易)).*)`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=🇯🇵 日本节点`url-test`(^(?!.*10x).*(日本|川日|东京|大阪|泉日|埼玉|沪日|深日|[^-]日|JP|Japan))`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=🇺🇲 美国节点`url-test`(美|波特兰|达拉斯|俄勒冈|凤凰城|费利蒙|硅谷|拉斯维加斯|洛杉矶|圣何塞|圣克拉拉|西雅图|芝加哥|US|United States)`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=🇨🇳 台湾节点`url-test`(台|新北|彰化|TW|Taiwan)`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=🇸🇬 狮城节点`url-test`(^(?!.*10x).*(新加坡|坡|狮城|SG|Singapore))`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=🇰🇷 韩国节点`url-test`(KR|Korea|KOR|首尔|韩|韓)`https://cp.cloudflare.com/generate_204`180,,10 custom_proxy_group=🏴‍☠️ 其他节点`url-test`(^(?!.*(懒人|香港|台湾|新加坡|韩国|美国|日本|网易)).*)`https://cp.cloudflare.com/generate_204`180,,10 ;设置分组标志位 enable_rule_generator=true overwrite_original_rules=true clash_rule_base=http://10.0.0.2/config_template.yaml ;Options for renaming nodes rename=印尼@印度尼西亚 rename=澳洲@澳大利亚 rename=迪拜@阿联酋 ;Options for adding emojis add_emoji=true remove_old_emoji=true ;emoji=(流量|时间|应急),🏳️‍🌈 emoji=香港,🇭🇰 emoji=澳门,🇲🇴 emoji=台湾,🇨🇳 emoji=日本,🇯🇵 emoji=韩国,🇰🇷 emoji=美国,🇺🇸 emoji=英国,🇬🇧 emoji=泰国,🇹🇭 emoji=法国,🇫🇷 emoji=德国,🇩🇪 emoji=巴西,🇧🇷 emoji=(^(?!.*尼).*印度),🇮🇳 emoji=荷兰,🇳🇱 emoji=南非,🇿🇦 emoji=智利,🇨🇱 emoji=丹麦,🇩🇰 emoji=伊朗,🇮🇷 emoji=越南,🇻🇳 emoji=瑞士,🇨🇭 emoji=捷克,🇨🇿 emoji=芬兰,🇫🇮 emoji=挪威,🇲🇽 emoji=瑞典,🇸🇪 emoji=新加坡,🇸🇬 emoji=俄罗斯,🇷🇺 emoji=阿根廷,🇦🇷 emoji=土耳其,🇹🇷 emoji=菲律宾,🇵🇭 emoji=比利时,🇧🇪 emoji=卢森堡,🇱🇺 emoji=阿联酋,🇦🇪 emoji=加拿大,🇨🇦 emoji=意大利,🇮🇹 emoji=爱尔兰,🇮🇪 emoji=奥地利,🇦🇹 emoji=孟加拉,🇧🇩 emoji=柬埔寨,🇰🇭 emoji=哈萨克,🇰🇿 emoji=墨西哥,🇲🇽 emoji=新西兰,🇳🇿 emoji=葡萄牙,🇵🇹 emoji=西班牙,🇪🇸 emoji=乌克兰,🇺🇦 emoji=罗马尼亚,🇷🇴 emoji=巴基斯坦,🇵🇰 emoji=马来西亚,🇲🇾 emoji=(澳洲|澳大利亚),🇦🇺 emoji=(印尼|印度尼西亚),🇮🇩 emoji=懒人,🦥 emoji=网易,🎶 ;用于包含或排除节点关键词的选项 会覆盖 主程序目录中的配置文件 里的内容 ;include_remarks= exclude_remarks=越南|南非|到期|流量|重置 ;在 header 里的加入流量信息 append_sub_userinfo=true 网易云音乐域名与IP规则 在 subconverter转换配置 中，我们引用了 http://10.0.0.2/neteasemusic.list，现在我们对它初始化。新建 /var/www/html/neteasemusic.list，内容如下，接下来我们会用脚本自动更新它。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 DOMAIN-SUFFIX,music.163.com DOMAIN-SUFFIX,music.163.com.163jiasu.com IP-CIDR,39.105.63.80/32,no-resolve IP-CIDR,39.105.175.128/32,no-resolve IP-CIDR,45.127.129.53/32,no-resolve IP-CIDR,47.100.127.239/32,no-resolve IP-CIDR,59.111.19.33/32,no-resolve IP-CIDR,59.111.19.99/32,no-resolve IP-CIDR,59.111.160.195/32,no-resolve IP-CIDR,112.47.51.30/32,no-resolve IP-CIDR,114.80.149.72/30,no-resolve IP-CIDR,115.238.119.67/32,no-resolve IP-CIDR,115.238.119.68/31,no-resolve IP-CIDR,118.24.63.156/32,no-resolve IP-CIDR,121.228.190.68/30,no-resolve IP-CIDR,122.225.83.106/32,no-resolve IP-CIDR,122.225.83.109/32,no-resolve IP-CIDR,122.225.83.110/32,no-resolve IP-CIDR,180.163.200.96/30,no-resolve IP-CIDR,182.92.170.253/32,no-resolve IP-CIDR,183.134.34.248/31,no-resolve IP-CIDR,183.136.182.18/31,no-resolve IP-CIDR,183.136.182.20/32,no-resolve IP-CIDR,193.112.159.225/32,no-resolve 网易云音乐的代理配置 在 前文（五） 中我们手动设置了网易云音乐的代理，现在我们为接下来的自动订阅创建一个文件：/var/www/html/neteasemusic.yaml，内容如下：\n1 2 3 4 5 proxies: - name: \u0026#34;🎶 网易代理\u0026#34; server: 10.0.0.2 port: 8080 type: http 工具准备 后面的脚本中还要用到两个工具。下载 v2dat 保存为 /usr/local/bin/v2dat，下载 cidr-merger 保存为 /usr/local/bin/cidr-merger。\n然后为它们增加可执行权限：\n1 chmod +x /usr/local/bin/{v2dat,cidr-merger} 感谢以下仓库：\nhttps://github.com/urlesistiana/v2dat\nhttps://github.com/zhanhb/cidr-merger\nhttps://github.com/sbwml/luci-app-mosdns\n自动脚本 为了自动备份旧的订阅文件，防止出错，我们使用将 /var/lib/clash/config.yaml 软连接到 /var/lib/clash/config/subscribes_name1.yaml（ subscribes_name1 由你自行定义，请和下文的脚本中的命名保持一致）。后续脚本中会自动删除超过30天的旧订阅。\n1 2 3 4 cd /var/lib/clash mkdir config cp config.yaml config/subscribes_name1.yaml ln -sf config/subscribes_name1.yaml config.yaml 如果未来需要在多份订阅中切换，直接更新软连接即可：\n1 2 cd /var/lib/clash ln -sf config/subscribes_name2.yaml config.yaml 然后新建一个文件 /usr/local/bin/update-config.sh 如下，并按照注释修改。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 #!/usr/bin/env bash ## 订阅相关信息，subscribes_name和subscribes_url一一对应，如果想要合并多个订阅为一份，使用 | 分隔，比如示例中第3个。同时这两个数组的元素个数必须一致。 subscribes_name=( subscribes_name1.yaml subscribes_name2.yaml subscribes_merge.yaml ) subscribes_url=( \u0026#34;https://api.clashsubscribes.icu/clashudp/1111/125adfqeradf/\u0026#34; \u0026#34;https://v3.clashsubscribes.xyz/api/v1/client/subscribe?token=abcdefjagadfqaer456\u0026#34; \u0026#34;https://api.clashsubscribes.icu/clashudp/1111/125adfqeradf/|https://v3.clashsubscribes.xyz/api/v1/client/subscribe?token=abcdefjagadfqaer456\u0026#34; ) ## 订阅设置 subconverter_target=\u0026#34;clash\u0026#34; # 转换目标 subconverter_url=\u0026#34;http://10.0.0.2:25500/sub\u0026#34; # subconverer的api接口 subconverter_nem=\u0026#34;http://10.0.0.2/neteasemusic.yaml\u0026#34; # 前面生成的neteasemusic.yaml的下载网址 subconverter_rule=\u0026#34;http://10.0.0.2/convert_rule.ini\u0026#34; # 前面生成的convert_rule.ini的下载网址 ## 路径 dir_clash_work=\u0026#34;/var/lib/clash\u0026#34; # clash的工作路径 dir_xd=$dir_clash_work/ui/xd # clash的XD面板相关文件的保存目录 dir_mosdns_geodata=\u0026#34;/var/lib/mosdns/geodata\u0026#34; # mosdns用到的geodata相关数据的保存目录，在mosdns配置文件中定义的 list_nem=\u0026#34;/var/www/html/neteasemusic.list\u0026#34; # neteasemusic.list的路径 nem_address=nem_address.nft # 前文中在/var/lib/clash下的clash需要用到的网易云音乐IP地址，服务clash的nftables规则用 geoip4_cn=geoip4_cn.nft # 前文中在/var/lib/clash下的clash需要用到的中国大陆IP地址，服务clash的nftables规则用 ############ 以下内容建议不要修改 ############ ## geodata相关 geodata=( geoip.dat geosite.dat ) geodata_url=( https://github.com/MetaCubeX/meta-rules-dat/releases/download/latest/geoip.dat https://github.com/MetaCubeX/meta-rules-dat/releases/download/latest/geosite.dat ) geodata_txt=( \u0026#39;geoip_cn.txt\u0026#39; \u0026#39;geosite_cn.txt\u0026#39; \u0026#39;geosite_geolocation-!cn.txt\u0026#39; ) ## 订阅相关信息 subscribes_current=$(readlink $dir_clash_work/config.yaml) # 当前所使用的配置，是个软连接 ## 是否重启的标记 mark_mosdns_restart=no mark_clash_restart=no ## 在clash工作目录下运行本脚本 cd \u0026#34;$dir_clash_work\u0026#34; ## url转换 urlencode() { while read -n1 v; do case $v in [a-zA-Z0-9.~_-]) printf \u0026#34;%s\u0026#34; \u0026#34;$v\u0026#34;;; *) printf \u0026#34;%%%02X\u0026#34; \u0026#34;\u0026#39;$v\u0026#34;;; esac done printf \u0026#39;\\n\u0026#39; } ## 计算sha256 gen_sha256sum() { local file=\u0026#34;$1\u0026#34; local sha if [[ -f \u0026#34;$file\u0026#34; ]]; then sha=$(sha256sum \u0026#34;$file\u0026#34; | awk \u0026#39;{print $1}\u0026#39;) elif [[ \u0026#34;$file\u0026#34; == \u0026#34;http\u0026#34;* ]]; then sha=$(curl -fsSL \u0026#34;$file\u0026#34; 2\u0026gt;/dev/null | awk \u0026#39;{print $1}\u0026#39;) fi if [[ -n $sha ]]; then echo $sha fi } ## 更新geodata和nftables规则 update_geodata() { local i txt local tmp_geodir=/tmp/geodata local mmdb=country.mmdb if [[ ! -d $tmp_geodir ]]; then mkdir $tmp_geodir fi ## 更新 country.mmdb echo \u0026#34;开始更新 $mmdb ...\u0026#34; if wget -q --progress=bar:dot --show-progress -O \u0026#34;$tmp_geodir/$mmdb\u0026#34; https://github.com/MetaCubeX/meta-rules-dat/releases/download/latest/$mmdb; then if [[ $(gen_sha256sum \u0026#34;$mmdb\u0026#34;) != $(gen_sha256sum \u0026#34;$tmp_geodir/$mmdb\u0026#34;) ]]; then cp -f \u0026#34;$tmp_geodir/$mmdb\u0026#34; \u0026#34;$mmdb\u0026#34; echo \u0026#34;更新数据 $mmdb 成功...\u0026#34; else echo \u0026#34;$mmdb 无变化，不更新...\u0026#34; fi else echo \u0026#34;更新数据 $mmdb 失败...\u0026#34; fi ## 更新 geodata for ((i=0; i\u0026lt;${#geodata[@]}; i++)); do local sha256sum_new=$(gen_sha256sum \u0026#34;${geodata_url[i]}.sha256sum\u0026#34;) echo \u0026#34;开始更新 ${geodata[i]} ...\u0026#34; if [[ -n \u0026#34;$sha256sum_new\u0026#34; \u0026amp;\u0026amp; \u0026#34;$sha256sum_new\u0026#34; != $(gen_sha256sum ${geodata[i]}) ]]; then if wget -q --progress=bar:dot --show-progress -O \u0026#34;$tmp_geodir/${geodata[i]}\u0026#34; \u0026#34;${geodata_url[i]}\u0026#34;; then if [[ \u0026#34;$sha256sum_new\u0026#34; == $(gen_sha256sum \u0026#34;$tmp_geodir/${geodata[i]}\u0026#34;) ]]; then cp -f \u0026#34;$tmp_geodir/${geodata[i]}\u0026#34; \u0026#34;${geodata[i]}\u0026#34; echo \u0026#34;更新数据 ${geodata[i]} 成功...\u0026#34; mark_clash_restart=yes # 重启clash fi else echo \u0026#34;更新数据 ${geodata[i]} 失败...\u0026#34; fi else echo \u0026#34;${geodata[i]} 无变化，不更新...\u0026#34; fi done ## 解包geodata if [[ $mark_clash_restart == yes ]]; then echo \u0026#34;geo 数据有变化，开始重新生成相关文件...\u0026#34; ## 为mosdns重新生成geoip_cn.txt，geosite_cn.txt，geosite_geolocation-!cn.txt echo \u0026#34;开始解包 geoip.dat 到临时目录 $tmp_geodir...\u0026#34; v2dat unpack geoip -o \u0026#34;$tmp_geodir\u0026#34; -f cn geoip.dat echo \u0026#34;开始解包 geosite.dat 到临时目录 $tmp_geodir...\u0026#34; v2dat unpack geosite -o \u0026#34;$tmp_geodir\u0026#34; -f cn -f \u0026#39;geolocation-!cn\u0026#39; geosite.dat for txt in ${geodata_txt[@]}; do if [[ $(gen_sha256sum \u0026#34;$dir_mosdns_geodata/$txt\u0026#34;) != $(gen_sha256sum \u0026#34;$tmp_geodir/$txt\u0026#34;) ]]; then echo \u0026#34;检测到 $txt 内容有变化，从 $tmp_geodir/$txt 复制到 $dir_mosdns_geodata/$txt ...\u0026#34; cp -f \u0026#34;$tmp_geodir/$txt\u0026#34; \u0026#34;$dir_mosdns_geodata/$txt\u0026#34; mark_mosdns_restart=yes else echo \u0026#34;$txt 内容无变化，不更新...\u0026#34; fi done ## 为clash重新生成geoip4_cn.nft echo \u0026#34;define geoip4_cn = {\u0026#34; \u0026gt; $tmp_geodir/$geoip4_cn cat \u0026#34;$tmp_geodir\u0026#34;/geoip_cn.txt | sed \u0026#39;/:/d\u0026#39; | perl -pe \u0026#34;{s|^| |; s|$|,|}\u0026#34; \u0026gt;\u0026gt; \u0026#34;$tmp_geodir\u0026#34;/$geoip4_cn echo \u0026#34;}\u0026#34; \u0026gt;\u0026gt; \u0026#34;$tmp_geodir\u0026#34;/$geoip4_cn if [[ -n $(grep -oP \u0026#34;(\\d{1,3}\\.){3}\\d{1,3}\u0026#34; \u0026#34;$tmp_geodir\u0026#34;/$geoip4_cn) \u0026amp;\u0026amp; $(gen_sha256sum $geoip4_cn) != $(gen_sha256sum \u0026#34;$tmp_geodir/$geoip4_cn\u0026#34;) ]]; then cp -f \u0026#34;$tmp_geodir\u0026#34;/$geoip4_cn $geoip4_cn echo \u0026#34;更新数据 $geoip4_cn 成功...\u0026#34; fi else echo \u0026#34;geo 数据无变化，无需解包 ${geodata_txt[@]}，无需更新 $geoip4_cn ...\u0026#34; fi ## 为clash重新生成nem_address.nft和neteasemusic.list local domain_nem=\u0026#34;music.163.com,interface.music.163.com,interface3.music.163.com,apm.music.163.com,apm3.music.163.com,clientlog.music.163.com,clientlog3.music.163.com\u0026#34; local nemip=$(wget --timeout=5 -qO- \u0026#34;http://httpdns.n.netease.com/httpdns/v2/d?domain=$domain_nem\u0026#34; | jq -r .data[].ip | grep -v null | jq -r .[] | cidr-merger --range) nemip=$( (cat $nem_address | grep -oP \u0026#34;(\\d{1,3}\\.){3}\\d{1,3}(-(\\d{1,3}\\.){3}\\d{1,3})?\u0026#34;; cat $list_nem | grep -oP \u0026#34;(\\d{1,3}\\.){3}\\d{1,3}/\\d+\u0026#34;; echo \u0026#34;$nemip\u0026#34;) | cidr-merger --range) if [[ -n \u0026#34;$nemip\u0026#34; ]]; then echo \u0026#34;define nem_address = {\u0026#34; \u0026gt; $tmp_geodir/$nem_address echo \u0026#34;$nemip\u0026#34; | perl -pe \u0026#34;{s|^| |; s|$|,|}\u0026#34; \u0026gt;\u0026gt; \u0026#34;$tmp_geodir\u0026#34;/$nem_address echo \u0026#34;}\u0026#34; \u0026gt;\u0026gt; \u0026#34;$tmp_geodir\u0026#34;/$nem_address if [[ -n $(grep -oP \u0026#34;(\\d{1,3}\\.){3}\\d{1,3}\u0026#34; \u0026#34;$tmp_geodir\u0026#34;/$nem_address) \u0026amp;\u0026amp; $(gen_sha256sum $nem_address) != $(gen_sha256sum \u0026#34;$tmp_geodir/$nem_address\u0026#34;) ]]; then cp -f \u0026#34;$tmp_geodir\u0026#34;/$nem_address $nem_address echo \u0026#34;更新数据 $nem_address 成功...\u0026#34; mark_clash_restart=yes # 重启clash else echo \u0026#34;$nem_address 内容无变化，不更新...\u0026#34; fi fi cp -f $list_nem \u0026#34;$tmp_geodir/${list_nem##*/}\u0026#34; sed -i \u0026#34;/IP-CIDR/d\u0026#34; \u0026#34;$tmp_geodir/${list_nem##*/}\u0026#34; echo \u0026#34;$nemip\u0026#34; | cidr-merger -s | perl -pe \u0026#34;{s|^|IP-CIDR,|; s|$|,no-resolve|}\u0026#34; \u0026gt;\u0026gt; \u0026#34;$tmp_geodir/${list_nem##*/}\u0026#34; if [[ $(gen_sha256sum \u0026#34;$tmp_geodir/${list_nem##*/}\u0026#34;) != $(gen_sha256sum \u0026#34;$list_nem\u0026#34;) ]]; then cp -f \u0026#34;$tmp_geodir/${list_nem##*/}\u0026#34; $list_nem echo \u0026#34;更新数据 ${list_nem##*/} 成功...\u0026#34; else echo \u0026#34;${list_nem##*/} 内容无变化，不更新...\u0026#34; fi } ## 检测proxies:和proxy-groups:之间的行差，$1: 文件路径 diff_detect() { local yaml=\u0026#34;$1\u0026#34; local line1=$(grep -nP \u0026#34;^proxies:\u0026#34; $yaml | awk -F: \u0026#39;{print $1}\u0026#39;) local line2=$(grep -nP \u0026#34;^proxy-groups:\u0026#34; $yaml | awk -F: \u0026#39;{print $1}\u0026#39;) local diff=$(( $line2 - $line1 )) 2\u0026gt;/dev/null if [[ -n $diff ]]; then echo $diff else echo 0 fi } ## 更新订阅 update_subscribes() { ## 更新订阅 local i sha256sum_old sha256sum_new url config local dir_tmpsubscribes=/tmp/clash if [[ ! -d $dir_tmpsubscribes ]]; then mkdir $dir_tmpsubscribes fi for ((i=0; i\u0026lt;${#subscribes_name[@]}; i++)); do echo \u0026#34;开始更新订阅 ${subscribes_name[i]} ...\u0026#34; url=$(echo -n \u0026#34;${subscribes_url[i]}|${subconverter_nem}\u0026#34; | urlencode) config=$(echo -n ${subconverter_rule} | urlencode) subscribes_tmpconfig=\u0026#34;$dir_tmpsubscribes/${subscribes_name[i]}\u0026#34; if wget -q -O \u0026#34;$subscribes_tmpconfig\u0026#34; \u0026#34;${subconverter_url}?target=${subconverter_target}\u0026amp;url=${url}\u0026amp;config=${config}\u0026#34;; then sha256sum_old=$(gen_sha256sum \u0026#34;config/${subscribes_name[i]}\u0026#34;) sha256sum_new=$(gen_sha256sum \u0026#34;$subscribes_tmpconfig\u0026#34;) if [[ $(diff_detect \u0026#34;$subscribes_tmpconfig\u0026#34;) -gt 2 \u0026amp;\u0026amp; $sha256sum_old != $sha256sum_new ]]; then if clash -t -d . -f \u0026#34;$subscribes_tmpconfig\u0026#34;; then cp -a \u0026#34;config/${subscribes_name[i]}\u0026#34; \u0026#34;config/${subscribes_name[i]}.$(date +\u0026#39;%s\u0026#39;)\u0026#34; cp -f \u0026#34;$subscribes_tmpconfig\u0026#34; \u0026#34;config/${subscribes_name[i]}\u0026#34; echo \u0026#34;更新订阅 ${subscribes_name[i]} 成功...\u0026#34; if [[ \u0026#34;config/${subscribes_name[i]}\u0026#34; == \u0026#34;$subscribes_current\u0026#34; ]]; then mark_clash_restart=yes # 重启clash fi else echo \u0026#34;订阅 ${subscribes_name[i]} 校验失败，不更新...\u0026#34; fi else echo \u0026#34;订阅 ${subscribes_name[i]} 无变化，不更新...\u0026#34; fi else echo \u0026#34;订阅 ${subscribes_name[i]} 下载失败...\u0026#34; fi done ## 删除超过30天的旧订阅 for yaml in $(ls config/*.yaml.* 2\u0026gt;/dev/null); do if [[ $(( $(date +%s) - ${yaml##*.} )) -gt 2592000 ]]; then rm -v \u0026#34;$yaml\u0026#34; fi done } ## 更新clash的XD面板 update_xd() { if [[ ! -d ${dir_xd} ]]; then mkdir -p ${dir_xd} fi cd ${dir_xd} echo \u0026#34;开始更新 clash 面板 XD ...\u0026#34; if [[ -n $(ls) \u0026amp;\u0026amp; ! -d .git ]] || [[ -z $(ls) ]]; then rm -rf * .* \u0026amp;\u0026gt;/dev/null git clone -b gh-pages --depth 1 https://github.com/MetaCubeX/metacubexd . elif [[ -n $(ls) \u0026amp;\u0026amp; -d .git ]]; then git fetch git reset origin/gh-pages --hard git pull fi } ## 重启服务 restart_service() { if [[ $mark_clash_restart == yes ]]; then systemctl restart clash.service # 也可以改成重新加载配置而非重启：curl -Ss -H \u0026#34;Authorization: Bearer YOUR_CLASH_SECRET\u0026#34; -X PUT -d \u0026#39;{\u0026#34;path\u0026#34;: \u0026#34;/var/lib/clash/config.yaml\u0026#34;}\u0026#39; \u0026#34;http://127.0.0.1:9090/configs?force=true\u0026#34; echo \u0026#34;重启 clash.service\u0026#34; fi if [[ $mark_mosdns_restart == yes ]]; then systemctl restart mosdns.service echo \u0026#34;重启 mosdns.service\u0026#34; fi } ## 中止时删除临时文件 finish() { rm -rf /tmp/{clash,geodata} \u0026amp;\u0026gt;/dev/null } ## 调用和函数 main() { trap finish EXIT update_geodata update_subscribes update_xd restart_service } main \u0026#34;$@\u0026#34; 为其增加可执行权限：\n1 chmod +x /usr/local/bin/update-config.sh 然后运行一下：\n1 update-config.sh 如果有报错，请在报错前行添加 set +x，在后行添加 set -x 后，再次运行，根据输出信息自行排故。这需要你有一点点的 shell 知识。\n建议将 update-config.sh 加入定时任务，请自行调整下执行时间：\n1 echo -e \u0026#34;SHELL=/bin/bash\\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\n19 1 * * * update-config.sh \u0026gt;/dev/null\u0026#34; | crontab - 最后 脚本运行没问题后，更新完全部所需文件，那么再回过头去把前面没有启动的服务全部启动起来吧。至此，基本的科学上网服务已配置完毕，在 本系列 接下来的文章中，将继续配置其他服务。\n系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-22T03:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%B8%83/cover_hu12437125556482584613.png","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%B8%83/","title":"我的家庭网络设计思路，开启debian的旁路由之路（七）"},{"content":"前言 clash 需要用到订阅转换，直接用网上的服务肯定不太安全，并且我们还需要自动在配置文件中插入本地自建的 UnblockNeteaseMusic 代理服务，所以我们采取自建格式转换服务。\n下载与安装 我默认你已经按照 前文（二） 安装好了必要的软件了。以下为root用户运行的命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## 检查最新稳定版的版本号，如果获取不到请检查网络 remote_ver=$(curl -sS https://api.github.com/repos/tindy2013/subconverter/releases/latest | jq -r .tag_name | sed \u0026#39;s|v||\u0026#39; | grep -v \u0026#34;null\u0026#34;); echo $remote_ver ## 下载最新稳定版（前一句有输出这一句才能正常执行） mkdir /tmp/subconverter cd /tmp/subconverter wget -q --progress=bar:dot --show-progress -O \u0026#34;subconverter_linux64.tar.gz\u0026#34; \u0026#34;https://github.com/tindy2013/subconverter/releases/download/v${remote_ver}/subconverter_linux64.tar.gz\u0026#34; ## 解压 tar --no-same-owner -xf \u0026#34;subconverter_linux64.tar.gz\u0026#34; --strip-components 1 --directory=. ## 安装 mkdir -p /var/lib/subconverter install -ps subconverter /usr/local/bin/subconverter rm -rf subconverter subconverter_linux64.tar.gz cp -afr * /var/lib/subconverter/ 创建服务 subconverter.service 创建文件 /etc/systemd/system/subconverter.service，内容如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 [Unit] Description = Utility to convert between various subscription format. After = network.target [Service] Environment = PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin Type = simple Restart = always WorkingDirectory = /var/lib/subconverter ExecStart = subconverter [Install] WantedBy = multi-user.target 如果不想以root用户运行 subconverter ，可以自行创建用户 subconverter 和用户组 subconverter ，然后在 /etc/systemd/system/subconverter.service 的 [Service] 单元下增加下面两行，同时修改 /var/lib/subconverter 及其子文件为该普通用户所有。（后续的脚本都是以root用户为运行用户进行的，如果要把 subconverter 服务调整为普通用户运行，请自行修改脚本）。\n1 2 User = subconverter Group = subconverter subconverter的配置文件 如果想要自定义，可以将 /var/lib/subconverter/pref.example.toml 复制一份为 /var/lib/subconverter/pref.toml，然后编辑复制后的文件即可，具体可参考 官方README。\n启用服务 完全配置好以后，我们可以设置 /etc/systemd/system/subconverter.service 为开启自动启动，并立即启动起来。\n1 systemctl enable --now subconverter.service 后续如想查看日志，我们直接使用Debian自带的工具来查看：\n1 journalctl -efu subconverter.service 如果想要重启：\n1 systemctl restart subconverter.service 系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-22T02:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%85%AD/cover_hu12437125556482584613.png","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%85%AD/","title":"我的家庭网络设计思路，开启debian的旁路由之路（六）"},{"content":"前言 我们继续趁热打铁，将UnblockNeteaseMusic也一起部署了，因为它也要用到 nftables 来实现。\n下载与安装 unblockneteasemusic 这个名称太长了，我们把它更名为 unblocknem。我默认你已经按照 前文（二） 安装好了必要的软件了。以下为root用户运行的命令。\n1 2 3 4 5 6 7 8 9 ## 检查最新稳定版的版本号，如果获取不到请检查网络 remote_ver=$(curl -sS https://api.github.com/repos/UnblockNeteaseMusic/server/releases/latest | jq -r .tag_name | sed \u0026#39;s|v||\u0026#39; | grep -v \u0026#34;null\u0026#34;); echo $remote_ver ## 下载最新稳定版（前一句有输出这一句才能正常执行） cd /tmp wget -q --progress=bar:dot --show-progress -O \u0026#34;unblockneteasemusic-linux-x64\u0026#34; \u0026#34;https://github.com/UnblockNeteaseMusic/server/releases/download/v${remote_ver}/unblockneteasemusic-linux-x64\u0026#34; ## 安装 install -p unblockneteasemusic-linux-x64 /usr/local/bin/unblocknem 创建服务 unblocknem.service 创建工作目录/var/lib/unblocknem。\n1 mkdir -p /var/lib/unblocknem 创建文件 /etc/systemd/system/unblocknem.service，内容如下。这时 clash 的配置文件为 /var/lib/unblocknem/unblocknem.env。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [Unit] Description = Revive unavailable songs for Netease Cloud Music (Refactored \u0026amp; Enhanced version). Wants = network-online.target clash.service After = network-online.target [Service] Type = simple Restart = always EnvironmentFile = -/var/lib/unblocknem/unblocknem.env WorkingDirectory = /var/lib/unblocknem ExecStart = /usr/local/bin/unblocknem RestartSec = 10 StartLimitInterval = 0 [Install] WantedBy = multi-user.target 如果你比较讲究Linux哲学，可以把 EnvironmentFile 改成下面这样，这时 unblocknem 的配置文件为 /etc/default/unblocknem。\n1 EnvironmentFile = -/etc/default/unblocknem 如果不想以root用户运行 unblocknem ，可以自行创建用户 unblocknem 和用户组 unblocknem ，然后在 /etc/systemd/system/unblocknem.service 的 [Service] 单元下增加下面两行，同时修改 /var/lib/unblocknem 及其子文件为该普通用户所有。（后续的脚本都是以root用户为运行用户进行的，如果要把 unblocknem 服务调整为普通用户运行，请自行修改脚本）。\n1 2 User = unblocknem Group = unblocknem 注意：由于各音源政策一直在变化，可能unblockneteasemusic默认的音源顺序（见官方README）无法使用，你可以查看unblocknem.service的运行日志来确认（方式见后文），这时需要你自己调整音源的顺序，也就是在ExecStart中增加-o参数，同时设置/etc/default/unblocknem中的FOLLOW_SOURCE_ORDER=true。ExecStart设置音源顺序举例如下：\n1 ExecStart = /usr/local/bin/unblocknem -o ytdlp bilibili 安装依赖 在 前文（二） 我们已经安装了UnblockNeteaseMusic的一个依赖项： yt-dlp，在实际运行中，部分情况下还需要另外一个依赖：phantomjs。这个软件已经多年没有更新过了。\n1 2 3 4 cd /tmp wget -q --progress=bar:dot --show-progress -O phantomjs-2.1.1-linux-x86_64.tar.bz2 https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2 tar --no-same-owner -xf phantomjs-2.1.1-linux-x86_64.tar.bz2 # 需要安装bzip2才能解压 install -p phantomjs-2.1.1-linux-x86_64/bin/phantomjs /usr/local/bin/phantomjs unblocknem 的配置文件 没有配置文件， unblocknem 也是可以以默认配置启动的。如有需要，可以新建 /var/lib/unblocknem/unblocknem.env 或 /etc/default/unblocknem，内容如下，请注意按照注释修改。全部环境变量详见 官方README。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 # 全部环境变量详见：https://github.com/UnblockNeteaseMusic/server # 激活无损音质获取 ENABLE_FLAC=true # 激活本地黑胶 VIP，可选值：true（等同于 CVIP）、cvip 和 svip ENABLE_LOCAL_VIP=svip # 仅对这些 UID 激活本地黑胶 VIP，默认为对全部用户生效 # LOCAL_VIP_UID=123456789,1234,123456 # 激活故障的 Netease HTTPDNS 查询（不建议） # ENABLE_HTTPDNS=true # 屏蔽应用内部分广告 BLOCK_ADS=true # 禁用更新检测 DISABLE_UPGRADE_CHECK=true # 激活开发模式。需要自己用 yarn 安装依赖 (dependencies) # DEVELOPMENT=true # 严格按照配置音源的顺序进行查询 # FOLLOW_SOURCE_ORDER=true # 输出机器可读的 JSON 记录格式 # JSON_LOG=true # 停用 cache # NO_CACHE=true # 允许的最低源音质，小于该值将被替换 # MIN_BR=320000 # 选择所有音源中的最高码率替换音频 SELECT_MAX_BR=true # 日志输出等级。请见〈日志等级〉部分 # LOG_LEVEL=debug # 从 Pino 端设置日志输出的文件位置。也可以用 *sh 的输出重导向功能 (node app.js \u0026gt;\u0026gt; app.log) 代替 # LOG_FILE=app.log # JOOX 音源的 wmid 和 session_key cookie # JOOX_COOKIE=\u0026#34;wmid=\u0026lt;your_wmid\u0026gt;; session_key=\u0026lt;your_session_key\u0026gt;\u0026#34; # 咪咕音源的 aversionid cookie # MIGU_COOKIE=\u0026#34;\u0026lt;your_aversionid\u0026gt;\u0026#34; # QQ 音源的 uin 和 qm_keyst cookie # QQ_COOKIE=\u0026#34;uin=123456789; qm_keyst=Q_H_L_6hTegBdoCzFj6bcUUpuhkOP11234ChsOkfKiOdvcIOFKiQQf4oGjykQ\u0026#34; # Youtube 音源的 Data API v3 Key # YOUTUBE_KEY=\u0026#34;Adjeuskn12xdEvQfLHnvfC12386QAApcOt5Kh1g\u0026#34; # 自定义证书文件 SIGN_CERT=\u0026#34;/var/lib/unblocknem/server.crt\u0026#34; # 自定义密钥文件 SIGN_KEY=\u0026#34;/var/lib/unblocknem/server.key\u0026#34; # 在其他音源搜索歌曲时携带专辑名称（默认搜索条件 歌曲名 - 歌手，启用后搜索条件 歌曲名 - 歌手 专辑名 # SEARCH_ALBUM=true 生成自己的证书 1 2 3 cd /var/lib/unblocknem wget https://raw.githubusercontent.com/UnblockNeteaseMusic/server/enhanced/generate-cert.sh env TYPE=\u0026#34;RSA\u0026#34; ISSUENAME=\u0026#34;Your Name\u0026#34; bash generate-cert.sh 脚本会在 /var/lib/unblocknem 目录下生成这些文件。如果你不以root用户来启动 unblocknem，则请注意修改它们的所有者。\n1 2 3 4 5 6 7 /var/lib/unblocknem ├── ca.crt ├── ca.key ├── ca.srl ├── server.crt ├── server.csr └── server.key 调整 nftables 规则 在 前文（四） 中我们为 clash 创建了一些 nftables 规则，现在我们多了 unblocknem，它也需要，所以我们要调整一下 前文（四） 中的 /usr/local/bin/mynftables.nft，调整为下面这个样子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 #!/usr/sbin/nft -f ## 清空旧规则 flush ruleset ## 只处理指定网卡的流量，要和ip规则中的接口操持一致 define interface = ens18 ## clash的透明代理端口 define tproxy_port = 7895 ## clash打的标记（routing-mark） define clash_mark = 666 ## 常规流量标记，ip rule中加的标记，要和ip规则中保持一致，对应 \u0026#34;ip rule add fwmark 1 lookup 100\u0026#34; 中的 \u0026#34;1\u0026#34; define default_mark = 1 ## 本机运行了服务并且需要在公网上访问的tcp端口（本机开放在公网上的端口），仅本地局域网访问的服务端口可不用在此变量中，以半角逗号分隔 define local_tcp_port = { 2222, # ssh，按需设置 8080-8088 # nginx webui，按需设置 } ## 要绕过的局域网内tcp流量经由本机访问的目标端口，也就是允许局域网内其他主机主动设置DNS服务器为其他服务器，而非旁路由 define lan_2_dport_tcp = { 53 # dns查询 } ## 要绕过的局域网内udp流量经由本机访问的目标端口，也就是允许局域网内其他主机主动设置DNS服务器为其他服务器，而非旁路由；另外也允许局域网内其他主机访问远程的NTP服务器 define lan_2_dport_udp = { 53, # dns查询 123 # ntp端口 } ## 保留ip地址 define private_address = { 127.0.0.0/8, 100.64.0.0/10, 169.254.0.0/16, 224.0.0.0/4, 240.0.0.0/4, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16 } ## 大陆ip地址 include \u0026#34;/var/lib/clash/geoip4_cn.nft\u0026#34; ## 网易云音乐ip地址 include \u0026#34;/var/lib/clash/nem_address.nft\u0026#34; table ip clash { ## 保留ipv4集合 set private_address_set { type ipv4_addr flags interval elements = $private_address } ## 网易云音乐ipv4集合 set nem_address_set { type ipv4_addr flags interval elements = $nem_address } ## 大陆ipv4集合 set geoip4_cn_set { type ipv4_addr flags interval elements = $geoip4_cn } ## prerouting链 chain prerouting { type filter hook prerouting priority filter; policy accept; ip protocol { tcp, udp } socket transparent 1 meta mark set $default_mark accept # 绕过已经建立的连接 meta mark $default_mark goto clash_tproxy # 已经打上default_mark标记的属于本机流量转过来的，直接进入透明代理 fib daddr type { local, broadcast, anycast, multicast } accept # 绕过本地、单播、组播、多播地址 tcp dport $lan_2_dport_tcp accept # 绕过经由本机到目标端口的tcp流量 udp dport $lan_2_dport_udp accept # 绕过经由本地到目标端口的udp流量 ip daddr @private_address_set accept # 绕过目标地址为保留ip的地址 ip daddr @nem_address_set goto clash_tproxy # 将网易云音乐的流量转发到透明代理 ip daddr @geoip4_cn_set accept # 绕过目标地址为大陆ip的地址 # ip protocol udp accept # 绕过全部udp流量（udp不进行透明代理） goto clash_tproxy # 其他流量透明代理到clash } ## 透明代理 chain clash_tproxy { ip protocol { tcp, udp } tproxy to :$tproxy_port meta mark set $default_mark } ## output链 chain output { type route hook output priority filter; policy accept; oifname != $interface accept # 绕过本机内部通信的流量（接口lo） meta mark $clash_mark accept # 绕过本机clash发出的流量 fib daddr type { local, broadcast, anycast, multicast } accept # 绕过本地、单播、组播、多播地址 udp dport { 53, 123 } accept # 绕过本机dns查询、NTP流量 tcp sport $local_tcp_port accept # 绕过本地运行了服务的tcp端口，如果并不需要从公网访问这些端口，可以注释掉本行 ip daddr @private_address_set accept # 绕过目标地址为保留ip的地址 ip daddr @geoip4_cn_set accept # 绕过目标地址为大陆ip的地址 ip protocol { tcp, udp } meta mark set $default_mark # 其他流量重路由到prerouting } } 注意到我们在第51行多引用了一个文件 /var/lib/clash/nem_address.nft （可先下载这个并非最新的文件到指定位置来将就一下：nem_address.nft，我们将在 本系列第（七）篇 用定时任务来自动更新这个文件），在第63-67行多形成了一个集合 nem_address_set，在第85行插入了一行规则 ip daddr @nem_address_set goto clash_tproxy，这条规则插入在 ip daddr @geoip4_cn_set accept 之前，表示虽然网易云音乐IP是中国大陆IP，但要在直接接收前转到透明代理并停止后续规则。现在的 prerouting 链内容有点多，其实可以一拆为三。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ## prerouting链 chain prerouting { type filter hook prerouting priority filter; policy accept; fib daddr type { local, broadcast, anycast, multicast } accept # 绕过本地、单播、组播、多播地址 tcp dport $lan_2_dport_tcp accept # 绕过经由本机到目标端口的tcp流量 udp dport $lan_2_dport_udp accept # 绕过经由本地到目标端口的udp流量 ip daddr @private_address_set accept # 绕过目标地址为保留ip的地址 ip daddr @geoip4_cn_set accept # 绕过目标地址为大陆ip的地址 # ip protocol udp accept # 绕过全部udp流量（udp不进行透明代理） goto clash_tproxy # 其他流量透明代理到clash } ## prerouting链绕过已经建立的连接，已经打上default_mark标记的属于本机流量转过来的，直接进入透明代理 chain divert { type filter hook prerouting priority mangle; policy accept; ip protocol { tcp, udp } socket transparent 1 meta mark set $default_mark accept meta mark $default_mark goto clash_tproxy } ## 局域网中访问网易云音乐的流量，第一次全部进行透明代理，优先级需要比绕过大陆ip先执行（mangle为-150，filter为0） chain neteasemusic { type filter hook prerouting priority dstnat; policy accept; ip daddr @nem_address_set goto clash_tproxy } 一拆为三后，新的 divert 链的优先级为 mangle （-150），新的neteasemusic 链的优先级为 dstnat (-100)，而新的 prerouting 链则仍是 filter （0），数值越小，优先级越高，所以 ip daddr @nem_address_set goto clash_tproxy 这条规则仍然早于 ip daddr @geoip4_cn_set accept 执行。这样也可以让网易云音乐IP在被直接接收前就转到透明代理去。\nunblocknem 工作在应用层，clash 转给它后，它出来的流量会经由 output 链中的 ip daddr @geoip4_cn_set accept 直接出去，不会形成环路（output 链并没有再劫持这部分流量）。这也就意味着上述规则只能代理局域网中除旁路由以外其他设备（以旁路由为网关的）的网易云音乐流量，不能代理旁路由自己的网易云音乐流量。\n设想一个这样的场景：unblocknem 设置了 ytdlp（Youtube）为劫持音源，那么局域网中以旁路由为网关的客户端A在播放灰色歌曲触发 unblocknem 时，流量是怎么运作的呢？\n对照前文（四）的题图，客户端A的流量先进入旁路由的 prerouting 链，按上述说明触发该链中的 ip daddr @nem_address_set goto clash_tproxy 规则将流量转向我们的 unblocknem HTTP代理，然后 unblocknem 代理会将流量劫持向Youtube，也就是说 unblocknem 会在旁路由中产生向Youtube的请求。前文已经说过，unblocknem 工作在应用层，它产生的流量会先进入 output 链。如果它请求的是国内的音源，那么将会由 output 链中 ip daddr @geoip4_cn_set accept 规则直接放行，而现在它请求的是Youtube需要走代理，所以流量会在 output 链中触发 ip protocol { tcp, udp } meta mark set $default_mark 这条规则，将其打上标记并重路由到 prerouting 链，然后按照前文（四）所说进行透明代理。也就是说，在这个假设场景下，客户端A在播放灰色歌曲时，流量经过了clash的两次透明代理。\n调整 clash 配置文件 我们后续将在 本系列第（七）篇 用定时任务来自动在 clash 的配置中自动插入下面这些内容。\n在 clash 的配置文件中 proxies: 部分新增：\n1 2 3 4 - name: 🎶 网易代理 server: 10.0.0.2 port: 8080 type: http proxy-groups: 部分新增：\n1 2 3 4 5 - name: 🎶 网易音乐 type: select proxies: - 🎶 网易代理 - DIRECT rules: 部分新增（各地IP可能是不一样的，我们将在 本系列第（七）篇 用定时任务来自动生成它，将其刷新为你本地的解析IP）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 - DOMAIN-SUFFIX,music.163.com,🎶 网易音乐 - DOMAIN-SUFFIX,music.163.com.163jiasu.com,🎶 网易音乐 - IP-CIDR,39.105.63.80/32,🎶 网易音乐,no-resolve - IP-CIDR,39.105.175.128/32,🎶 网易音乐,no-resolve - IP-CIDR,45.127.129.53/32,🎶 网易音乐,no-resolve - IP-CIDR,47.100.127.239/32,🎶 网易音乐,no-resolve - IP-CIDR,59.111.19.33/32,🎶 网易音乐,no-resolve - IP-CIDR,59.111.19.99/32,🎶 网易音乐,no-resolve - IP-CIDR,59.111.160.195/32,🎶 网易音乐,no-resolve - IP-CIDR,112.47.51.30/32,🎶 网易音乐,no-resolve - IP-CIDR,114.80.149.72/30,🎶 网易音乐,no-resolve - IP-CIDR,115.238.119.67/32,🎶 网易音乐,no-resolve - IP-CIDR,115.238.119.68/31,🎶 网易音乐,no-resolve - IP-CIDR,118.24.63.156/32,🎶 网易音乐,no-resolve - IP-CIDR,121.228.190.68/30,🎶 网易音乐,no-resolve - IP-CIDR,122.225.83.106/32,🎶 网易音乐,no-resolve - IP-CIDR,122.225.83.109/32,🎶 网易音乐,no-resolve - IP-CIDR,122.225.83.110/32,🎶 网易音乐,no-resolve - IP-CIDR,180.163.200.96/30,🎶 网易音乐,no-resolve - IP-CIDR,182.92.170.253/32,🎶 网易音乐,no-resolve - IP-CIDR,183.134.34.248/31,🎶 网易音乐,no-resolve - IP-CIDR,183.136.182.18/31,🎶 网易音乐,no-resolve - IP-CIDR,183.136.182.20/32,🎶 网易音乐,no-resolve - IP-CIDR,193.112.159.225/32,🎶 网易音乐,no-resolve 网易云音乐IP只允许解析IPv4 因为我们的透明代理只代理 IPv4 流量，所以我们不能让网易云音乐客户端解析出 IPv6 地址。有好几种方式可以实现，既可以在 mosdns 中实现，也可以在 adguardhome 中实现，但后者有 webui 要方便些，并且 adguardhome 是第一级，它有可能会切换到后备服务器而不向 mosdns 发起请求，所以我们就选后者吧。\n在 adguardhome 中实现也有两种方式，其一是将 “设置 -\u0026gt; DNS设置 -\u0026gt; 上游DNS服务器” 设置为下面这样（这种方式不会计入“被拦截域名”中，但是如若 adguardhome 在 clash 遇到故障会切换到后备，对后备是不生效的），直接将网易云音乐的解析发到 clash 去解析，因为我们关闭了 clash 的DNS模块的 IPv6 解析。\n1 2 127.0.0.1:5335 [/music.163.com/music.ntes53.netease.com/music.163.com.163jiasu.com/music.163.com.bsclink.cn/uz99.v.bsclink.cn/]127.0.0.1:7874 其二是在 “过滤器 -\u0026gt; 自定义过滤规则” 中添加规则如下（这种方式会计入“被拦截域名”中，但是对包括后备在内的全部上游DNS服务器都有效）。\n1 2 3 4 5 6 7 ||music.163.com^$dnstype=AAAA ||music.ntes53.netease.com^$dnstype=AAAA ||music.163.com.163jiasu.com^$dnstype=AAAA ||music.163.com.bsclink.cn^$dnstype=AAAA ||music.163.com.c.vedcdnlb.com^$dnstype=AAAA ||s.bdsa.cdnbuild.net^$dnstype=AAAA ||uz99.v.bsclink.cn^$dnstype=AAAA 只能保证目前有效。上述两种方式，都由于 CNAME 域名的存在，光处理 music.163.com 和 music.163.com.163jiasu.com 不行，还要处理它们背后的 CNAME 域名。可能有望在未来得以改进，详见 Hosts-Blocklists#dnstype。\n启用服务 完全配置好以后，我们可以设置 /etc/systemd/system/unblocknem.service 为开启自动启动，并立即启动起来。如果这个时候 clash 还没有启动起来，那么 unblocknem 服务就还不可用。都启动好后，unblocknem 将会监听在 8080 和 8081 端口上。\n1 systemctl enable --now unblocknem.service 后续如想查看日志，我们直接使用Debian自带的工具来查看：\n1 journalctl -efu unblocknem.service 如果想要重启：\n1 systemctl restart unblocknem.service 客户端 安卓系统不支持。\nWindows 安装网易云音乐客户端后，创建一个快捷方式，然后在该快捷方式的属性中的“目标”增加 --ignore-certificate-errors，注意有个空格。\nArchLinux系 将刚刚生成的 /var/lib/unblocknem/ca.crt 下载下来，然后运行：\n1 sudo trust anchor --store ca.crt 在启动命令行后面添加 --ignore-certificate-errors，然后启动即可。\nDebian系 将刚刚生成的 /var/lib/unblocknem/ca.crt 下载下来，放在 /usr/local/share/ca-certificates 下，然后运行：\n1 sudo update-ca-certificates 在启动命令行后面添加 --ignore-certificate-errors，然后启动即可。\n最后 打开 clash 的 webui：http://10.0.0.2:9090/ui/xd/#/proxies ，选择 网易音乐 为 网易代理；你再打开网易云音乐客户端后，在 http://10.0.0.2:9090/ui/xd/#/conns 就能看到许多连接都接管到 UnblockNeteaseMusic 了。\n从 unblocknem.service 的日志中也能看到它的作用，这些灰色歌曲都被接管了。\n系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-22T01:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%BA%94/nem2_hu8097916181066803298.png","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%BA%94/","title":"我的家庭网络设计思路，开启debian的旁路由之路（五）"},{"content":"前言 使用clash实现透明代理有两种方式，一种是 redirect，仅支持TCP流量，另一种是 tproxy，支持TCP和UDP流量。为了能代理UDP流量，所以我们选用 tproxy 的方式来实现。\n工作流 nftables 的工作流详见 Netfilter hooks。具体Netfilter的五个链 prerouting input forward output postrouting 是什么关系，以及流向，请参考该链接来加深理解。全部的文档可以查阅本文下方 参考资料 的1和2。\n注意，在旁路由自身中运行的程序都工作在应用层，而 tproxy 只能工作在 prerouting 链，所以如果我们要想透明代理旁路由自己产生的流量，要通过设置IP规则让这部分流量在进入 output 链时，将需要代理的流量转回到 prerouting 链。这就需要靠IP规则来实现。\n下载与安装 在 clash 和 clash-meta (现在叫mihomo)中，我选用后者来使用（前者已经删库了）。我默认你已经按照 前文（二） 安装好了必要的软件了。以下为root用户运行的命令。\n1 2 3 4 5 6 7 8 9 10 11 12 ## 检查最新稳定版的版本号，如果获取不到请检查网络 remote_ver=$(curl -sS https://api.github.com/repos/MetaCubeX/mihomo/releases/latest | jq -r .tag_name | sed \u0026#39;s|v||\u0026#39; | grep -v \u0026#34;null\u0026#34;); echo $remote_ver ## 下载最新稳定版（前一句有输出这一句才能正常执行） cd /tmp wget -q --progress=bar:dot --show-progress -O \u0026#34;mihomo-linux-amd64-v${remote_ver}.gz\u0026#34; \u0026#34;https://github.com/MetaCubeX/mihomo/releases/download/v${remote_ver}/mihomo-linux-amd64-v${remote_ver}.gz\u0026#34; ## 解压 gzip -d \u0026#34;mihomo-linux-amd64-v${remote_ver}.gz\u0026#34; ## 安装 install -ps mihomo-linux-amd64-v${remote_ver} /usr/local/bin/clash 上述 wget 这一行默认下载的是 AMD64 v3 架构的包，你可以输入以下命令查看是否支持。如若不支持，可以下载名称中带 cgo 或者 compatible 的版本，说明 在此。\n1 /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 --help | grep supported 如若支持 AMD64 v3 架构，输出将会是下面这样的。\n1 2 3 4 5 x86-64-v3 (supported, searched) x86-64-v2 (supported, searched) x86_64 (AT_PLATFORM; supported, searched) tls (supported, searched) x86_64 (supported, searched) 创建服务 clash.service 创建工作目录/var/lib/clash。\n1 mkdir -p /var/lib/clash 创建文件 /etc/systemd/system/clash.service，内容如下。请注意将 ens18 修改为你的网卡名。这时 clash 的配置文件为 /var/lib/clash/config.yaml。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [Unit] Description = Clash-Meta tproxy daemon. Wants = network-online.target subconverter.service After = network-online.target [Service] Environment = PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin Type = simple Restart = always LimitNPROC = 500 LimitNOFILE = 1000000 ExecStartPre = sleep 1s ExecStart = clash -d /var/lib/clash ExecStartPost = ip route add local default dev ens18 table 100 ; ip rule add fwmark 1 lookup 100 ; mynftables.nft ExecStop = nft flush ruleset ; ip route del local default dev ens18 table 100 ; ip rule del fwmark 1 lookup 100 [Install] WantedBy = multi-user.target 如果你比较讲究Linux哲学，可以把 ExecStart 改成下面这样，这时 clash 的配置文件为 /etc/clash/config.yaml。\n1 ExecStart = clash -d /var/lib/clash -f /etc/clash/config.yaml 如果不想以root用户运行 clash ，可以自行创建用户 clash 和用户组 clash ，然后在 /etc/systemd/system/clash.service 的 [Service] 单元下增加下面几行，同时修改 /var/lib/clash 为该普通用户所有（后续的脚本都是以root用户为运行用户进行的，如果要把 clash 服务调整为普通用户运行，请自行修改脚本）。\n1 2 3 4 User = clash Group = clash CapabilityBoundingSet = CAP_NET_ADMIN CAP_NET_RAW CAP_NET_BIND_SERVICE AmbientCapabilities = CAP_NET_ADMIN CAP_NET_RAW CAP_NET_BIND_SERVICE mynftables.nft 注意到我们在 /etc/systemd/system/clash.service 的 ExecStartPost 行有执行 mynftables.nft。现在，新建 /usr/local/bin/mynftables.nft，内容如下。请注意按照注释修改，创建好后以命令 chmod +x /usr/local/bin/mynftables.nft 为它增加可执行权限。该文件会引用到另外一个文件 /var/lib/clash/geoip4_cn.nft，你可以先下载这并非是最新的文件，先保存到该位置：geoip4_cn.nft，我们将在 本系列第（七）篇 用定时任务来自动更新。\n如果你的代理不支持代理 UDP 流量，可以选择解除 ip protocol udp accept 行的注释。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 #!/usr/sbin/nft -f ## 清空旧规则 flush ruleset ## 只处理指定网卡的流量，要和ip规则中的接口操持一致 define interface = ens18 ## clash的透明代理端口 define tproxy_port = 7895 ## clash打的标记（routing-mark） define clash_mark = 666 ## 常规流量标记，ip rule中加的标记，要和ip规则中保持一致，对应 \u0026#34;ip rule add fwmark 1 lookup 100\u0026#34; 中的 \u0026#34;1\u0026#34; define default_mark = 1 ## 本机运行了服务并且需要在公网上访问的tcp端口（本机开放在公网上的端口），仅本地局域网访问的服务端口可不用在此变量中，以半角逗号分隔 define local_tcp_port = { 2222, # ssh，按需设置 8080-8088 # nginx webui，按需设置 } ## 要绕过的局域网内tcp流量经由本机访问的目标端口，也就是允许局域网内其他主机主动设置DNS服务器为其他服务器，而非旁路由 define lan_2_dport_tcp = { 53 # dns查询 } ## 要绕过的局域网内udp流量经由本机访问的目标端口，也就是允许局域网内其他主机主动设置DNS服务器为其他服务器，而非旁路由；另外也允许局域网内其他主机访问远程的NTP服务器 define lan_2_dport_udp = { 53, # dns查询 123 # ntp端口 } ## 保留ip地址 define private_address = { 127.0.0.0/8, 100.64.0.0/10, 169.254.0.0/16, 224.0.0.0/4, 240.0.0.0/4, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16 } ## 大陆ip地址 include \u0026#34;/var/lib/clash/geoip4_cn.nft\u0026#34; table ip clash { ## 保留ipv4集合 set private_address_set { type ipv4_addr flags interval elements = $private_address } ## 大陆ipv4集合 set geoip4_cn_set { type ipv4_addr flags interval elements = $geoip4_cn } ## prerouting链 chain prerouting { type filter hook prerouting priority filter; policy accept; ip protocol { tcp, udp } socket transparent 1 meta mark set $default_mark accept # 绕过已经建立的连接 meta mark $default_mark goto clash_tproxy # 已经打上default_mark标记的属于本机流量转过来的，直接进入透明代理 fib daddr type { local, broadcast, anycast, multicast } accept # 绕过本地、单播、组播、多播地址 tcp dport $lan_2_dport_tcp accept # 绕过经由本机到目标端口的tcp流量 udp dport $lan_2_dport_udp accept # 绕过经由本地到目标端口的udp流量 ip daddr @private_address_set accept # 绕过目标地址为保留ip的地址 ip daddr @geoip4_cn_set accept # 绕过目标地址为大陆ip的地址 # ip protocol udp accept # 绕过全部udp流量（udp不进行透明代理） goto clash_tproxy # 其他流量透明代理到clash } ## 透明代理 chain clash_tproxy { ip protocol { tcp, udp } tproxy to :$tproxy_port meta mark set $default_mark } ## output链 chain output { type route hook output priority filter; policy accept; oifname != $interface accept # 绕过本机内部通信的流量（接口lo） meta mark $clash_mark accept # 绕过本机clash发出的流量 fib daddr type { local, broadcast, anycast, multicast } accept # 绕过本地、单播、组播、多播地址 udp dport { 53, 123 } accept # 绕过本机dns查询、NTP流量 tcp sport $local_tcp_port accept # 绕过本地运行了服务的tcp端口，如果并不需要从公网访问这些端口，可以注释掉本行 ip daddr @private_address_set accept # 绕过目标地址为保留ip的地址 ip daddr @geoip4_cn_set accept # 绕过目标地址为大陆ip的地址 ip protocol { tcp, udp } meta mark set $default_mark # 其他流量重路由到prerouting } } clash配置文件 暂时先按照下面的形式形成 clash 的配置文件 /var/lib/clash/config.yaml 或者 /etc/clash/config.yaml，我们将在 本系列第（七）篇 用定时任务来自动更新订阅。我只对关键信息进行了注释，未注释的内容你都可以自行按照 官方WIKI 进行设置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 port: 7890 socks-port: 7891 mixed-port: 7893 tproxy-port: 7895 # 和mynftables.nft中的tproxy_port保持一致 routing-mark: 666 # 和mynftables.nft中的clash_mark保持一致 allow-lan: true bind-address: \u0026#34;*\u0026#34; mode: rule log-level: info ipv6: false # 不进行IPv6流量代理 find-process-mode: off external-controller: 0.0.0.0:9090 secret: # 登陆ui的密码 external-ui: ui # webui的基础路径 external-ui-name: xd # webui的下级路径 external-ui-url: https://github.com/MetaCubeX/metacubexd/archive/refs/heads/gh-pages.zip unified-delay: true tcp-concurrent: true experimental: sniff-tls-sni: true geodata-mode: true geodata-loader: standard geox-url: geoip: https://testingcf.jsdelivr.net/gh/MetaCubeX/meta-rules-dat@release/geoip.dat geosite: https://testingcf.jsdelivr.net/gh/MetaCubeX/meta-rules-dat@release/geosite.dat mmdb: https://testingcf.jsdelivr.net/gh/MetaCubeX/meta-rules-dat@release/country.mmdb profile: tracing: true store-selected: true store-fake-ip: true sniffer: enable: true parse-pure-ip: true override-destination: true dns: enable: true ipv6: false # 禁止DNS解析IPv6 listen: 0.0.0.0:7874 # DNS监听端口 use-hosts: true enhanced-mode: redir-host default-nameserver: # 建议修改为你最近的DNS服务器 - 10.0.0.1 - 101.226.4.6 - 114.114.114.114 - 116.228.111.118 - 223.5.5.5 nameserver: # 建议修改为你最近的DNS服务器 - 10.0.0.1 - 101.226.4.6 - 114.114.114.114 - 116.228.111.118 - 223.5.5.5 fallback: - https://dns.cloudflare.com/dns-query - tls://dns.google:853 - https://1.1.1.1/dns-query - tls://1.1.1.1:853 - tls://8.8.8.8:853 - https://public.dns.iij.jp/dns-query - https://jp.tiar.app/dns-query - https://jp.tiarap.org/dns-query - tls://jp.tiar.app - tls://dot.tiar.app fallback-filter: geoip: true geoip-code: CN geosite: - gfw ipcidr: - 0.0.0.0/8 - 10.0.0.0/8 - 100.64.0.0/10 - 127.0.0.0/8 - 169.254.0.0/16 - 172.16.0.0/12 - 192.0.0.0/24 - 192.0.2.0/24 - 192.88.99.0/24 - 192.168.0.0/16 - 198.18.0.0/15 - 198.51.100.0/24 - 203.0.113.0/24 - 224.0.0.0/4 - 240.0.0.0/4 - 255.255.255.255/32 domain: - +.google.com - +.facebook.com fake-ip-filter: - +.* proxies: # 以下为你的代理节点、分组及代理规则 proxy-groups: rules: clash其他相关文件 clash 还需要一些配套文件，在启动前先下载下来。我们将在 本系列第（七）篇 用定时任务来自动更新这些文件。\n1 2 3 4 5 6 7 8 9 10 cd /var/lib/clash wget -q --progress=bar:dot --show-progress -O country.mmdb https://github.com/MetaCubeX/meta-rules-dat/releases/download/latest/country.mmdb wget -q --progress=bar:dot --show-progress -O geosite.dat https://github.com/MetaCubeX/meta-rules-dat/releases/download/latest/geosite.dat wget -q --progress=bar:dot --show-progress -O geoip.dat https://github.com/MetaCubeX/meta-rules-dat/releases/download/latest/geoip.dat mkdir -p ui cd ui wget -q --progress=bar:dot --show-progress -O xd.zip https://github.com/MetaCubeX/metacubexd/archive/refs/heads/gh-pages.zip unzip -oqq xd.zip mv metacubexd-gh-pages xd 启用服务 完全配置好以后，我们可以设置 /etc/systemd/system/clash.service 为开启自动启动，并立即启动起来。\n1 systemctl enable --now clash.service 后续如想查看日志，我们直接使用Debian自带的工具来查看：\n1 journalctl -efu clash.service 如果日志报错 ip: RTNETLINK answers: File exists，请手动将旧的ip路由及ip规则清空，其实就是多执行几次 /etc/systemd/system/clash.service 中 ExecStop 这一行的命令，出现 RTNETLINK answers: No such process 和 RTNETLINK answers: No such file or directory 为止，表示旧的ip路由及ip规则都清空了。\n1 nft flush ruleset ; ip route del local default dev ens18 table 100 ; ip rule del fwmark 1 lookup 100 如果想要重启：\n1 systemctl restart clash.service 查看当前的 nftables 规则，如果为空可以手动输入 mynftables.nft 以查看错误，如有错误，请自行根据输出排故。\n1 nft list ruleset 访问webui：http://\u0026lt;IP\u0026gt;:9090/ui/xd，其中 9090 ui xd 均在配置文件中由你定义，分别对应 external-controller external-ui external-ui-name。\n执行逻辑 大致在 mynftables.nft 这个文件的注释也解释过每句的作用了，这里再捊一下。\n对照着题图，局域网中的其他客户端的流量在通过旁路由时，进入 nftables 的 prerouting 链，然后判断第69-76行的规则，如果规则匹配就以 accept 直接收受并发往目的地，不会再转到 clash；如果全都不匹配，会在最后匹配上 goto clash_tproxy，也就是进入 ip protocol { tcp, udp } tproxy to :$tproxy_port meta mark set $default_mark 这句，这句将会把流量转到 clash。需要提一句的是第70行的规则是针对从本机 output 链发过来的流量的，没有第70行，这部分流量同样会在最后匹配到第77行的 goto clash_tproxy。\n经过 clash 代理后，流量会被打上标记 clash_mark，也就是第13行定义的 666，clash 工作在题图中的应用层，经过 clash 处理过的流量会在 output 链中被第89行直接接收并发往目的地，不会再一次进行代理，这样就防止了流量一直在走环路的问题。\n本机产生的流量类似，它们会在 output 链中先匹配第88-94行，如果匹配就直接接收并发往目的地了，而剩余没有匹配到的会在第95行被打上 $default_mark，也就是在第16行定义的 1，这个标记和上方创建的 clash.service 中 fwmark 1 的 1 一致。被打上这个标记的流量会按照 clash.service 定义的 ip route 和 ip rule，重路由进入 prerouting 链，然后根据规则确定是直接接收还是转向 clash。\n至于 forward 转发链，我们并没有设置它，那么转发的默认 policy 就是 accept，将直接全部接受。我已经在 前文（一） 中提及了我只在主路由爱快上设置防火墙：IPv4、IPv6，旁路由对这类流量直接转发，不再过滤。所以，针对运行在我NAS 10.0.0.11 上的服务以及其他众多运行在 Docker MacVLAN 网络上的容器，我直接从主路由爱快转发端口到它们即可，无需再经过旁路由额外中转。\n参考资料 nftables wiki\nnft Man Page\nclash nftables 透明代理（TPROXY）\nProject X 透明代理（TProxy）配置教程\n系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-21T14:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%9B%9B/nf-hooks_hu5706531108708616834.png","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E5%9B%9B/","title":"我的家庭网络设计思路，开启debian的旁路由之路（四）"},{"content":"前言 在 前文（一） 中我提及了我的目标是在10.0.0.0/24这个旁路由所在的子网中实现国内网站IPv4/IPv6双栈解析并可正常访问，国外网站仅解析IPv4地址并进行科学上网，那么仅凭Clash很难实现（其他的代理软件我也不介绍了），我们可以借助mosdns来实现（其他的smartdns、coredns我就不介绍了）。又为了能够更加方便的为电视机屏蔽广告、自定义子网中设备解析为私网IPv4地址和公网IPv6地址这种形式的双栈、防止代理有故障需要后备DNS等等功能，我继续在mosdns前加一层adguardhome，以方便的实现。\n逻辑图 说明 由于我在 前文（二） 中并没有安装 dnsmasq，53 端口上并没有运行任何服务，所以我可以让 adguardhome 直接监听在 53 端口。在 前文（二） 中我已经设置了旁路由自身的DNS服务器为 127.0.0.1。在 前文（一） 中我们也设置好了 10.0.0.0/24 整个网段的DNS服务器为旁路由的IP 10.0.0.2。\n当客户端需要解析DNS时，监听在 53 端口上的 adguardhome 会转发给其上游 mosdns，然后 mosdns 根据设置来进行分流，中国大陆部分使用国内的公共DNS服务器进行解析，保留IPv4/IPv6双栈结果，非中国大陆部分继续转发给上游 clash ，由 clash 通过代理向国外公共DNS服务器进行解析，clash 中的DNS模块设置关闭IPv6解析，这样国外部分只会返回IPv4的结果。\n而当 mosdns 出现故障时（mosdns本身也会有一个后备，防止clash出现故障，也就是说会有两层后备），adguardhome 则直接向国内公共DNS服务器请求解析，做到不影响局域网的网络。\nAdGuardHome的安装和配置 下载安装 我默认你已经按照 前文（二） 安装好了必要的软件了。以下为root用户运行的命令。\n1 2 3 4 5 6 7 8 9 10 11 12 ## 检查最新稳定版的版本号，如果获取不到请检查网络 remote_ver=$(curl -sS https://api.github.com/repos/AdguardTeam/AdGuardHome/releases/latest | jq -r .tag_name | sed \u0026#39;s|v||\u0026#39; | grep -v \u0026#34;null\u0026#34;); echo $remote_ver ## 下载最新稳定版（前一句有输出这一句才能正常执行） cd /tmp wget -q --progress=bar:dot --show-progress -O \u0026#34;AdGuardHome_linux_amd64.tar.gz\u0026#34; \u0026#34;https://github.com/AdguardTeam/AdGuardHome/releases/download/v${remote_ver}/AdGuardHome_linux_amd64.tar.gz\u0026#34; ## 解压 tar --no-same-owner -xf \u0026#34;AdGuardHome_linux_amd64.tar.gz\u0026#34; --strip-components 2 --directory=. ## 安装 install -ps AdGuardHome /usr/local/bin/adguardhome 创建服务 创建工作目录/var/lib/adguardhome。\n1 mkdir -p /var/lib/adguardhome 创建 /etc/systemd/system/adguardhome.service 如下，这时配置文件为 /var/lib/adguardhome/AdGuardHome.yaml。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Unit] Description = Network-wide ads \u0026amp; trackers blocking DNS server. Wants = network-online.target mosdns.service After = network-online.target mosdns.service [Service] Type = simple Restart = always StartLimitInterval = 5 StartLimitBurst = 10 ExecStart = /usr/local/bin/adguardhome -w /var/lib/adguardhome RestartSec = 10 [Install] WantedBy = multi-user.target 如果你比较讲究Linux哲学，可以把ExecStart改成下面这样，这时配置文件为 /etc/adguardhome/config.yaml。\n1 ExecStart = /usr/local/bin/adguardhome -w /var/lib/adguardhome -c /etc/adguardhome/config.yaml 如果不想以root用户运行 adguardhome ，可以自行创建用户 adguardhome 和用户组 adguardhome ，然后在 /etc/systemd/system/adguardhome.service 的 [Service] 单元下增加下面几行，同时修改 /var/lib/adguardhome 为该普通用户所有（后续的脚本都是以root用户为运行用户进行的，如果要把 adguardhome 服务调整为普通用户运行，请自行修改脚本）。\n1 2 3 4 5 6 User = adguardhome Group = adguardhome # 我们需要监听特权端口53 CapabilityBoundingSet = CAP_NET_BIND_SERVICE AmbientCapabilities = CAP_NET_BIND_SERVICE adguardhome 自身的命令行是支持自动创建 /etc/systemd/system/adguardhome.service 的，但个人不是很建议直接使用 adguardhome 本身所支持的命令来完成上述工作，以下仅供参考。\n1 2 3 adguardhome -s install -w /var/lib/adguardhome # 需要自行创建目录var/lib/adguardhome # 或者 adguardhome -s install -w /var/lib/adguardhome -c /etc/adguardhome/config.yaml # 需要自行创建目录/etc/adguardhome和/var/lib/adguardhome 初始化 先开一个终端输入adguardhome，然后浏览器打开 http://10.0.0.2:3000 并按下图设置。\n配置 DNS设置 上游DNS服务器设置为mosdns的监听端口。\n后备DNS服务器填写公共DNS服务器，可以附加上你的ISP当地的DNS服务器，如果主路由设置了DNS的功能，也可以加上，当mosdns出现故障时，adguardhome会转为使用后备DNS服务器来进行解析。这样。即使mosdns或者clash出现故障时，也不影响adguardhome为局域网提供DNS服务。\n我们只在局域网中使用，所以不限制查询流量。\n开启乐观缓存可以更快的响应，但有些时候可能会导致问题，可以视情况开关。\nDNS重写 如果你已经使用DDNS将你的域名解析了IPv4和IPv6，则可以在AdGuardHome的DNS重写模块中按下图这样设置，设置后局域网中的设备在解析时，可以解析私网IPv4地址和公网IPv6地址，做到在局域网中照样使用和公网中一样的域名访问。\n一个良好的习惯是针对局域网中每一个运行着需要被访问的服务的IP，都通过 adguardhome 劫持其域名，做到不同IP不同子域名。只要设置好DDNS的子域名以及主路由爱快的端口转发，就可以做到在局域网环境中和在公网环境中，使用相同的域名去访问同一个服务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## 解析nas的ip，我的nas双网卡，均配置了IP $ nslookup nas.evine.win Server: 10.0.0.2 Address: 10.0.0.2#53 Non-authoritative answer: Name: nas.evine.win Address: 10.0.0.11 Name: nas.evine.win Address: 10.0.0.12 Name: nas.evine.win Address: 240e:■■■■:■■■■:■■■■:■■■:■■■■:■■■■:1ee Name: nas.evine.win Address: 240e:■■■■:■■■■:■■■■:■■■:■■■■:■■■■:6c4c ## 解析创建在10.0.1.0/24网段docker macvlan上的qbittorrent容器的ip $ nslookup qb.evine.win Server: 10.0.0.2 Address: 10.0.0.2#53 Non-authoritative answer: Name: qb.evine.win Address: 10.0.1.2 Name: qb.evine.win Address: 240e:■■■■:■■■■:■■■■:■■■:■■■■:■■■■:102 在完全配置好旁路由后，你就可以实现上述这样的域名解析。这样的话，像手机、笔记本电脑这种会频繁进出局域网的设备，可以在局域网和公网中使用一样的域名去访问各项服务，而不用在公网用域名访问，在局域网得换成IP访问这种形式。\n启用服务 完全配置好以后，我们可以设置 /etc/systemd/system/adguardhome.service 为开启自动启动，并立即启动起来（这时上游mosdns尚未配置，会直接跳转到备用DNS服务器去，你可以等后续配置完好以后再来启动它）。\n1 systemctl enable --now adguardhome.service 后续如想查看日志，我们直接使用Debian自带的工具来查看：\n1 journalctl -efu adguardhome.service 如果想要重启：\n1 systemctl restart adguardhome.service mosdns的安装和配置 下载安装 我默认你已经按照 前文（二） 安装好了必要的软件了。以下为root用户运行的命令。\n1 2 3 4 5 6 7 8 9 10 11 12 ## 检查最新稳定版的版本号，如果获取不到请检查网络 remote_ver=$(curl -sS https://api.github.com/repos/IrineSistiana/mosdns/releases/latest | jq -r .tag_name | sed \u0026#39;s|v||\u0026#39; | grep -v \u0026#34;null\u0026#34;); echo $remote_ver ## 下载最新稳定版（前一句有输出这一句才能正常执行） cd /tmp wget -q --progress=bar:dot --show-progress -O \u0026#34;mosdns-linux-amd64.zip\u0026#34; \u0026#34;https://github.com/IrineSistiana/mosdns/releases/download/v${remote_ver}/mosdns-linux-amd64.zip\u0026#34; ## 解压 unzip -oqq mosdns-linux-amd64.zip -d . ## 安装 install -ps mosdns /usr/local/bin/mosdns 创建服务 创建工作目录/var/lib/mosdns。\n1 mkdir -p /var/lib/mosdns 创建 /etc/systemd/system/mosdns.service 如下，这时配置文件为 /var/lib/mosdns/config.yaml。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Unit] Description = A DNS forwarder. Wants = network-online.target clash.service After = network-online.target clash.service [Service] StartLimitInterval = 5 StartLimitBurst = 10 WorkingDirectory = /var/lib/mosdns ExecStart = /usr/local/bin/mosdns start Restart = always RestartSec = 10 [Install] WantedBy = multi-user.target 如果你比较讲究Linux哲学，可以把 ExecStart 改成下面这样，这时配置文件为 /etc/mosdns/config.yaml。\n1 ExecStart = /usr/local/bin/mosdns start -c /etc/mosdns/config.yaml 如果不想以root用户运行 mosdns，可以自行创建用户 mosdns 和用户组 mosdns，然后在 /etc/systemd/system/mosdns.service 的 [Service] 单元下增加两行，同时修改 /var/lib/mosdns 为该普通用户所有（后续的脚本都是以root用户为运行用户进行的，如果要把 mosdns 服务调整为普通用户运行，请自行修改脚本）。\n1 2 User = mosdns Group = mosdns 同样的，mosdns 自身的命令行也支持自动创建 /etc/systemd/system/mosdns.service 的，但个人不是很建议直接使用 mosdns 本身所支持的命令来完成上述工作，以下仅供参考。\n1 2 3 mosdns service install -d /var/lib/mosdns # 需要自行创建目录var/lib/mosdns # 或者指定配置文件为/etc/mosdns/config.yaml mosdns service install -d /var/lib/mosdns -c /etc/mosdns/config.yaml # 需要自行创建目录/etc/mosdns和/var/lib/mosdns 配置 luci-app-mosdns 提供的 默认配置 已经是一份非常好的配置了，我们稍微改改就能用了。考虑到我已经使用 adguardhome 来屏蔽广告，以及用来解析本地局域网内的私有IP了，所以在 mosdns 中我们这可舍弃这一部分配置内容。\n稍加修改后的配置文件见 mosdns配置，在该文件中，会引用到以下文件。其中 rule 文件夹下的几份文件可以参考 luci-app-mosdns的配置。至于 geodata 下面的文件，你可以先下载这几个并非是最新的文件，先保存到该目录下：geoip_cn.txt、geosite_cn.txt、geosite_geolocation-!cn.txt，我们将在 本系列第（七）篇 用定时任务系统来定时更新。\n1 2 3 4 5 6 7 8 9 10 /var/lib/mosdns ├── geodata │ ├── geoip_cn.txt # 中国大陆IP │ ├── geosite_cn.txt # 中国大陆网址 │ └── geosite_geolocation-!cn.txt # 非中国大陆网址 └── rule ├── ddnslist.txt # 你的DDNS主域名 ├── greylist.txt # 优先通过clash代理获取DNS解析的域名 ├── local-ptr.txt # ptr记录 └── whitelist.txt # 优先通过中国大陆DNS服务器获取解析的域名 在配置中，由于 fallback 这个后备 tag 的存在，也能保障clash在出现故障时，使用国内DNS服务器进行解析。这一点，再加上 adguardhome 本身也设置了后备节点，两层保障不因clash服务故障而影响DNS的解析。\n你也可以参考 mosdns wiki 来进行更加定制化的配置。\n启用服务 完全配置好以后，我们可以设置 /etc/systemd/system/mosdns.service 为开启自动启动，并立即启动起来（这时上游clash尚未配置，你可以等后续配置完好以后再来启动它）。\n1 systemctl enable --now mosdns.service 后续如想查看日志，我们直接使用Debian自带的工具来查看：\n1 journalctl -efu mosdns.service 如果想要重启：\n1 systemctl restart mosdns.service clash 由于clash不仅仅只涉及DNS服务，还涉及到代理、nftables、IP规则相关内容，我们将在接下来的单篇 本系列第（四）篇 中详细详解。\n系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-21T13:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%B8%89/DNS_hu13311774234368334609.jpg","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%B8%89/","title":"我的家庭网络设计思路，开启debian的旁路由之路（三）"},{"content":"安装 安装Debian的详细过程我就不提了，网上的教程很多，我只提一部分内容。如果对其他安装内容真有需要，可以在本文下方评论区提出。\n主机名和域名 在配置主机名和域名时，可以考虑设置为你的DDNS域名的三级域名下，详见下面两图，后续就可以使用gate.evine.com来访问旁路由。\n安装哪些内容 仅安装核心系统和SSH服务端，不要安装其他东西，连“标准系统工具”都不需要选择。\n首次安装后 首次安装完成后进入系统，系统进程只有这些（请手动安装htop：apt install htop），非常清爽。下图是虚拟机安装的，并且创建时启用了qemu-guest-agent，所以额外有个qemu-ga进程，物理机安装甚至连这个进程都没有。在我们还没有配置其他服务时，内存也只占用了120M左右，也并没有比OpenWRT多多少。\n配置 SSHD 如果你想以root用户进行ssh登陆，可以将/etc/ssh/sshd_config中的#PermitRootLogin prohibit-password修改为PermitRootLogin yes，如果要修改ssh端口，可以将#Port 22修改为Port 2222（2222端口仅为示例）。最后重启一下sshd服务systemctl restart sshd.service。\n你也可以关闭密码登陆仅允许私钥登陆，将#PasswordAuthentication yes修改为PasswordAuthentication no即可，不过在关闭前请先以700权限创建好$HOME/.ssh文件夹，以600权限上传公钥$HOME/.ssh/authorized_keys，并在其他地方保存好私钥。\n配置网络 输入 nano /etc/network/interfaces，编辑为以下内容，编辑好后以 Ctrl+X 退出。说明：\n其中的 ens18 是我的网卡名，可以输入 ip a 这个命令查看到。\nIPv4地址进行静态配置 inet static，设置自身的IP和掩码为 10.0.0.2/24，网关为 10.0.0.1，后续我还将以adguardhome和mosdns在旁路由中自建DNS服务，所以设置默认DNS服务器为 127.0.0.1。不过下面的示例是最终的状态，我们在配置旁路由过程中，需要科学上网环境，所以在完全配置好旁路由以前，网关 gateway 和默认DNS服务器 dns-nameservers 建议先暂时设置为局域网中另一台可以实现科学上网的OpenWRT，在完全配置好后再改成下面这样。\nIPv6地址采用DHCPv6形式，配置为 inet6 dhcp，这仅仅表示旁路由自身可以从主路由爱快处获取IPv6地址，并不代表它将作为IPv6网关。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). source /etc/network/interfaces.d/* # The loopback network interface auto lo iface lo inet loopback # The primary network interface # allow-hotplug ens18 auto ens18 iface ens18 inet static address 10.0.0.2/24 network 10.0.0.0 broadcast 10.0.0.255 gateway 10.0.0.1 dns-nameservers 127.0.0.1 iface ens18 inet6 dhcp 保存好该文件后，输入以下命令重启网络服务：\n1 systemctl restart networking.service 然后你就会发现系统启动了DHCPv6客户端以获取IPv6地址。不过虽然配置了静态IPv4地址，但需要在重启系统以后，dhclient -4这个用来获取DHCPv4地址的进程才会消失。\n查看IP：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ip a ## 输出可见ip已经是所设置的了 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host noprefixroute valid_lft forever preferred_lft forever 2: ens18: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 0e:■■:■■:■■:■■:■■ brd ff:ff:ff:ff:ff:ff altname enp0s18 inet 10.0.0.2/24 brd 10.0.0.255 scope global ens18 valid_lft forever preferred_lft forever inet6 240e:■■■:■■■■:■■■■::dfc/128 scope global dynamic valid_lft 5242sec preferred_lft 5242sec inet6 240e:■■■:■■■■:■■■■:■■■:■■■■:■■■■:ff2f/64 scope global dynamic mngtmpaddr valid_lft 215432sec preferred_lft 129032sec inet6 fe80::■■■:■■■■:■■■■:ff2f/64 scope link valid_lft forever preferred_lft forever 配置网关功能 由于我仅将旁路由作为IPv4的网关，IPv6网关仍然为主路由爱快，所以只需要配置IPv4的转发。\n1 2 echo \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p 安装一些后续必要的软件 后续我们会用到一些软件包，在这里可以先安装好。如果你暂时不想增加系统体积，也可以根据下方的注释选择性的安装，或者在后续配置旁路由的过程中根据需要再进行安装。\n你可以先将源更改为国内源后再安装下面的包。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 apt update ## 后续会用到的 apt install -y --no-install-recommends \\ arp-scan `# arp扫描用的，后续监测外来陌生设备会用到` \\ bind9-dnsutils `# dns工具` \\ binutils `# 二进制文件处理工具，在本系统最后的脚本汇总中会用到` \\ bzip2 `# 解压bz2` \\ curl `# 下载工具` \\ git `# 从github下载东西` \\ htop `# 监测进程` \\ jq `# 后续在各种脚本中、命令中解析json会用到` \\ lsof `# 后续监测打开的TCP/UDP端口会用到` \\ nginx `# 后续配置文件服务器会用到` \\ libnginx-mod-http-headers-more-filter `# nginx的一个模块，后续如果用不到可以不安装` \\ openssh-server `# 安装Debian时应该已经安装好了` \\ snmpd `# 解决爱快查到不到以旁路由为网关的设备信息的问题` \\ sudo `# 如果不是root用户登陆的话，需要这个` \\ unzip `# 解压zip` \\ wget `# 下载工具` \\ xz-utils `# 解压xz` \\ yt-dlp `# youtube下载工具，unblockneteasemusic的依赖项` ## 一些好用的工具，按需安装 apt install -y --no-install-recommends \\ duf `# 美观的磁盘使用情况查看工具` \\ etherwake `# 网络唤醒用的` \\ ethtool `# 网卡工具` \\ fzf `# 配合zsh插件fzf和zsh-interactive-cd` \\ iftop `# 监测网络流量` \\ iperf3 `# 测速工具` \\ lsd `# 比ls美观` \\ gdu `# 美观的查看文件夹体积大小的工具` \\ qemu-guest-agent `# qemu宿主机管理虚拟机的工具` \\ rsync `# 同步工具` \\ socat `# 自动签发ssl证书的工具acme.sh的依赖` \\ tmux `# 虚拟屏幕，运行长任务的好帮手` \\ zoxide `# 配合zsh的插件zoxide` \\ zsh `# 一个好用的shell` 总结 截止目前，我们安装好了Debian，并配置了它的基础网络服务，开启了IPv4流量转发，这个时候，它已经可以做一个旁路由了。不过，如果仅仅是这样，我们要这旁路由有何用！！！所以，我将在接下来的 软路由系列文章 继续设置adguardhome、mosdns、clash、nftables、subconverter、unblockneteasemusic、snmpd、cron、nginx等等，让它成为一台合格的旁路由。\n系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-20T00:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%BA%8C/dhcpv6-client_hu5731835652040388842.png","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%BA%8C/","title":"我的家庭网络设计思路，开启debian的旁路由之路（二）"},{"content":"前言 之前我用的是爱快作为主路由，OpenWRT作为旁路由，旁路由上会跑一些只有它能跑而主路由上不能跑的服务。尽管OpenWRT还是我自己定制化编译的，抛弃了许多我不使用的功能，但可能因为要用的服务仍然有些多，并且它们之间都会操作netfilter，导致网络经常出问题。所以，用OpenWRT作为旁路由的时候，我从来不敢在爱快上直接指定全部设备的网关和DNS为OpenWRT（网关和DNS仍然是爱快自己），只敢在我自己的设备上手动指定网关和DNS为OpenWRT。但这长久用起来不是个办法，所以干脆下定决心，抛弃OpenWRT，完全启用Debian来作为旁路由。\n网络设计思路 为什么不直接采用Debian作为主路由呢，毕竟爱快作为专业的路由系统，还是有其便利性的，查看相关数据也比较容易，如果直接采用Debian作为主路由的话，将会有大量的配置工作，并且想要便捷的查看各项数据也不是很方便。\n并且，我还需要旁路由的存在不能影响端口转发，必须由主路由爱快直接将端口转发到NAS及其他服务，不能先转发到旁路由再经旁路由再转发一次。\n那么，基于爱快作为主路由，Debian作为旁路由，我将以下面的拓扑图开展。\n上图中仅涉及了爱快中lan1的设置，如果需要使用IPTV，还可以参考我的这篇文章来设置一下lan2。\n关于IPv6 IPv6是未来的趋势，我的ISP也已经支持IPv6了，并且不管是DDNS还是PT，有IPv6的双栈总归是好的。但又同时，我所使用的科学上网服务并不支持IPv6，所以，我需要在10.0.0.0/24这个科学上网的网段保留国内网站的IPv6解析，屏蔽掉国外网站IPv6的解析。这就得靠我在旁路由10.0.0.2上自建DNS服务了，与此同时，如果不关闭爱快IPv6的DNS服务，由于我并没有设置旁路由作为IPv6网关，仍然使用主路由作为IPv6网关，这样的话，终端就不仅仅从我的自建DNS服务来获取解析了，也会从IPv6 DNS服务器来获取，所以还需要关闭爱快IPv6的DNS。自建DNS服务一样可以解析IPv6地址，以IPv6访问国内网站不是问题。\n说明 网段的划分 10.0.0.0/24作为科学上网的子网，该子网下全部设备默认直接可以科学上网。注意其中旁路由的IP是10.0.0.2/24\n10.0.1.0/24作为无需科学上网的子网，该子网下全部设备默认不可以科学上网。\n爱快中的设置 lan1设置10.0.0.1为主IP，子网掩码为/24，同时设置10.0.1.1为扩展IP，子网掩码同样为/24，详见下图。你也可以设置更多的扩展IP来分别管理不同的网段及设备（比如再单独设置一个子网为访客网络）。 爱快的DHCP服务器中分别设置两个子网的掩码、网关和DNS，其中10.0.0.3-10.0.0.254的网关和DNS都是旁路由的IP10.0.0.2(请在完成全部旁路由配置以后再在爱快中设置成这样，没配置好旁路由前就设置成这样会上不了网)；10.0.1.2-10.0.1.254这一段的网关是爱快的扩展IP10.0.1.1，DNS可以设置为当地响应最快的DNS服务器，如果爱快开启了DNS加速，也可以将爱快的扩展IP10.0.1.1设置为这一网段的DNS服务器。 为全部设备设置DHCP静态分配。如果你需要为后续首次接入网络的设备分配到10.0.1.2-10.0.1.254中，而不是直接分配到10.0.0.3-10.0.0.254网段中，你可以在DHCP静态分配中，把那些还没有设备占用的IP用假MAC先占用着，MAC批量生成工具在此，批量生成后粘贴在从爱快DHCP静态分配导出的csv文件中，再导入回去就好。或者也可以交换一下10.0.0.0/24作为无需科学上网的子网，10.0.1.0/24作为需要科学上网的子网。\n关闭IPv6的DNS。后续我将在旁路由上自建DNS服务，所以必须关闭爱快IPv6的DNS通告。\n全部子网内的设备不再单独设置防火墙，全部在主路由爱快中设置，具体的教程可以见这两篇文章：IPv4、IPv6。\n网关为旁路由的设备在爱快的终端监控中，全部显示为旁路由的信息，所以我们还需要设置爱快的“高级应用-\u0026gt;跨三层应用”，具体如何设置因为还涉及到旁路由中的设置，我将在接下来的 本系列第（八）篇 中详细讲解。\n交换机 如果主路由有足够的网口，交换机可以省略，全部设备都直接接入主路由。有交换机时，即使交换机本身的管理IP处于10.0.0.3/24，但接入的处于10.0.1.0/24网段的设备一样是可以正常上网的，毕竟它是交换机。\nAP 如果主路由或者旁路由有无线功能，AP也可以省略，直接以主路由或者旁路由作为AP即可。\n旁路由 旁路由是不是虚拟机都没有关系。我的主路由是物理机，旁路由是虚拟机。其实我的很多设备都是通过虚拟机或者Docker的MacVLAN接入网络中，它们既有10.0.0.0/24的，也有10.0.1.0/24的，都按照我上面设置的DHCP服务正常工作着。\n总结 通过分离为两个子网，将需要科学上网的设备和不需要科学上网的设置分开，同时在前者所在子网下自建DNS服务器，达到国内支持IPv4/IPv6双栈，国外仅通过IPv4科学上网的目的。而在不需要科学上网的子网下，设备都是直接采用公共DNS服务器。\n不同的服务可以放在不同的子网下分别进行管理，比如我的许多Docker容器就通过创建在两个子网下的MacVLAN网络分别走不同的路线，一块网卡也可以创建多个MacVLAN网络以进行分流，详见我的 这篇文章，比如 我的qBittorrent容器 就放在10.0.1.0/24下，完全不用担心流量走了代理（我甚至在Clash中开启了代理PT网站，但这只影响我用PC访问PT网站，对 我的qBittorrent容器 毫无影响）。至于虚拟机也是一样，可以将其放入不同的子网来走不同的路线。\n接下来，我们将继续设置Debian为旁路由，真正的开启Debian的旁路由之路，这将在我的 软路由系列文章 中逐渐地一篇一篇发出来。这个系列虽然比较长，看起来比较复杂，但你可以根据你的需要进行选择性的使用，并且，配置好后是一劳永逸的，不用担心刷机，不用担心哪天服务故障，这套配置比OpenWRT稳定多了，即使未来升级系统也是分分钟的事。\n系列 一、子网划分及网络拓扑设计、爱快上的设置\n二、安装Debian、初始网络配置、必要软件安装\n三、AdGuardHome、mosdns、clash在DNS的关系，以及AdGuardHome、mosdns的安装和配置\n四、clash透明代理(Tproxy)的安装和配置、相关的IP规则和nftables规则\n五、UnblockNeteaseMusic的安装和配置、相关的的nftables规则、客户端如何使用\n六、subconverter的安装和配置\n七、配置nginx为文件服务器、自动更新clash订阅、自动生成需要的文件\n八、配置旁路由的SNMPD服务、配置主路由的跨三层应用\n九、监测陌生设备\n十、快速简单的安装和更新软件包\n十一、DNS、网络故障等的总结，以及一些注意事项\n","date":"2023-10-19T00:00:00+08:00","image":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%B8%80/%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C_hu15325140971667430952.jpg","permalink":"https://evine.win/p/%E6%88%91%E7%9A%84%E5%AE%B6%E5%BA%AD%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E5%BC%80%E5%90%AFdebian%E7%9A%84%E6%97%81%E8%B7%AF%E7%94%B1%E4%B9%8B%E8%B7%AF%E4%B8%80/","title":"我的家庭网络设计思路，开启debian的旁路由之路（一）"},{"content":" 本文较长，如想略过某些内容，请直接点击右侧目录链接。\n说明 为保证用户安全，防止用户因使用反代并代理了127.0.0.1这种情况导致安全性降低，从2023年9月5日更新的镜像开始，创建容器需要新增设置两个环境变量：QB_USERNAME（登陆qBittorrent的用户名）和QB_PASSWORD（登陆qBittorrent的密码）。容器将在创建时使用这两个环境变量去设置（如已存在配置文件则是修改）登陆qBittorent的用户名和密码。如未设置这两个环境变量，或者保持为qBittorrent的默认值（默认用户名：admin，默认密码：adminadmin），则本容器附加的所有脚本、定时任务将无法继续使用。详情。也因此镜像默认即安装好python，不再需要设置INSTALL_PYTHON这个环境变量。\n声明 本镜像非魔改版、非快验版、非Enhanced增强版，qBittorrent自身的行为/功能全部未做任何改动（也不会考虑添加或修改官方客户端行为/功能的内容），全部属于官方客户端的默认行为/功能，在和PT站Tracker服务器交互时反馈的一切信息均是qBittorrent官方版反馈的信息。本镜像只是基于官方客户端附加了一些实用的脚本，脚本全部是合理合法使用qBittorrent官方API获取信息，脚本全部行为都集中在本地，与任何远端服务器无任何联系。增加的脚本全部代码在 Github 或 Gitee 均可查看 。绝对不会因为使用此镜像而导致账号被封。\n效果图 特点 自动按tracker分类或打标签（可以选择关闭，可以选择采用qBittorrent中的“分类”还是“标签”）。\n下载完成发送通知（可以选择关闭），可选途径：钉钉（效果图）, Telegram, ServerChan, 爱语飞飞, PUSHPLUS推送加, 企业微信, Gotify；搭配RSS功能（RSS教程）自动下载效果很好；下载完成后还可以补充运行你的自定义脚本。\n故障时发送通知，可选途径同上。\n按设定的cron检查tracker状态，如发现种子的tracker状态有问题，将给该种子添加TrackerError的标签，方便筛选；如果tracker出错数量超过设定的阈值，给设定渠道发送通知。\n一些辅助功能：批量修改tracker；检测指定文件夹下未做种的子文件夹/文件；生成做种文件清单；生成未做种文件清单；配合IYUU自动重新校验和自动恢复做种；指定设备上线时自动限速；多时段限速；分析指定目录的重复做种率（辅种率）等等。\n如需要下载完成后自动触发EMBY/JELLYFIN扫描媒体库，触发ChineseSubFinder自动为刚刚下载完成的视频自动下载字幕，请按照 这里 操作。\npython为可选安装项，设置为true就自动安装。（从2023年9月5日起，默认安装好python，不再需要设置这一项。）\n体积小，默认中文UI，默认东八区时区。\niyuu标签集成了IYUUPlus，自动设置好下载器，减少IYUUPlus设置复杂程度。\n标签 4.x.x , latest: 标签以纯数字版本号命名，这是qBittorrent正式发布的稳定版，其中最新的版本额外增加latest标签。\n4.x.x-iyuu , latest-iyuu , iyuu: 标签中带有iyuu字样，基于qBittorrent稳定版集成了IYUUPlus，其中最新的版本额外增加latest-iyuu和iyuu标签，自动安装好IYUUPlus，自动设置好下载器，主要针对不会设置下载器的用户。\nx.x.xalphax, x.x.xbetax , x.x.xrcx , unstable: 标签中带有alpha、beta或rc字样，这是qBittorrent发布的测试版，其中最新的测试版额外增加unstable 标签。此标签仅供测试使用及向qBittorrent官方反馈bug使用。\nedge: 基于alpine:edge制作的镜像，体积最小，所依赖的组件版本最新，会提供riscv64版本镜像。所有新功能或者BUG修复，或者有任何变化时，都会第一时间更新到此标签。\n更新日志（仅列出稳定版） Date qBittorrent libtorrent alpine 备注 2021-06-08 4.3.5 1.2.13 3.13.5 2021-06-17 4.3.5 1.2.14 3.14.0 默认不再安装python，需要开关打开才安装 2021-06-28 4.3.6 1.2.14 3.14.0 优化自动分类和tracker错误检查时的资源占用 2021-08-04 4.3.7 1.2.14 3.14.0 1. 增加5个环境变量控制开关，详见环境变量清单；\n2. 增加批量修改 tracker的功能，详见命令；\n3. 增加在运行dl-finish %K时运行自定义脚本的功能，详见相关问题2。 2021-08-30 4.3.8 1.2.14 3.14.2 1. 增加3个环境变量控制开关，详见环境变量清单；\n2. 增加检测指定目录未做种的子文件夹/文件功能，详见命令。 2021-11-01 4.3.9 1.2.14 3.14.2 修复通知内容中含有字符\u0026quot;\u0026amp;\u0026ldquo;时无法正常发送的bug。 2022-01-07 4.4.0 2.0.5 3.14.3 1. 增加环境变量EXTRA_PACKAGES，详见环境变量清单；\n2. 默认运行自动分类程序时仅对未分类的种子进行分类，如需要强制对所有种子进行分类，请参考命令；\n3. 增加两个需要手动运行的脚本report-seed-files(导出所有做种文件清单)和report-unseed-files(导出指定文件夹下未做种文件清单)，详见命令。 2022-02-16 4.4.1 2.0.5 3.14.3 2022-03-25 4.4.2 2.0.5 3.14.4 2022-05-24 4.4.3 2.0.6 3.16.0 1. 修复存在多个标签时无法移除TrackerError标签的bug；2. 增加企业微信群机器人的通知渠道。3. 升级openssl到1.1.1o，boost到1.78，alpine到3.16.0，升级iyuu镜像中的php7为php8。 2022-05-26 4.4.3.1 2.0.6 3.16.0 2022-08-24 4.4.4 2.0.7 3.16.2 1. 增加remove-track脚本，详见命令；2. 优化del-unseed-dir脚本，现还可以一次性检测多个目录了；3. 增加Gotity通知环境变量GOTIFY_URL GOTIFY_APP_TOKEN GOTIFY_PRIORITY，详见环境变量清单。 2022-08-31 4.4.5 2.0.7 3.16.2 2022-10-24 4.4.5 2.0.8 3.16.2 libtorrent-rasterbar v2.0.8 修复了内存溢出的问题，因此更新一下qbittorrent。 2022-11-09 4.3.9 1.2.18 3.16.2 添加CATEGORY_OR_TAG环境变量，详见环境变量清单；考虑到4.3.9将是许多人的使用版本，将全部新功能重新应用到4.3.9版本中。 2022-11-26 4.3.94.5.0 1.2.182.0.8 3.17.0 alpine升级至3.17.0，升级依赖版本为：boost 1.80.0, openssl 3.0.7, qt 5.16.6, zlib 1.2.13 2022-11-30 4.5.0 1.2.18 3.17.0 把依赖项libtorrent-rasterbar从2.0.8切换为1.2.18，应用#17994.patch修复4.5.0版本简体中文无法启用的bug，需要先切换为英文再切换为中文，或者在启动容器前先将config/qBittorrent.conf中General\\Locale这一行从zh改为zh_CN。 2023-02-13 4.5.1 1.2.18 3.17.2 1. 根据版本的不同自动设置General\\Locale为zh或zh_CN；2. 优化auto-cat report-unseed-files tracker-error逻辑，加快运行速度，对多tracker的，只要有一个正常就不标记为TrackerError（有任何一个tracker处于工作``更新中和未联系都不会视作TrackerError，只有在运行脚本当时那一刻全部tracker处于未工作才会标记）；3. 切换为qt6并增加依赖qt6-qtbase-sqlite；4. 修复#68，#69。 2023-02-28 4.5.2 2.0.8 3.17.2 1. libtorrent-rasterbar切换为2.x；2. 再一次优化tracker-error减少70%时长。 2023-05-29 4.5.3 2.0.9 3.18.0 1. 再一次优化report-seed-files减少70%时长；2. dl-finish不再使用%I传参，而使用%K，已经部署好的使用%I也没有问题（除非会有混合种子或v2种子）；3. 增加gen-dup脚本，详见“命令”章节。 2023-06-19 4.5.4 2.0.9 3.18.2 gen-dup脚本增加总计输出。 2023-08-30 4.5.5 2.0.9 3.18.3 抛弃s6-overlay，直接交给tini来捕获退出信号，在退出/停止容器时qB会自动保存配置和种子进度。定时任务改由低权限运行，日志记录在容器内的/data/diy/crond.log，不再输出到容器控制台。 2023-09-06 4.5.5 2.0.9 3.18.3 为保证用户安全，防止用户因使用反代并代理了127.0.0.1这种情况导致安全性降低，从2023年9月5日更新的镜像开始，创建容器需要新增设置两个环境变量：QB_USERNAME（登陆qBittorrent的用户名）和QB_PASSWORD（登陆qBittorrent的密码）。容器将在创建时使用这两个环境变量去设置（如已存在配置文件则是修改）登陆qBittorent的用户名和密码。如未设置这两个环境变量，或者保持为qBittorrent的默认值（默认用户名：admin，默认密码：adminadmin），则本容器附加的所有脚本、定时任务将无法继续使用。详情。也因此镜像默认即安装好python，不再需要设置INSTALL_PYTHON这个环境变量。 2023-10-23 4.6.0 2.0.9 3.18.4 2023-11-21 4.3.94.6.1 2.0.9 3.18.4 增加一个环境变量TG_API_HOST，同时允许关闭CRON_HEALTH_CHECK和CRON_TRACKER_ERROR，此三项环境变量说明详见 环境变量清单。从此版本起，qBittorrent官方已经设置禁止默认密码，因此请务必设置QB_USERNAME和QB_PASSWORD为非默认值。同步编译的4.3.9版本亦可使用新版本可用的环境变量。 2023-11-28 4.6.2 2.0.9 3.18.4 修复UMASK_SET。 2024-01-17 4.6.3 2.0.9 3.19.0 iyuu相关标签将php升级到8.3.x。 2024-03-25 4.6.4 2.0.10 3.19.1 2024-05-27 4.6.5 2.0.10 3.20.0 因IYUUPlus调整了架构，从此版本起，不再构建集成了IYUUPlus的标签。从此版本起，ENABLE_AUTO_CATEGORY默认值调整为false。 2024-08-20 4.6.6 2.0.10 3.20.2 2024-09-17 4.6.7 2.0.10 3.20.3 下载完成通知也可以设置为下载开始通知，通知中添加主机名。 2024-10-08 5.0.0 2.0.10 3.20.3 修改iyuu-help脚本以适应5.0.0带来的API接口变化。 2024-10-29 5.0.1 2.0.10 3.20.3 2024-11-18 5.0.2 2.0.10 3.20.3 环境变量清单 在下一节的创建命令中，包括已经提及的变量在内，总共以下环境变量，请根据需要参考创建命令中WEBUI_PORT BT_PORT的形式自行补充添加到创建命令中。\n注1：默认值的含义是，你不设置这个环境变量为其他值，那么程序就自动使用默认值。\n注2：所有定时任务cron类的环境变量（以CRON这四个字母开头的）在docker cli中请用一对双引号引起来，在docker-compose中不要增加引号。\n注3：QB_USERNAME和QB_PASSWORD必须改成非默认值，除此以外，其余所有环境变量你都可以不设置，并不影响qbittorrent的使用，但如果你想用得更爽，你就根据你的需要设置。\n以下是所有标签均可用的环境变量：\n序号 变量名 默认值 说明 1 PUID 1000 用户的uid，输入命令id -u可以查到，以该用户运行qbittorrent-nox，群晖用户必须改。 2 PGID 100 用户的gid，输入命令id -g可以查到，以该用户运行qbittorrent-nox，群晖用户必须改。 3 WEBUI_PORT 8080 WebUI访问端口，建议自定义，如需公网访问，需要将qBittorrent和公网之间所有网关设备上都设置端口转发。 4 BT_PORT 34567 BT监听端口，建议自定义，如需达到可连接状态，需要将qBittorrent和公网之间所有网关设备上都设置端口转发。 5 QB_USERNAME admin 4.5.5+必须设置此环境变量，登陆qBittorrent的用户名，请务必不要使用默认值，如使用默认值将无法使用本镜像的全部脚本。 6 QB_PASSWORD adminadmin 4.5.5+必须设置此环境变量，登陆qBittorrent的密码，请务必不要使用默认值，如使用默认值将无法使用本镜像的全部脚本。 7 TZ Asia/Shanghai 时区，可填内容详见：https://meetingplanner.io/zh-cn/timezone/cities 8 INSTALL_PYTHON false 从4.5.5起，默认安装好python，不再需要设置这个环境变量。默认不安装python，如需要python（qBittorrent的搜索功能必须安装python），请设置为true，设置后将在首次启动容器时自动安装好。 9 ENABLE_AUTO_CATEGORY false 4.3.7+可用。是否自动按tracker进行分类，设置为true开启（从4.6.5+起默认值为false，4.6.4-的默认值为true）。 10 CATEGORY_OR_TAG category 4.3.9及4.5.0+可用，当ENABLE_AUTO_CATEGORY=true时，控制自动分类是qBittorrent中的“分类”还是“标签”。设置为category（默认值）为“分类”，设置为tag为“标签”。当设置为tag时，由于标签不是唯一的，无法筛选出没有打上tracker标签的种子，所以运行auto-cat -a和auto-cat -A都将对全部种子按tracker打标签，种子多时比较耗时；而当设置为category时，运行auto-cat -a就只对未分类种子进行分类。 11 DL_FINISH_NOTIFY false 是否在下载完成时向设定的通知渠道发送种子下载完成的通知消息，设置为true开启（从4.6.5+起默认值为false，4.6.4-的默认值为true）。 12 TRACKER_ERROR_COUNT_MIN 3 4.3.7+可用。可以设置的值：正整数。在检测到tracker出错的种子数量超过这个阈值时，给设置的通知渠道发送通知。 13 UMASK_SET 权限掩码umask，指定qBittorrent在建立文件时预设的权限掩码。 14 TG_USER_ID 通知渠道telegram，如需使用需要和 TG_BOT_TOKEN 同时赋值，私聊 @getuseridbot 获取。 15 TG_BOT_TOKEN 通知渠道telegram，如需使用需要和 TG_USER_ID 同时赋值，私聊 @BotFather 获取。 16 TG_PROXY_ADDRESS 4.3.7+可用。给TG机器人发送消息的代理地址，当设置了TG_USER_ID和TG_BOT_TOKEN后可以设置此值，形如：http://192.168.1.1:7890，也可以不设置。 17 TG_PROXY_USER 4.3.7+可用。给TG机器人发送消息的代理的用户名和密码，当设置了TG_PROXY_ADDRESS后可以设置此值，格式为：\u0026lt;用户名\u0026gt;:\u0026lt;密码\u0026gt;，形如：admin:password，如没有可不设置。 18 TG_API_HOST 4.6.1+可用。Telegram 的反代 API，如果设置了就改为向你的反代 API 发送消息，不设置则向官方 API 发送消息。 19 DD_BOT_TOKEN 通知渠道钉钉，如需使用需要和 DD_BOT_SECRET 同时赋值，机器人设置中webhook链接access_token=后面的字符串（不含=以及=之前的字符）。 20 DD_BOT_SECRET 通知渠道钉钉，如需使用需要和 DD_BOT_TOKEN 同时赋值，机器人设置中只启用加签，加签的秘钥，形如：SEC1234567890abcdefg。 21 IYUU_TOKEN 通知渠道爱语飞飞，通过 这里 获取，爱语飞飞的TOKEN。 22 SCKEY 通知渠道ServerChan，通过 这里 获取。 23 PUSHPLUS_TOKEN 4.3.7+可用。通知渠道PUSH PLUS，填入其token，详见 这里。 24 WORK_WECHAT_BOT_KEY 4.3.9及4.4.3+可用。通知渠道企业微信群机器人，填入机器人设置webhook链接中key=后面的字符串，不含key=。 25 GOTIFY_URL 4.3.9及4.4.4+可用。通知渠道Gotify，填入其通知网址，需要和GOTIFY_APP_TOKEN同时赋值。 26 GOTIFY_APP_TOKEN 4.3.9及4.4.4+可用。通知渠道Gotify，填入其TOKEN，需要和GOTIFY_URL同时赋值。 27 GOTIFY_PRIORITY 5 4.3.9及4.4.4+可用。通知渠道Gotify，发送消息的优先级。 28 CRON_HEALTH_CHECK 12 * * * * 宕机检查的cron，在设定的cron运行时如发现qbittorrent-nox宕机了，则向设置的通知渠道发送通知。4.6.1+可以设置为off，意为关闭此定时任务。 29 CRON_AUTO_CATEGORY 32 */2 * * * 自动分类的cron，在设定的cron运行auto-cat -a命令，将所有未分类种子按tracker分类（当CATEGORY_OR_TAG=category时），或将所有种子按tracker打标签（当CATEGORY_OR_TAG=tag时）。对于种子很多的大户人家，建议把cron频率修改低一些，一天一次即可。此cron可以由ENABLE_AUTO_CATEGORY关闭，关闭后不生效。虽然本变量是全版本有效，但控制采用“分类”还是“标签”的变量CATEGORY_OR_TAG仅4.3.9和4.5.0+有效。 30 CRON_TRACKER_ERROR 52 */4 * * * 检查tracker状态是否健康的cron，在设定的cron将检查所有种子的tracker状态，如果有问题就打上TrackerError的标签。在运行的时候比较吃资源，所以对于种子很多的大户人家，或者是对此不那么敏感的用户，建议把cron频率修改低一些，一天一次即可。4.6.1+可以设置为off，意为关闭此定时任务。 31 MONITOR_IP 4.3.8+可用。可设置为局域网设备的ip，多个ip以半角空格分隔，形如：192.168.1.5 192.168.1.9 192.168.1.20。本变量作用：当检测到这些设置的ip中有任何一个ip在线时（检测频率为每分钟），自动启用qbittorent客户端的“备用速度限制”，如果都不在线就关闭“备用速度限制”。“备用速度限制”需要事先设置好限制速率，建议在路由器上给需要设置的设备固定ip。在docker cli中请使用一对双引号引起来，在docker-compose中不要使用引用。 32 CRON_ALTER_LIMITS 4.3.8+可用。启动和关闭“备用速度限制“的cron，主要针对多时段限速场景，当设置了MONITOR_IP时本变量的cron不生效（因为会冲突）。详见 相关问题13 问题13。 33 CRON_IYUU_HELP 4.3.8+可用。IYUUPlus辅助任务的cron，自动重校验、自动恢复做种，详见 相关问题14。 34 EXTRA_PACKAGES 4.3.9+可用。你需要安装的其他软件包，形如htop nano nodejs，多个软件包用半角空格分开，在docker cli中请用一对双引号引起来，在docker-compose中不要增加引号。 以下是仅iyuu标签额外可用的环境变量：\n序号 变量名 默认值 说明 1 IYUU_REPO_URL https://gitee.com/ledc/iyuuplus.git 指定从哪里获取IYUUPlus的代码，默认从gitee更新，如果你想从github更新，可以设置为：https://github.com/ledccn/IYUUPlus.git 创建 群晖 安装后访问http://ip:8080。如想使用集成了IYUUPlus的qBittorrent（自动设置好IYUUPlus中的下载器），请使用docker cli以命令行方式部署。\n命令行docker cli 除WEBUI_PORT BT_PORT PUID PGID这几个环境变量外，如果你还需要使用其他环境变量，请根据环境变量清单按照-e 变量名=\u0026quot;变量值\u0026quot; \\的形式自行添加在创建命令中。\narmv7设备如若无法使用网络，可能是seccomp问题，详见 这里。可以在创建命令中增加一行--security-opt seccomp=unconfined \\ 来解决。\n创建完成后请访问http://\u0026lt;IP\u0026gt;:\u0026lt;WEBUI_PORT\u0026gt;（如未修改，对安装机默认是http://127.0.0.1:8080）来对qbittorrent作进一步设置，初始用户名密码：admin/adminadmin。如要在公网访问，请务必修改用户名和密码。\n针对iyuu标签，创建后可访问http://\u0026lt;IP\u0026gt;:8787进行IYUUPlus设置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 ## latest标签或unstable标签 docker run -dit \\ -v $PWD/qbittorrent:/data `# 冒号左边请修改为你想在本地保存的路径，这个路径用来保存你个人的配置文件` \\ -e PUID=\u0026#34;1000\u0026#34; `# 输入id -u可查询，群晖必须改` \\ -e PGID=\u0026#34;100\u0026#34; `# 输入id -g可查询，群晖必须改` \\ -e WEBUI_PORT=\u0026#34;8080\u0026#34; `# WEBUI控制端口，可自定义` \\ -e BT_PORT=\u0026#34;34567\u0026#34; `# BT监听端口，可自定义` \\ -p 8080:8080 `# 冒号左右一样，要和WEBUI_PORT一致，命令中的3个8080要改一起改` \\ -p 34567:34567/tcp `# 冒号左右一样，要和BT_PORT一致，命令中的5个34567要改一起改` \\ -p 34567:34567/udp `# 冒号左右一样，要和BT_PORT一致，命令中的5个34567要改一起改` \\ --tmpfs /tmp \\ --restart always \\ --name qbittorrent \\ --hostname qbittorrent \\ nevinee/qbittorrent `# 如想参与qbittorrent测试工作，可以指定测试标签nevinee/qbittorrent:unstable` ## iyuu标签 docker run -dit \\ -v $PWD/qbittorrent:/data `# 冒号左边请修改为你想在本地保存的路径，这个路径用来保存你个人的配置文件` \\ -e PUID=\u0026#34;1000\u0026#34; `# 输入id -u可查询，群晖必须改` \\ -e PGID=\u0026#34;100\u0026#34; `# 输入id -g可查询，群晖必须改` \\ -e WEBUI_PORT=\u0026#34;8080\u0026#34; `# WEBUI控制端口，可自定义` \\ -e BT_PORT=\u0026#34;34567\u0026#34; `# BT监听端口，可自定义` \\ -p 8080:8080 `# 冒号左右一样，要和WEBUI_PORT一致，命令中的3个8080要改一起改` \\ -p 34567:34567/tcp `# 冒号左右一样，要和BT_PORT一致，命令中的5个34567要改一起改` \\ -p 34567:34567/udp `# 冒号左右一样，要和BT_PORT一致，命令中的5个34567要改一起改` \\ -p 8787:8787 `# IYUUPlus的WebUI控制端口` \\ --tmpfs /tmp \\ --restart always \\ --name qbittorrent \\ --hostname qbittorrent \\ nevinee/qbittorrent:iyuu docker compose 新建compose.yml文件如下（docker compose安装方法），创建好后以docker-compose up -d(旧版)或docker compose up -d(新版)命令启动即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 version: \u0026#34;2.0\u0026#34; services: qbittorrent: image: nevinee/qbittorrent # 如想参与测试工作可以指定nevinee/qbittorrent:unstable，如想使用集成了iyuu的版本请指定nevinee/qbittorrent:iyuu container_name: qbittorrent restart: always tty: true network_mode: bridge hostname: qbitorrent stop_grace_period: 10m # 让qBittorrent程序自行退出后再关闭/删除/重启容器的最长时间，如不设置，则docker默认10秒，这时，种子多的qBittorrent可能还没有完全保存好全部需要保存的信息。 volumes: - ./data:/data # 配置保存目录 tmpfs: - /tmp environment: # 下面未列出的其他环境变量请根据环境变量清单自行添加 - WEBUI_PORT=8080 # WEBUI控制端口，可自定义 - BT_PORT=34567 # BT监听端口，可自定义 - PUID=1000 # 输入id -u可查询，群晖必须改 - PGID=100 # 输入id -g可查询，群晖必须改 ports: - 8080:8080 # 冒号左右一致，必须同WEBUI_PORT一样，本文件中的3个8080要改一起改 - 34567:34567 # 冒号左右一致，必须同BT_PORT一样，本文件中的5个34567要改一起改 - 34567:34567/udp # 冒号左右一致，必须同BT_PORT一样，本文件中的5个34567要改一起改 #- 8787:8787 # 如使用的是nevinee/qbittorrent:iyuu标签，请解除本行注释 #security_opt: # armv7设备请解除本行和下一行的注释 #- seccomp=unconfined 如若想将qbittorrent建立在已经创建好的macvlan网络上，可以按如下方式创建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 version: \u0026#34;2.0\u0026#34; services: qbittorrent: image: nevinee/qbittorrent # 如想参与测试工作可以指定nevinee/qbittorrent:unstable，如想使用集成了iyuu的版本，请指定nevinee/qbittorrent:iyuu container_name: qbittorrent restart: always tty: true networks: \u0026lt;你的macvlan网络名称\u0026gt;: ipv4_address: \u0026lt;你想设置的ip\u0026gt; aliases: - qbittorrent dns: # docker是无法为macvlan网络提供dns解析服务的，要想正常在macvlan网络上发通知，请给容器添加dns服务器，你也可以直接使用你的网关ip作为dns服务器 - 223.5.5.5 - 114.114.114.114 - 1.2.4.8 hostname: qbitorrent stop_grace_period: 10m # 让qBittorrent程序自行退出后再关闭/删除/重启容器的最长时间，如不设置，则docker默认10秒，这时，种子多的qBittorrent可能还没有完全保存好全部需要保存的信息。 volumes: - ./data:/data tmpfs: - /tmp environment: # 下面未列出的其他环境变量请根据环境变量清单自行添加 - WEBUI_PORT=8080 # WEBUI控制端口，可自定义 - BT_PORT=34567 # BT监听端口，可自定义 - PUID=1000 # 输入id -u可查询，群晖必须改 - PGID=100 # 输入id -g可查询，群晖必须改 #security_opt: # armv7设备请解除本行和下一行的注释 #- seccomp=unconfined networks: \u0026lt;你的macvlan网络名称\u0026gt;: external: true 创建完成后请访问http://\u0026lt;IP\u0026gt;:\u0026lt;WEBUI_PORT\u0026gt;（如未修改，对安装机默认是http://127.0.0.1:8080）来对qbittorrent作进一步设置，初始用户名密码：admin/adminadmin。如要在公网访问，请务必修改用户名和密码。\n针对iyuu标签，创建后可访问http://\u0026lt;IP\u0026gt;:8787进行IYUUPlus设置。\n目录说明 如果按照上述任何一种部署方式，在映射的目录下会有以下文件夹：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /data # 基础路径在容器内为/data，下面所有文件夹均处于/data的下一层，基础路径在宿主机上为你创建容器时映射的 ├── cache # qbittorrent的缓存目录 ├── certs # 用来存放ssl证书，默认是空的，可另外使用acme.sh来申请ssl证书 ├── config # 所有的配置文件保存目录 │ ├── qBittorrent.conf # **配置文件，很重要，如需恢复配置此文件必须保留** │ ├── qBittorrent-data.conf # **上传下载数据统计文件，如需恢复配置此文件必须保留** │ └── rss # **rss的配置文件保存目录，如需恢复配置此目录必须保留** ├── data # 所有的数据文件保存目录 │ ├── BT_backup # **当高级设置中恢复文件选择为\u0026#34;Fastresume files\u0026#34;时，种子和快速恢复文件保存目录，如需恢复做种数据此目录必须保留** │ ├── torrents.db # **当高级设置中恢复文件选择为\u0026#34;SQLite database\u0026#34;时，种子和快速恢复数据的数据库文件，如需恢复做种数据此文件必须保留** │ ├── GeoDB # IP数据保存目录 │ ├── logs # 日志文件保存目录 │ ├── nova3 # 启用qBittorrent搜索功能后相关文件保存目录 │ └── rss # rss订阅下载文件保存目录 ├── diy # 存放你自己编写的脚本的目录，diy.sh需要存放在此 ├── downloads # 默认下载目录 ├── iyuu_db # 仅iyuu标签有此目录，用来保存IYUUPlus的配置文件，IYUUPlus用户须保留此文件夹 ├── logs -\u0026gt; data/logs # 只是个软连接，连接到容器内的/data/data/logs ├── temp # 下载文件临时存放目录，默认在配置中未启用 ├── torrents # 保存种子文件目录，默认在配置中未启用 ├── watch # 监控目录，监控这个目录下的.torrent文件并自动下载，默认在配置中未启用 └── webui # 存放其他webui文件的目录，需要自己存放，默认在配置中未启用 有两个星号标记的文件或目录是重要目录，恢复数据必须要有这几个。\n在 这里 可以查阅所有可用的非官方webui。\n相关问题 使用此镜像会导致封号吗 此镜像未修改qbittorrent客户端官方任何信息，在和pt站tracker服务器交互时反馈的一切信息均是qbittorrent官方原版反馈的信息，此镜像只是基于qbittorrent额外增加了一些脚本而已。增加的脚本全部代码在 这里 可以查看，不会因为使用此镜像导致pt账号被封。\n如何在运行 dl-finish \u0026ldquo;%K\u0026rdquo; 时调用自定义脚本 此功能可用版本：4.3.7+；\n在4.5.0以前的版本不能使用%K，只能使用%I；\n只要你将名为diy.sh的shell脚本放在映射目录下的diy文件夹下即可，容器内路径为/data/diy/diy.sh（hash已存储在名为torrent_hash的变量中，可通过此值获取其他信息）。\n如想传入除“%K”种子ID之外的其他参数，可以在 设置-\u0026gt;下载-\u0026gt;Torrent 完成时运行外部程序 下填入这种形式：dl-finish \u0026quot;%K\u0026quot; \u0026quot;%N\u0026quot; \u0026quot;%L\u0026quot; \u0026quot;%F\u0026quot;，必须保证\u0026rdquo;%K\u0026quot;是第一个参数，后面的参数根据你自己需要调整。在diy.sh中，\u0026quot;%N\u0026quot; \u0026quot;%L\u0026quot; \u0026quot;%F\u0026quot;分别通过$2 $3 $4调用。如：cmd \u0026quot;$2\u0026quot; \u0026quot;$3 \u0026quot;$4\u0026quot;。$2, $3, $4分别指传入的第2, 第3, 第4个参数，分别对应\u0026quot;%N\u0026quot; \u0026quot;%L\u0026quot; \u0026quot;%F\u0026quot;。\n假如你要调用其他语言的脚本，比如python，可以在diy.sh中写上python3 /data/diy/your_python_scripts.py $torrent_hash即可。如需要传入更多参数，请参考上一条在“Torrent 完成时运行外部程序”填入形如dl-finish \u0026quot;%K\u0026quot; \u0026quot;%N\u0026quot; \u0026quot;%L\u0026quot; \u0026quot;%F\u0026quot;的形式，然后在diy.sh中写上python3 /data/diy/your_python_scripts.py \u0026quot;$2\u0026quot; \u0026quot;$3\u0026quot; \u0026quot;$4\u0026quot;。\n如需要下载完成后自动触发EMBY/JELLYFIN扫描媒体库，触发ChineseSubFinder自动为刚刚下载完成的视频自动下载字幕，请按照 这里 操作。\n如何优雅的关闭qbittorrent容器 暴力强制关闭qbittorrent容器自然是容易丢失任务的，所以在关闭前应当先将所有种子暂停，过一会再关闭容器。这时，所有的配置文件和torrent恢复文件也都是暂停后的状态，然后再新建容器或重新部署，启动后再开始所有任务。\n还有一点要注意，千万不要在有下载任务时关闭或重启qbittorrent容器。\n如何从其他作者的镜像/套件版转移至本镜像 如果启用了ssl/https，请先在原qbittorrent的webui中禁用，或者将qBittorrent.conf中WebUI\\HTTPS\\Enabled=true改为WebUI\\HTTPS\\Enabled=false。\n请注意要优雅的关闭旧容器后再处理配置文件。\n进入原来容器的映射目录（或原套件版配置文件保存目录，可能是隐藏的）下，在config下分别找到qBittorrent.conf qBittorrent-data.conf rss，在data下找到BT_backup或torrents.db，然后将其参考上面的目录树放在新容器的映射目录下，然后在创建容器时，保证新容器中的下载文件的保存路径和旧容器一致，并新建容器即可。\n举例说明如何保证新容器中的下载文件的保存路径和旧容器一致，比如旧容器中下载了一个 xxx.2020.BluRay.1080p.x264.DTS-XXX，保存路径为/movies（宿主机上的真实路径为/volume1/home/id/movies），那么在新建新容器时，给新容器增加一个路径映射：/volume1/home/id/movies:/movies　即可。\n注意新容器的PUID/PGID和要旧容器保持一致。\n注意在 设置 -\u0026gt; 下载 中勾选 Torrent 完成时运行外部程序 并填入 dl-finish \u0026quot;%K\u0026quot;，如需要https要重新设置证书路径。\n可不可以不使用默认下载目录 默认下载目录是/data/downloads，如不想使用默认下载目录，可以额外映射其他路径，比如映射/volume1/media:/media，然后在qbittorrent中设置默认下载目录为/media，也可以在每次下载时自己输入下载目录为/media。\n遗忘登陆密码如何重置 重启一次容器即可，启动时容器会自动以你创建容器时定义的环境变量QB_USERNAME和QB_PASSWORD去设置登陆qBittorrent的用户名和密码。\n如何与emby, jellyfin, plex等等配合使用 将需要配合使用的容器的环境变量PUID/PGID设置为一样的即可。\n启用了其他非官方webui，导致webui打不开，如何关闭 1 2 3 4 5 # 进入容器 docker exec -it qbittorrent bash # 关闭备用webui source /usr/local/bin/share; $cmd_curl_post -d \u0026#39;json={\u0026#34;alternative_webui_enabled\u0026#34;:false}\u0026#39; $api_url_base/app/setPreferences 如何自动更新容器 安装watchtower即可，详见 这里\n安装了watchtower，如何让qbittorrent不被watchtower自动更新 方法1：部署qbittorrent容器时，直接指定标签，如nevinee/qbittorrent:4.3.7；\n方法2（推荐）：在部署时在命令中添加一个label：com.centurylinklabs.watchtower.enable=false：\ndocker cli：\n1 --label com.centurylinklabs.watchtower.enable=false \\ docker-compose:\n1 2 labels: com.centurylinklabs.watchtower.enable: false 为何建议将qbittorrent安装在macvlan网络上 可以在网关上给qbittorrent所在ip独立设置限速;\n如果有用openwrt时，可以让qbittorrent所在ip跳过代理。\n将qbittorrent安装在macvlan网络上时，如何使用IYUUAutoReseed自动辅种 将两个容器都安装在同一个macvlan网络上即可，或者直接安装nevinee/qbittorrent:iyuu标签。\n如何使用 CRON_ALTER_LIMITS 这个环境变量 4.3.8+可用。\n该功能主要提供给多时段限速场景使用，请在qbittorrent客户端中先设置好”备用速度限制“的限制速率。\n当设置了有效的MONITOR_IP时，CRON_ALTER_LIMITS的cron不生效（因为会冲突）。\n设置形式如：0 5 * * *:0 18 * * *|0 8 * * *:0 22 * * *，|前面的cron是启用“备用速度限制”的时间点，|后面的cron是关闭“备用速度限制”的时间点。需要在一天中多次启用“备用速度限制”的，以:分隔每个cron，可以任意个cron，需要多次关闭“备用速度限制”的同样以:分隔每个cron。\n比如需要在周一至周五的5:00-8:00、17:30-23:30，以及周六、周日的9:00-23:30进行限速，那么可以设置CRON_ALTER_LIMITS为0 5 * * 1-5:30 17 * * 1-5:0 9 * * 0,6|0 8 * * 1-5:30 23 * * *。\n比如需要在周一至周五的17:30-22:00，以及周六、周日的8:30-23:00进行限速，那么可以设置CRON_ALTER_LIMITS为30 17 * * 1-5:30 8 * * 0,6|0 22 * * 1-5:0 23 * * 0,6。\n在docker cli中请使用一对双引号引起来，在docker-compose.yml中请勿增加引号。\n如何使用 CRON_IYUU_HELP 这个环境变量 4.3.8+可用。\n在设置的时间点执行iyuu-help命令，实现以下功能：\n检查下载清单（就是qbittorrent筛选“下载”的清单），检测该清单中处于暂停状态、并且下载完成率为0%（辅种的种子在校验前也是0%）的种子，将这些种子请求重新校验。已经请求过校验并且完成率大于0%的种子不会再次校验。 检查暂停清单（就是qbittorrent筛选“暂停”的清单），检测该清单中100%下载完成/100%校验通过的种子，将这些种子恢复做种。校验未通过不达100%完成率的种子不会启动，仍然保持暂停状态。 配合IYUUAutoReseed，将CRON_IYUU_HELP设置在IYUUAutoReseed自动辅种任务的cron以后，并运行若干次即可（因为校验比较费时，所以要多次运行）。\n比如你IYUUAutoReseed辅种任务的cron是22 7 * * *，你想从辅种任务3分钟后，每10分钟运行一次，共运行4次，那么可以设置CRON_IYUU_HELP为：25-55/10 7 * * *。\n在docker cli中请使用一对双引号引起来，在docker-compose.yml中请勿增加引号。\nqBittorrent使用https的webui时，iyuu如何连接 当qBittorrent使用https的webui时，iyuu连接qBittorrent需要使用https://\u0026lt;域名\u0026gt;:\u0026lt;端口\u0026gt;的形式，不能使用https://\u0026lt;IP\u0026gt;:\u0026lt;端口\u0026gt;，所以需要在创建iyuu容器（使用nevinee/qbittorrent:iyuu时同样也需要）指定域名和ip的对应关系。\n命令行创建iyuu容器时时，增加--add-host \u0026lt;域名\u0026gt;:\u0026lt;qBittorrent容器的IP\u0026gt;，其中域名是你在公网上访问qBittorrent的webui的域名，如果直接使用的nevinee/qbittorrent:iyuu标签，就是--add-host \u0026lt;域名\u0026gt;:127.0.0.1。\ndocker compose创建时，增加以下内容：\n1 2 extra_hosts: - \u0026#34;\u0026lt;域名\u0026gt;:\u0026lt;qBittorrent容器的IP\u0026gt;\u0026#34; ## 如果直接使用的`nevinee/qbittorrent:iyuu`标签，IP就是127.0.0.1 qBittorrent占用了巨大的内存，如何调整 你所见到的占用巨大的内存并不是真的占用了，使用docker stats qbittorrent输出的内存占用更准确一点，其他方式输出的内存占用会非常的大。因为libtorrent-rasterbar v2.x把内存使用交给内核来处理，内核会自己根据内存大小和读取频次来自动决定怎么去缓存，所以不要被看起来庞大的内存占用给吓着了。详见libtorrent-rasterbar作者的原话。\n谷歌翻译如下：\n总结一下，libtorrent2.0使用内存映射文件。在除windows之外的所有现代操作系统上，在块设备级别使用统一的页面缓存，其中匿名内存（由swapfile支持）和内存映射文件（包括共享库，运行可执行文件）都是同一缓存的一部分。Linux可能是决定如何在物理RAM中平衡这些页面的最复杂的工具。 使用内存映射文件的好处主要有： 内核（它知道机器有多少物理RAM可用）最了解何时以及以何种顺序刷新缓存。也许更重要的是，决定保留读缓存的数量和时间。 某些类型的存储可以由CPU直接寻址，就像它是RAM一样，绕过了许多内核基础设施，并提供了非常高的性能。（linux称此DAX） 此外，当报告libtorrent（特别是mmap磁盘后端）中的问题时，仅仅指出vmstats数字表明内核决定使用大量物理内存进行磁盘缓存是不够的。这是内存映射磁盘后端的一个特性。\nqB老是不监听IPv6地址，怎么办？ 有很多原因会导致qBittorrent没有监听IPv6，比如你的IPv6地址变了，比如启动qBittorrent时还没有获取到IPv6等等。看看有没有成功监听到IPv6，只需要在日志中查看本次启动后有没有出现这样的字样即可：\n1 检测到外部 IP。IP：“240e:1234:5678:abcd:ef12:3456:7890:abcd” 如果没有出现类似这样的日志，或者出的日志中的IPv6地址不是当前最新的地址，那么你可以操作：先将 “设置-\u0026gt;高级-\u0026gt;绑定到的可选IP地址” 选择最新的IPv6地址，保存一次；然后再将其设置为 “所有地址” 后再重新保存一次。过一会日志中就会出现正常的信息了。\n命令 自动运行的命令（所有标签可用，由设置的cron或在下载完成时自动运行，当然也可以手动运行） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 发送通知 docker exec qbittorrent notify \u0026#34;测试消息标题\u0026#34; \u0026#34;测试消息通知内容\u0026#34; # 将种子按tracker进行分类，由CRON_AUTO_CATEGOR设置的cron来调用 docker exec qbittorrent auto-cat -a # 由程序自动调用，也可手动运行。当CATEGORY_OR_TAG=category时，将所有未分类的种子按tracker分类；当CATEGORY_OR_TAG=tag时，对所有种子按tracker打标签 docker exec qbittorrent auto-cat -A # 需要手动运行。当CATEGORY_OR_TAG=category时，将所有种子按tracker分类；当CATEGORY_OR_TAG=tag时，对所有种子按tracker打标签 # 将指定种子按tracker进行分类，会自动在下载完成时运行一次（由 dl-finish \u0026lt;hash\u0026gt; 命令调用） docker exec qbittorrent auto-cat -i \u0026lt;hash\u0026gt; # hash可以在种子详情中的\u0026#34;普通\u0026#34;标签页上查看到 # 下载完成时将种子分类，并发送通知，已经在配置文件中填好了 docker exec qbittorrent dl-finish \u0026lt;hash\u0026gt; # hash可以在种子详情中的\u0026#34;普通\u0026#34;标签页上查看到 # 检查qbittorrent是否宕机，如宕机则发送通知，由CRON_HEALTH_CHECK设置的cron来调用 docker exec qbittorrent health-check # 检查所有种子的tracker状态是否有问题，如有问题，给该种子添加一个 TrackerError 的标签，由CRON_TRACKER_ERROR设置的cron来调用 # 有任何一个tracker处于`工作中``更新中`和`未联系`都不会视作`TrackerError`，只有在运行脚本当时那一刻全部tracker处于`未工作`才会标记 docker exec qbittorrent tracker-error # 每分钟检测MONITOR_IP设置的ip是否在线，如有任何一个ip在线，则启用“备用速度限制”，4.3.8+可用。 docker exec qbittorrent detect-ip ## 启用可关闭“备用速度限制”，4.3.8+可用，由CRON_ALTER_LIMITS设置的cron来调用 docker exec qbittorrent alter-limits on # 启用“备用速度限制” docker exec qbittorrent alter-limits off # 关闭“备用速度限制” ## IYUUAutoReseed辅助任务，自动重校验、自动恢复做种，4.3.8+可用，由CRON_IYUU_HELP设置的cron来调用 docker exec qbittorrent iyuu-help 需要手动运行的命令（所有标签可用） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 查看qbittorrent日志，也可以直接在portainer控制台中看到 docker logs -f qbittorrent # 批量修改tracker，详见效果图，4.3.7+可用，有两种使用方式，请运行下面命令查看两种方式 docker exec -it qbittorrent change-tracker -h # 批量删除tracker，4.4.4+可用，有两种使用方式，请运行下面命令查看两种方式 docker exec -it qbittorrent remove-tracker -h # 检测指定文件夹下没有在qbittorrent客户端中做种或下载的子文件夹/子文件，由用户确认是否删除，详见效果图，4.3.8+可用 # 从4.4.4起，更改成可以一次性检测多个目录 docker exec -it qbittorrent del-unseed-dir # 当CATEGORY_OR_TAG=category时，将所有种子按tracker分类；当CATEGORY_OR_TAG=tag时，对所有种子按tracker打标签。4.3.9+可用 docker exec qbittorrent auto-cat -A # 生成本qBittorrent客户端中所有做种文件清单，4.3.9+可用 docker exec -it qbittorrent report-seed-files # 生成指定路径下没有在本qBittorrent客户端做种的文件清单，4.3.9+可用 docker exec -it qbittorrent report-unseed-files # 分析指定目录的重复做种率（辅种率），具体说明请运行下列命令，4.5.3+可用 docker exec -it qbittorrent gen-dup 仅“iyuu”标签可用的命令 1 2 3 4 5 # 更新IYUUPlus脚本 docker exec -it qbittorrent git -C /iyuu pull # 重启IYUUPlus docker exec -it qbittorrent php /iyuu/start.php restart -d 参考 crazymax/qbittorrent , 参考了Dockerfile;\n80x86/qbittorrent, 借鉴了标签和分类的理念。\n源代码、问题反馈、意见建议 如果镜像好用，请点亮star。全套代码见 Github 或 Gitee。如有使用上的问题，或者有其他好的功能建议，请直接在本文下方评论，或者在 Github这里 或 Gitee这里 提交。\n提交bug必须反馈的信息，如不反馈以下信息，我就直接无视了。\n创建命令或 docker-compose.yml 文件，请自行对密码打码；\n使用的docker镜像的tag，以及qBittorrent的版本；\n进入容器后运行 bash -x /usr/local/bin/\u0026lt;命令名\u0026gt; 如 bash -x /usr/local/bin/report-seed-files 的输出（什么命令出错你就反馈什么命令的内容），请自行对密码打码。\n","date":"2023-10-18T00:00:00+08:00","image":"https://evine.win/p/docker-install-qbittorrent/notify_hu9071491819000094549.png","permalink":"https://evine.win/p/docker-install-qbittorrent/","title":"一款更懂你的 qbittorrent docker 镜像"},{"content":"docker在一块网卡上创建多个macvlan子网，不可以进行多次创建，需要在一次创建中把多个子网同时创建好。说明及创建命令如下：\n一个subnet对应一个gateway，gateway必须在subnet的范围内，直接改为你所使用的真实的gateway即可。这样可以不同的subnet设置不同的gateway，控制不同的容器走不同的线路（比如有的需要代理，有的不能代理）。\n--subnet=fe80::/64 --ipv6可以打开ipv6，无需设置公网ipv6的subnet，只要这样设置在这个macvlan网络上的容器就能自动获取到公网ipv6。\n--opt parent=eth0指定本macvlan网络绑定到父级网卡eth0上。\n--opt com.docker.network.bridge.name=mymacvlan指定macvlan网络名称为mymacvlan。\n最后的mymacvlan是docker中的网络名称。\n1 2 3 4 5 6 7 8 9 10 docker network create \\ --driver macvlan \\ --subnet=10.0.0.0/24 --gateway \u0026#34;10.0.0.2\u0026#34; \\ --subnet=10.0.1.0/24 --gateway \u0026#34;10.0.1.1\u0026#34; \\ --subnet=10.0.2.0/24 --gateway \u0026#34;10.0.2.254\u0026#34; \\ --subnet=fe80::/64 --ipv6 \\ --opt parent=eth0 \\ --opt macvlan_mode=bridge \\ --opt com.docker.network.bridge.name=mymacvlan \\ mymacvlan ","date":"2023-09-06T00:00:00+08:00","image":"https://evine.win/p/docker-create-macvlan-with-multi-subnet/docker-poster_hu14098955999488624441.jpg","permalink":"https://evine.win/p/docker-create-macvlan-with-multi-subnet/","title":"docker在一块网卡上创建多个macvlan子网"},{"content":" 关键词：docker buildx cache gc prune 构建 缓存 策略 缓存时间 缓存大小\n新建buildkit配置文件$HOME/.docker/buildx/buildkitd.default.toml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [worker.oci] enabled = true gc = true gckeepstorage = 20480 # 单位：MiB [[worker.oci.gcpolicy]] keepBytes = 21474836480 # 单位：B，下同 keepDuration = 7200 # 单位：s，下同 filters = [ \u0026#34;type==source.local\u0026#34;, \u0026#34;type==exec.cachemount\u0026#34;, \u0026#34;type==source.git.checkout\u0026#34;] [[worker.oci.gcpolicy]] keepBytes = 32212254720 keepDuration = 86400 filters = [ \u0026#34;type==source.local\u0026#34;, \u0026#34;type==exec.cachemount\u0026#34;, \u0026#34;type==source.git.checkout\u0026#34;] [[worker.oci.gcpolicy]] all = true keepBytes = 42949672960 上述配置可以按时间、按上限设置多个层级的worker.oci.gcpolicy，按照不同时间、不同上限来删除buildx的构建缓存。如果是本地构建，主要的缓存类型是source.local和exec.cachemount。详细配置请见：buildkit。\n如果之前创建过名为builder的实例，先删除：\n1 docker buildx rm builder 然后重新创建一个名为builder的实例：\n1 2 3 docker run --privileged --rm tonistiigi/binfmt --install all docker buildx create --name builder --driver=docker-container --use --bootstrap docker buildx inspect 上面最后一个命令docker buildx inspect输出如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 Name: builder Driver: docker-container Last Activity: 2023-09-06 02:55:47 +0000 UTC Nodes: Name: builder0 Endpoint: unix:///var/run/docker.sock Status: running Buildkit: v0.12.1 Platforms: linux/amd64, linux/amd64/v2, linux/amd64/v3, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/mips64le, linux/mips64, linux/arm/v7, linux/arm/v6 Labels: org.mobyproject.buildkit.worker.executor: oci org.mobyproject.buildkit.worker.hostname: bcff51b12dca org.mobyproject.buildkit.worker.network: host org.mobyproject.buildkit.worker.oci.process-mode: sandbox org.mobyproject.buildkit.worker.selinux.enabled: false org.mobyproject.buildkit.worker.snapshotter: overlayfs GC Policy rule#0: All: false Filters: type==source.local type==exec.cachemount type==source.git.checkout Keep Duration: 2h0m0s Keep Bytes: 20GiB GC Policy rule#1: All: false Filters: type==source.local type==exec.cachemount type==source.git.checkout Keep Duration: 24h0m0s Keep Bytes: 30GiB GC Policy rule#2: All: true Keep Bytes: 40GiB 可以看出缓存策略已经设置为自己的了。\n","date":"2023-08-30T00:00:00+08:00","image":"https://evine.win/p/docker-buildx-set-cache-gcpolicy/docker-poster_hu14098955999488624441.jpg","permalink":"https://evine.win/p/docker-buildx-set-cache-gcpolicy/","title":"docker buildx 设置构建缓存策略（设置缓存保存时间及大小上限）"},{"content":"前言 近期在PVE中发现，只要连接数一多，PVE会有两个单核的使用率明显比其他核超过一大截。经过查询资料发现，这是因为我的 RealTEK RTL8125 2.5GB 网卡默认加载的驱动是r8169，它并没有开启网卡多队列等特性。导致一个网卡的软中断只能使用固定的一个核心开接收和发送数据。\n查看网卡加载的是什么驱动：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## 看看网卡的pci编号 $ lspci | grep RTL8125 22:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller (rev 05) 2a:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller (rev 05) ## 看看网卡加载的驱动 $ lspci -s 22:00.0 -k # 22:00.0这块网卡 22:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller (rev 05) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller Kernel driver in use: r8169 Kernel modules: r8169 $ lspci -s 2a:00.0 -k # 2a:00.0这块网卡 2a:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller (rev 05) Subsystem: Micro-Star International Co., Ltd. [MSI] RTL8125 2.5GbE Controller Kernel driver in use: r8169 Kernel modules: r8169 查看网卡软中断数量：\n1 2 3 4 $ cat /proc/interrupts | grep -P \u0026#39;eth|CPU0\u0026#39; # 我的网卡名叫eth0、eth1 CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 CPU8 CPU9 CPU10 CPU11 CPU12 CPU13 CPU14 CPU15 51: 0 0 0 0 0 0 0 0 0 631894756 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 eth0 59: 0 0 0 0 0 0 0 0 0 0 0 932824696 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 eth1 也可以用这个命令看看软件中断（%soft）是不是大量集中在某个核心上。\n1 $ mpstat -P ALL 1 5 连接数多的时候，甚至这两个核心的使用率能达到80%，而其他核心才不到20%。所以还是有必要将该网卡驱动从Linux默认的r8169切换到官方驱动上。\n使用官方驱动 已经有大佬把官方驱动打包成了dkms deb包：https://github.com/awesometic/realtek-r8125-dkms，不过该deb包并没有打开网卡多队列，所以我FORK了一份，启用TX多队列及RSS，禁用ASPM，发布在：https://github.com/devome/r8125-dkms ，直接使用即可。先下载Release中最新的deb文件，再按下方流程安装即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 ## 更新内核、安装依赖 $ apt update $ apt upgrade $ apt install -y dkms pve-headers #pve 8.0.4+建议将pve-headers替换为proxmox-default-headers ## 安装headers $ headers=$(dpkg -l | awk \u0026#39;/^ii.+kernel-[0-9]+\\.[0-9]+\\.[0-9]/{gsub(/-signed/, \u0026#34;\u0026#34;); gsub(/kernel/, \u0026#34;headers\u0026#34;); print $2}\u0026#39; | tr \u0026#34;\\n\u0026#34; \u0026#34; \u0026#34;) $ eval apt install -y $headers ## 安装刚刚下载好的deb包，此命令只会为当前系统所使用的内核以及刚刚安装的最新内核（也可能当前所使用的内核就是最新内核）安装驱动 $ dpkg -i r8125-dkms_*.deb # 如通配符会匹配多个时亦可指定具体的文件名 ## 如果想为那些既不是系统当前所使用的内核，也不是刚刚安装的最新内核安装驱动，需要手动指定安装 ## 看看哪些内核安装好了驱动 $ dkms status ## 列出全部内核版本kernel_version，找出那些还没有安装驱动的内核 $ dpkg -l | awk \u0026#39;/^ii.+kernel-[0-9]+\\.[0-9]+\\.[0-9]/{gsub(/proxmox-kernel-|pve-kernel-|-signed/, \u0026#34;\u0026#34;); print $2}\u0026#39; ## 手动指定驱动版本（在deb文件名中有体现）和内核版本（从上一句命令的输出中），zsh按tab可自动补全，比如：dkms install r8125/9.011.01 -k 6.2.16-5-pve $ dkms install r8125/\u0026lt;driver_version\u0026gt; -k \u0026lt;kernel_version\u0026gt; ## 卸载不再需要的headers $ eval apt-mark auto $headers $ apt autopurge ## 禁用r8169驱动 $ echo \u0026#34;blacklist r8169\u0026#34; \u0026gt;\u0026gt; /etc/modprobe.d/dkms.conf ## 重启 $ update-grub $ update-initramfs -u -k all $ reboot ## 再次查看网卡加载的驱动，现在加载的是r8125了 $ lspci -s 22:00.0 -k 22:00.0 Ethernet controller: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller (rev 05) Subsystem: Realtek Semiconductor Co., Ltd. RTL8125 2.5GbE Controller Kernel driver in use: r8125 Kernel modules: r8169, r8125 如何更新驱动 如果已经安装好了 r8125-dkms 驱动，未来升级时可以无需重启PVE。如需要不重启PVE来更新驱动，并且你的 RTL8125B 网口作为了管理口，那么建议直接物理操作PVE（也就是不要通过ssh）来达到更新驱动的目标。\n1 2 3 4 5 6 7 #!/usr/bin/env bash modprobe -r r8125 insmod \u0026#34;/lib/modules/$(uname -r)/updates/dkms/r8125.ko\u0026#34; systemctl restart networking.service ## 然后自行重启全部虚拟机 如果你的 RTL8125B 网口作为了管理口，并且无法物理操作PVE，那么也可以将上述命令保存到一个脚本文件 reload.sh 中，增加可执行权限后在 tmux 中运行它（不能直接在ssh中运行）。\n看看效果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 # 看看中断数 $ cat /proc/interrupts | grep -P \u0026#39;eth|CPU0\u0026#39; # 我的网卡名叫eth0、eth1 CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 CPU8 CPU9 CPU10 CPU11 CPU12 CPU13 CPU14 CPU15 99: 0 0 0 144263633 0 631894756 0 0 0 297 0 3128 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 0-edge eth0-0 101: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 1-edge eth0-1 102: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 2-edge eth0-2 103: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 3-edge eth0-3 104: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 4-edge eth0-4 105: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 5-edge eth0-5 106: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 6-edge eth0-6 107: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 7-edge eth0-7 108: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 8-edge eth0-8 109: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 9-edge eth0-9 110: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 10-edge eth0-10 111: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 11-edge eth0-11 112: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 12-edge eth0-12 113: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 13-edge eth0-13 114: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 14-edge eth0-14 115: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 15-edge eth0-15 116: 0 0 1733 0 440636622 5579613 0 161245 17862881 0 0 1031 0 0 9500904 0 IR-PCI-MSIX-0000:22:00.0 16-edge eth0-16 117: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 17-edge eth0-17 118: 3365897 0 1182441 0 124570 308349 2351042 235318334 0 0 0 0 230800986 1358 0 0 IR-PCI-MSIX-0000:22:00.0 18-edge eth0-18 119: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 19-edge eth0-19 120: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 20-edge eth0-20 121: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 21-edge eth0-21 122: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 22-edge eth0-22 123: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 23-edge eth0-23 124: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 24-edge eth0-24 125: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 25-edge eth0-25 126: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 26-edge eth0-26 127: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 27-edge eth0-27 128: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 28-edge eth0-28 129: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 29-edge eth0-29 130: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 30-edge eth0-30 131: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:22:00.0 31-edge eth0-31 133: 0 156031397 0 0 0 147300933 215 514317 0 0 0 1456987057 0 0 0 422 IR-PCI-MSIX-0000:2a:00.0 0-edge eth1-0 134: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 1-edge eth1-1 136: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 2-edge eth1-2 137: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 3-edge eth1-3 138: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 4-edge eth1-4 139: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 5-edge eth1-5 140: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 6-edge eth1-6 141: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 7-edge eth1-7 142: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 8-edge eth1-8 143: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 9-edge eth1-9 144: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 10-edge eth1-10 145: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 11-edge eth1-11 146: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 12-edge eth1-12 147: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 13-edge eth1-13 148: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 14-edge eth1-14 149: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 15-edge eth1-15 150: 2196 115680935 162017341 0 0 3 459917 567139230 25305 106494 2371 5 82635683 0 1254 632401889 IR-PCI-MSIX-0000:2a:00.0 16-edge eth1-16 151: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 17-edge eth1-17 152: 1557 4043 309835387 0 0 293 1044744 0 0 473416721 0 0 0 4 162948447 615115873 IR-PCI-MSIX-0000:2a:00.0 18-edge eth1-18 153: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 19-edge eth1-19 154: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 20-edge eth1-20 155: 1 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 21-edge eth1-21 156: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 22-edge eth1-22 157: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 23-edge eth1-23 158: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 24-edge eth1-24 159: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 25-edge eth1-25 160: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 26-edge eth1-26 161: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 27-edge eth1-27 162: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 28-edge eth1-28 163: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 29-edge eth1-29 164: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 30-edge eth1-30 165: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSIX-0000:2a:00.0 31-edge eth1-31 每个网卡都用到了多个核心来处理软中断，效果不错。根据这个帖子的说法，9.011.01版本驱动是1个rx队列和2个tx队列。\n再看看cpu各核心的使用率是否相对均衡：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 $ mpstat -P ALL 1 3 Linux 6.2.16-6-pve (pve) 08/15/23 _x86_64_ (16 CPU) 20:55:54 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 20:55:55 all 1.44 0.06 1.57 0.06 0.00 0.38 0.00 4.27 0.00 92.21 20:55:55 0 0.98 0.00 1.96 0.00 0.00 0.00 0.00 5.88 0.00 91.18 20:55:55 1 0.00 0.00 1.01 0.00 0.00 0.00 0.00 4.04 0.00 94.95 20:55:55 2 0.00 0.00 0.99 0.00 0.00 0.00 0.00 8.91 0.00 90.10 20:55:55 3 1.01 0.00 0.00 0.00 0.00 1.01 0.00 5.05 0.00 92.93 20:55:55 4 2.02 0.00 0.00 0.00 0.00 1.01 0.00 5.05 0.00 91.92 20:55:55 5 4.00 0.00 4.00 0.00 0.00 1.00 0.00 1.00 0.00 90.00 20:55:55 6 1.98 0.99 1.98 0.00 0.00 0.99 0.00 3.96 0.00 90.10 20:55:55 7 1.98 0.00 1.98 0.99 0.00 0.00 0.00 3.96 0.00 91.09 20:55:55 8 1.02 0.00 2.04 0.00 0.00 0.00 0.00 2.04 0.00 94.90 20:55:55 9 0.00 0.00 1.03 0.00 0.00 0.00 0.00 4.12 0.00 94.85 20:55:55 10 4.12 0.00 1.03 0.00 0.00 0.00 0.00 3.09 0.00 91.75 20:55:55 11 1.01 0.00 1.01 0.00 0.00 1.01 0.00 7.07 0.00 89.90 20:55:55 12 1.02 0.00 2.04 0.00 0.00 1.02 0.00 2.04 0.00 93.88 20:55:55 13 3.00 0.00 1.00 0.00 0.00 0.00 0.00 3.00 0.00 93.00 20:55:55 14 0.00 0.00 2.02 0.00 0.00 0.00 0.00 3.03 0.00 94.95 20:55:55 15 0.98 0.00 2.94 0.00 0.00 0.00 0.00 5.88 0.00 90.20 20:55:55 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 20:55:56 all 1.14 0.00 1.21 0.51 0.00 0.44 0.00 2.35 0.00 94.35 20:55:56 0 1.02 0.00 3.06 0.00 0.00 0.00 0.00 2.04 0.00 93.88 20:55:56 1 1.02 0.00 0.00 1.02 0.00 1.02 0.00 1.02 0.00 95.92 20:55:56 2 0.99 0.00 1.98 0.00 0.00 0.00 0.00 3.96 0.00 93.07 20:55:56 3 1.98 0.00 1.98 0.00 0.00 0.99 0.00 3.96 0.00 91.09 20:55:56 4 3.06 0.00 1.02 0.00 0.00 0.00 0.00 2.04 0.00 93.88 20:55:56 5 0.00 0.00 2.97 0.00 0.00 1.98 0.00 4.95 0.00 90.10 20:55:56 6 2.06 0.00 1.03 0.00 0.00 0.00 0.00 0.00 0.00 96.91 20:55:56 7 1.02 0.00 0.00 3.06 0.00 1.02 0.00 2.04 0.00 92.86 20:55:56 8 0.00 0.00 0.00 0.00 0.00 0.00 0.00 1.04 0.00 98.96 20:55:56 9 1.02 0.00 1.02 0.00 0.00 1.02 0.00 2.04 0.00 94.90 20:55:56 10 0.00 0.00 1.01 1.01 0.00 0.00 0.00 3.03 0.00 94.95 20:55:56 11 2.04 0.00 1.02 0.00 0.00 0.00 0.00 2.04 0.00 94.90 20:55:56 12 1.03 0.00 1.03 1.03 0.00 1.03 0.00 2.06 0.00 93.81 20:55:56 13 1.01 0.00 1.01 0.00 0.00 0.00 0.00 2.02 0.00 95.96 20:55:56 14 1.01 0.00 0.00 2.02 0.00 0.00 0.00 3.03 0.00 93.94 20:55:56 15 1.02 0.00 2.04 0.00 0.00 0.00 0.00 2.04 0.00 94.90 20:55:56 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 20:55:57 all 1.95 0.00 1.01 0.19 0.00 0.38 0.00 2.83 0.00 93.65 20:55:57 0 0.99 0.00 0.00 0.00 0.00 0.99 0.00 3.96 0.00 94.06 20:55:57 1 0.00 0.00 1.98 0.99 0.00 0.00 0.00 2.97 0.00 94.06 20:55:57 2 0.00 0.00 2.04 0.00 0.00 0.00 0.00 3.06 0.00 94.90 20:55:57 3 2.00 0.00 0.00 0.00 0.00 1.00 0.00 3.00 0.00 94.00 20:55:57 4 1.01 0.00 2.02 0.00 0.00 0.00 0.00 2.02 0.00 94.95 20:55:57 5 2.02 0.00 3.03 0.00 0.00 0.00 0.00 1.01 0.00 93.94 20:55:57 6 2.00 0.00 0.00 0.00 0.00 1.00 0.00 2.00 0.00 95.00 20:55:57 7 10.10 0.00 0.00 1.01 0.00 0.00 0.00 2.02 0.00 86.87 20:55:57 8 0.00 0.00 1.01 0.00 0.00 0.00 0.00 5.05 0.00 93.94 20:55:57 9 1.01 0.00 0.00 0.00 0.00 2.02 0.00 3.03 0.00 93.94 20:55:57 10 3.03 0.00 1.01 0.00 0.00 0.00 0.00 4.04 0.00 91.92 20:55:57 11 4.00 0.00 2.00 0.00 0.00 0.00 0.00 2.00 0.00 92.00 20:55:57 12 3.92 0.00 0.98 0.00 0.00 0.98 0.00 3.92 0.00 90.20 20:55:57 13 0.00 0.00 1.01 1.01 0.00 0.00 0.00 3.03 0.00 94.95 20:55:57 14 0.00 0.00 1.03 0.00 0.00 0.00 0.00 1.03 0.00 97.94 20:55:57 15 1.01 0.00 0.00 0.00 0.00 0.00 0.00 3.03 0.00 95.96 Average: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle Average: all 1.51 0.02 1.26 0.25 0.00 0.40 0.00 3.15 0.00 93.40 Average: 0 1.00 0.00 1.66 0.00 0.00 0.33 0.00 3.99 0.00 93.02 Average: 1 0.34 0.00 1.01 0.67 0.00 0.34 0.00 2.68 0.00 94.97 Average: 2 0.33 0.00 1.67 0.00 0.00 0.00 0.00 5.33 0.00 92.67 Average: 3 1.67 0.00 0.67 0.00 0.00 1.00 0.00 4.00 0.00 92.67 Average: 4 2.03 0.00 1.01 0.00 0.00 0.34 0.00 3.04 0.00 93.58 Average: 5 2.00 0.00 3.33 0.00 0.00 1.00 0.00 2.33 0.00 91.33 Average: 6 2.01 0.34 1.01 0.00 0.00 0.67 0.00 2.01 0.00 93.96 Average: 7 4.36 0.00 0.67 1.68 0.00 0.34 0.00 2.68 0.00 90.27 Average: 8 0.34 0.00 1.02 0.00 0.00 0.00 0.00 2.73 0.00 95.90 Average: 9 0.68 0.00 0.68 0.00 0.00 1.02 0.00 3.06 0.00 94.56 Average: 10 2.37 0.00 1.02 0.34 0.00 0.00 0.00 3.39 0.00 92.88 Average: 11 2.36 0.00 1.35 0.00 0.00 0.34 0.00 3.70 0.00 92.26 Average: 12 2.02 0.00 1.35 0.34 0.00 1.01 0.00 2.69 0.00 92.59 Average: 13 1.34 0.00 1.01 0.34 0.00 0.00 0.00 2.68 0.00 94.63 Average: 14 0.34 0.00 1.02 0.68 0.00 0.00 0.00 2.37 0.00 95.59 Average: 15 1.00 0.00 1.67 0.00 0.00 0.00 0.00 3.68 0.00 93.65 看得出来软中断在各核心上使用率差异已不如之前大了。\n","date":"2023-08-15T00:00:00+08:00","image":"https://evine.win/p/pve-install-realtek-8125-driver/pve-poster_hu9310090483394246981.jpg","permalink":"https://evine.win/p/pve-install-realtek-8125-driver/","title":"PVE 8 安装 ReakTEK RTL8125B 2.5G网卡驱动"},{"content":" 本文为《PVE安装Kodi》系列文章的一部分。\nPVE 直接安装最新版 Kodi 为Kodi适配遥控器 修改Kodi字幕字体 修改Kodi皮肤字体 屏蔽Kodi的关机、重启按钮 设置Kodi启动的前置条件 像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停 kodi-send使用相关说明 转换遥控器的退出键为返回键 前言 在上文 《像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停》 中，我们把2.4G无线遥控器的电源键支持并转换为开关Kodi了。不过，有些2.4G无线遥控器的返回键不是退格键（backspace键），而是退出键（esc键），导致短按它的效果是直接退出到上一级菜单（PreviousMenu），而不是返回到上一个界面（Back）。这种情况在点的界面比较深的时候会比较明显，一点返回结果返回了很远。如果不习惯这样的操作方式，那么我们可以转换按键。\n说明 看到本篇教程这里，我默认你已经按照《PVE 直接安装最新版 Kodi》《像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停》《kodi-send使用相关说明》这三篇教程安装好了必备的软件包，编辑好了必备的脚本，相关的安装过程就不再赘述了，直接进入正题。\n2.4G无线遥控器一般被Linux系统识别为键盘设备，所以这种遥控器的按键实际上就是普通键盘上的常规按键，它的按键的作用是通过/usr/share/kodi/system/keymaps/keyboard.xml来处理的（在未被Keymap Editor映射的前提下）。打开该xml文件内容可知（见下），大部分界面中长按esc键的效果等同于短按backspace键（然而似乎遥控器并不支持长按\u0026hellip;普通键盘才支持\u0026hellip;），如果你习惯短按是PreviousMenu，也可以不再往下看了。不过对我来说，短按Back才更符合我的习惯，所以我需要将这个遥控器的esc键转换为backspace键。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;keymap\u0026gt; \u0026lt;global\u0026gt; \u0026lt;keyboard\u0026gt; ... \u0026lt;backspace\u0026gt;Back\u0026lt;/backspace\u0026gt; ... \u0026lt;escape\u0026gt;PreviousMenu\u0026lt;/escape\u0026gt; \u0026lt;escape mod=\u0026#34;longpress\u0026#34;\u0026gt;Back\u0026lt;/escape\u0026gt; ... \u0026lt;/keyboard\u0026gt; ... \u0026lt;/global\u0026gt; ... \u0026lt;/keymap\u0026gt; 转换按键有很多方式，一种使用Kodi本身支持的特性，新建~/.kodi/userdata/keymaps/my_remap.xml（文件名可以自己定义，详见Keymaps，~/.kodi/userdata/keymaps下的xml覆盖/usr/share/kodi/keymaps下的，同文件夹下的文件名字母序靠后的覆盖靠前的），内容可以形如下面这种：\n1 2 3 4 5 6 7 8 \u0026lt;keymap\u0026gt; \u0026lt;global\u0026gt; \u0026lt;keyboard\u0026gt; \u0026lt;escape\u0026gt;Back\u0026lt;/escape\u0026gt; \u0026lt;escape mod=\u0026#34;longpress\u0026#34;\u0026gt;PreviousMenu\u0026lt;/escape\u0026gt; \u0026lt;/keyboard\u0026gt; \u0026lt;/global\u0026gt; \u0026lt;/keymap\u0026gt; 上面的示例就是把短按esc和长按esc的作用交换了一下（尽管遥控器可能并不支持长按）。虽然上述配置并未列全，但基本上可以应付大部分情况了，你也可以自行参考/usr/share/kodi/system/keymaps/keyboard.xml中的escape所在的全部模块进行自定义覆盖。\n既然我已经在使用evsieve来胁持电源键了，那么再用它来胁持esc键也是个不错的办法，所以就有了另外第二种办法，流程如下。\n流程 测试遥控器的返回键到底是个什么按键，不出意外，出现一点返回结果返回了很远的一个界面这种情况下，返回键应该就是esc键。注：在测试前请先退出Kodi，保证画面处于控制台界面。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # 运行evtest evtest --grab # evtest会列出所有可用的输入设备，可以看到我的遥控器有event5-event8共4个设备 # 你可以选择具体的编号来进行测试，找到每个设备分别能控制哪些按键 # 经过测试，我发现我遥控器的返回键在event5，也就是2.4G Composite Devic这个设备 No device specified, trying to scan all of /dev/input/event* Available devices: /dev/input/event0: Power Button /dev/input/event1: AT Translated Set 2 keyboard /dev/input/event2: VirtualPS/2 VMware VMMouse /dev/input/event3: VirtualPS/2 VMware VMMouse /dev/input/event4: QEMU QEMU USB Tablet /dev/input/event5: 2.4G Composite Devic /dev/input/event6: 2.4G Composite Devic Mouse /dev/input/event7: 2.4G Composite Devic Consumer Control /dev/input/event8: 2.4G Composite Devic System Control /dev/input/event9: PC Speaker Select the device event number [0-9]:5 # 反馈键一般在遥控器名称最短的那个设备上，也就是2.4G Composite Devic，你也可以把多次测试一个一个试出来 Input driver version is 1.0.1 Input device ID: bus 0x3 vendor 0x276d product 0x1101 version 0x111 Input device name: \u0026#34;2.4G Composite Devic\u0026#34; Supported events: Event type 0 (EV_SYN) Event type 1 (EV_KEY) Event code 1 (KEY_ESC) Event code 2 (KEY_1) Event code 3 (KEY_2) Event code 4 (KEY_3) Event code 5 (KEY_4) Event code 6 (KEY_5) ... ## 中间太长了，略去 Properties: Testing ... (interrupt to exit) ## 按下返回键，有反应说明设备选择对了，无反应说明返回键不在这个设备上 Event: time 1691294047.183861, type 4 (EV_MSC), code 4 (MSC_SCAN), value 70029 Event: time 1691294047.183861, type 1 (EV_KEY), code 1 (KEY_ESC), value 1 Event: time 1691294047.183861, -------------- SYN_REPORT ------------ Event: time 1691294047.255862, type 4 (EV_MSC), code 4 (MSC_SCAN), value 70029 Event: time 1691294047.255862, type 1 (EV_KEY), code 1 (KEY_ESC), value 0 Event: time 1691294047.255862, -------------- SYN_REPORT ------------ ## Ctrl+C退出 由上述输出内容可知，这款遥控器的返回键是esc键，而另外一些遥控器的返回键是backspace键，这才是返回上一层而非退出的按键。所以我们接下来把这个遥控器的esc键转换为backspace键。\n先确认/dev/input/by-id下已经有/dev/input/event5（对我而言，event5就是我的2.4G Composite Devic这个遥控器设备）的软连接。一般udev程序识别这个设备没有问题，不再需要自己编辑相应的udev规则；然后修改在《像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停》中创建的脚本/usr/local/bin/run-evsieve.sh如下，并注意按照注释修改为自己的信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/usr/bin/env bash export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin ## 要劫持的目标设备的绝对路径，请注意修改成自己的 ## 不要直接写/dev/input/eventX，而要写/dev/input/by-id下的设备 ## target_hijack_input_device1是返回键（esc键）所在的设备 ## target_hijack_input_device2是电源键（power键）所在的设备 target_hijack_input_device1=\u0026#34;/dev/input/by-id/usb-0627_2.4G_Composite_Devic-event-kbd\u0026#34; target_hijack_input_device2=\u0026#34;/dev/input/by-id/usb-0627_2.4G_Composite_Devic-System-Control\u0026#34; ## 要胁持的按键的键名，应该分别就是esc和power了，大概率不用改 ## target_hijack_button1就是target_hijack_input_device1上的esc键 ## target_hijack_button2就是target_hijack_input_device2上的power键 target_hijack_button1=\u0026#34;esc\u0026#34; target_hijack_button2=\u0026#34;power\u0026#34; ###### 以下无需修改 ###### ## 先检测 target_hijack_input_device1 和 target_hijack_input_device2 是否已经存在 while :; do if [[ -L \u0026#34;$target_hijack_input_device1\u0026#34; \u0026amp;\u0026amp; -L \u0026#34;$target_hijack_input_device2\u0026#34; ]]; then break else echo \u0026#34;The \u0026#39;$target_hijack_input_device1\u0026#39; or \u0026#39;$target_hijack_input_device2\u0026#39; is not inserted, wait 2 seconds...\u0026#34; sleep 2 fi done ## 执行按键胁持，详细用法请见：https://github.com/KarsMulder/evsieve ## 当按下退出键时，转换为返回键 ## 当按下电源键时，转换为运行脚本/usr/local/bin/kodi-power.sh exec evsieve \\ --input \u0026#34;$target_hijack_input_device1\u0026#34; grab persist=reopen \\ --map key:$target_hijack_button1 key:backspace \\ --output \\ --input \u0026#34;$target_hijack_input_device2\u0026#34; grab persist=reopen \\ --hook key:$target_hijack_button2 exec-shell=\u0026#34;/usr/local/bin/kodi-power.sh\u0026#34; \\ --block key:$target_hijack_button2 然后重启在《像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停》中创建的服务/etc/systemd/system/evsieve.service。\n1 2 systemctl daemon-reload systemctl restart evsieve.service 确认服务正常运行起来了，然后你就可以用遥控器打开Kodi并测试退出键是否转换为返回键了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## 查看状态 systemctl status evsieve.service ## 如下输出内容像下面这样，就表示胁持好了 ● evsieve.service - Run Evsieve Loaded: loaded (/etc/systemd/system/evsieve.service; enabled; preset: enabled) Active: active (running) since Sun 2023-08-06 12:05:36 CST; 1h 20min ago Main PID: 3612370 (evsieve) Tasks: 2 (limit: 75726) Memory: 1.3M CPU: 317ms CGroup: /system.slice/evsieve.service └─3612370 evsieve --input /dev/input/by-id/usb-0627_2.4G_Composite_Devic-event-kbd grab persist=reopen --map key:esc key:backspace --output --input /dev/input/by-id/usb-0627_2.4G_Composite_Devic-System-Control grab persist=reopen --hook key:power exec-shell=/usr/local/bin/kodi-power.sh --block key:power 8月 06 12:05:36 pve systemd[1]: Started evsieve.service - Run Evsieve. ","date":"2023-08-06T00:00:00+08:00","image":"https://evine.win/p/kodi-change-exit-to-backspace/kodi-poster_hu6896014991795686649.jpg","permalink":"https://evine.win/p/kodi-change-exit-to-backspace/","title":"转换遥控器的退出键为返回键"},{"content":" 关键词：上海 电信 IPTV SDN光猫 桥接 爱快 iKuai IPTV盒子\n根据 这个方法 ，可以在没有交换机时，实现光猫桥接、爱快作为主路由进行拨号的情况下，无需设置vlan tag即可让上海电信IPTV盒子正常使用。注意：此方法不是将IPTV信号流媒体化，只是让电信的IPTV盒子可以正常使用。主要适用于SDN光猫以及最新的2.5G光猫。\n光猫先找电信小哥沟通好改桥接，然后按如下的网络拓扑图接线：\n爱快至少需要4个物理网口，假如分别为eth0、eth1、eth2、eth3。其中eth3作为wan口连接光猫（你也可以使用其他口，只要区分清楚即可）。\neth0设置为lan1 ，lan1相应的DHCP服务请自行设置。\neth2通过网线连接光猫的网口3，eth1和eth2设置为lan2，注意扩展网卡要勾选两个。\n设置lan2的DHCP服务并设置相应的DHCP Option。\noption 60（十六进制）:\n1 00:00:01:00:02:03:43:50:45:03:0e:45:38:20:47:50:4f:4e:20:52:4f:55:54:45:52:04:03:31:2e:30 option 125 （十六进制）:\n1 2 3 00:00:00:00:1a:02:06:48:47:57:2d:43:54:0a:02:20:00:0b:02:00:55:0d:02:00:2e # 或者 00:00:01:00:02:03:43:50:45:03:0e:45:38:20:47:50:4f:4e:20:52:4f:55:54:45:52:04:03:31:2e:30 打开IPTV盒子，连接好电视机，应该就可以了，从系统信息中也能看到能够获取到两个 IP。\n","date":"2023-05-19T00:00:00+08:00","image":"https://evine.win/p/ikuai-how-use-iptv-in-shanghai/pic1_hu10516691097187188740.jpg","permalink":"https://evine.win/p/ikuai-how-use-iptv-in-shanghai/","title":"光猫桥接爱快拨号时，上海电信IPTV盒子如何正常使用"},{"content":" 关键词：爱快 IPv4 / IPv6 ACL / 防火墙 端口转发 设置 安全\n相关概念 引用自爱快帮助文档，不完全理解也没有关系，可以在实践中加深概念理解。\n协议栈：支持选择IPV4或IPV6，在爱快路由3.7.0及以上版本支持。 协议：这条ACL规则所走的协议的类型。 动作：允许或阻断； 方向： 进或转发； [进]：内网或外网进路由。 [转发]：路由接收到内网或外网数据然后把数据进行转发动作。 连接方向匹配: [原始方向]：匹配主动发起方发起访问时的报文。 [应答方向]：匹配被访问方应答时的报文。 源地址：转发与进动作的起始地址。 目的地址：转发与进动作的结束地址。 源端口：允许或阻断的起始端口。 目的端口：特定目标的端口。 进接口：数据来源口。 出接口：目的出口。 IPv4与IPv6的不同 IPv4在爱快系统中设置了端口转发以后，被转发的端口通过任何公网IP都能访问，不太安全，但总得来说只限制在转发的端口范围内。\n而IPv6不存在端口转发的概念，只要在爱快系统中启用了IPv6，那么内网的设备都有全球唯一的IPv6地址，不需要什么设置就能从公网访问。而爱快默认就没有启用IPv6防火墙，意思就是有IPv6地址的设备是几乎完全暴露在公网环境中的，极不安全。\n当然，ISP大概率封掉了一些常见的端口。\nIPv4的ACL/防火墙设置 IPv4要设置ACL/防火墙，由于NAT的存在，只需要针对设置了端口转发/UPNP/DMZ的端口/设备来设置。可以参考这篇教程 ，可以限制SSH/WEBUI/RDP的访问来源IP，提高安全性。\n注意，如要设置ACL，要先设置好端口转发，然后只针对需要提高安全性的转发端口来设置ACL（BT/PT软件IPv4的监听端口只转发不设置ACL）。\nIPv6的ACL/防火墙设置 ACL中允许的优先级高于阻断。\n爱快在3.7.0新增了IPv6 ACL/防火墙的功能，由此终于可以放心的开启IPv6了。由于默认IPv6环境是几乎完全暴露在公网的。所以开启IPv6后，先加入两条规则，不允许公网通过IPv6访问本地，但允许本地通过IPv6访问公网：\n注：第一条阻断规则的连接方向为原始方向，第二条允许规则的连接方向为关闭。并且由于目前爱快的IPv6 ACL还无法针对性的打开指定本地设备的ICMP协议，所以这样操作以后会默认禁止从公网ping本地的IPv6地址。爱快默认允许，所以上图中第二条规则不设置也可以。\n然后再对有安全性要求的端口/IP来针对性的开放权限。以下举几种情况：\nWEBUI/HTTPS/HTTP/SSH/RDP等\n假如8080,20000,30000-30004这几个端口都是WEBUI/SSH/RDP控制端口，只允许国内IPv6地址访问。对应本地设备有两个IPv6地址，分别为：\n1 2 2400:d0a0:38ba:abde:abbb:c1f:fea5:6c4c/64 2400:d0a0:38ba:abde::add/64 那么可以这样设置：\n连接方向匹配：原始方向。\n源地址：全国的数据可以从这里获取：clang，如果需要限制到省级的具体运营商，可以在这里获取：zxipv6wry（从中国.txt中你也可以找到市级/区级的信息）。\n目的地址：是IPv6特有的后缀式/负掩码写法（负掩码是一个全0的位串，后面跟着一个全1的位串，表示地址中不变的部分。），前缀变化后亦可生效：\n1 2 ::abbb:c1f:fea5:6c4c/::ffff:ffff:ffff:ffff ::add/::ffff:ffff:ffff:ffff 为了防止ACL规则不失效，建议需要此规则的设备通过DHCPv6/EUI-64方式获取IPv6，防止后缀变化。\nBT/PT的监听端口\n假如33333,44444这两个端口是BT/PT下载软件的下载监听端口，由于上面最开始添加的默认规则阻断了其他公网IPv6访问本地，现在需要将33333,44444在IPv6上暴露出去。假如下载软件的IPv6地址是：\n1 2400:d0a0:38ba:abde:42:aff:fe00:fc/64 可以如下设置：\n同上所述，目的地址是后缀式::42:aff:fe00:fc/::ffff:ffff:ffff:ffff，源地址留空表示允许任何IPv6，连接方向匹配可以选择关闭。一条是tcp，一条是udp，目前爱快IPv6的ACL无法设置tcp+udp，只能分成两条。\n完全暴露某台设备\n因为某些原因（比如PCDN），假如需要将某些IPv6完全暴露在公网中，那么可以这样设置：\n其中的连接方向可以选择原始方向，目的地址，参照上述写法写成负掩码形式，源地址、目的端口均留空，表示全部允许。\n规则验证 另外找台公网机器（不在本地网络中的，用手机蜂窝网临时开个热点也行），安装好nmap（linux直接从仓库中安装，windows的在 这里），比如检测IPv6的某端口开放情况运行下面命令即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ## 检测IPv6某端口的开放情况 nmap -6 \u0026lt;IPv6地址或能解析IPv6的域名\u0026gt; -p \u0026lt;端口\u0026gt; -Pn ## 举例 nmap -6 2400:d0a0:38ba:abde:abbb:c1f:fea5:6c4c -p 8080,20000,30000-30004 -Pn ## 输出 Starting Nmap 7.93 ( https://nmap.org ) at 2023-04-08 20:40 CST Nmap scan report for 2400:d0a0:38ba:abde:abbb:c1f:fea5:6c4c Host is up (0.016s latency). PORT STATE SERVICE 8080/tcp open unknown 20000/tcp filtered unknown 30000/tcp filtered unknown 30001/tcp filtered unknown 30002/tcp open unknown 30003/tcp open unknown 30004/tcp open unknown 假如要检测IPv4的端口开放情况，把命令中的-6更换为-4即可。\nstate状态说明：\nopen: 目标可达并且端口已开放； closed: 目标可达但端口没有打开，一般是没有服务运行在这个端口上； fitered: 目标不可达，也就是被ACL/防火墙阻断了。 你可以启用/停用爱快系统中对应的ACL规则后，运行命令检测端口是否可连接。\n","date":"2023-04-08T00:00:00+08:00","image":"https://evine.win/p/ikuai-set-ipv6-acl/pic1_hu12656687762263913986.png","permalink":"https://evine.win/p/ikuai-set-ipv6-acl/","title":"爱快 IPv4／IPv6 ACL／防火墙设置"},{"content":"效果图 流程 通过手机版钉钉-\u0026gt;面对面建群，建立一个一人群。\n通过PC版钉钉在群中创建一个“自定义”的Webhook机器人，名字随意，安全设置勾选“自定义关键词”，并新增两个词：播放和添加，同时把Webhook链接记录下来，链接形如https://oapi.dingtalk.com/robot/send?access_token=1234567890abcdef1234567890abcdef。\nJellyfin通过官方插件库安装好“Webhook”插件，并重启Jellyfin。\n在Jellyfin的“Webhook”插件的设置界面中，点击 Add General Destination 按钮新增一个Hook，设置以下信息：\nServer Url：你的Jellyfin访问地址，形如http://example.com:8096 Webhook Name：取个名，比如DingTalk Webhook Url：第2步中添加的“自定义”机器人的Webhook链接 Notification Type：勾选Item Added、Playback Start、Playback Stop User Filter：勾选你想触发通知的用户 Item Type：勾选你想监控的媒体类型，不能勾选其中的Send All Properties (ignores template) Template：填入以下内容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 { \u0026#34;msgtype\u0026#34;: \u0026#34;markdown\u0026#34;, \u0026#34;markdown\u0026#34;: { {{#if_equals NotificationType \u0026#39;ItemAdded\u0026#39;}} {{#if_equals ItemType \u0026#39;Season\u0026#39;}} \u0026#34;title\u0026#34;: \u0026#34;{{{SeriesName}}} {{{Name}}} 已添加到 {{{ServerName}}}\u0026#34;, {{else}} {{#if_equals ItemType \u0026#39;Episode\u0026#39;}} \u0026#34;title\u0026#34;: \u0026#34;{{{SeriesName}}} S{{SeasonNumber00}}E{{EpisodeNumber00}} {{{Name}}} 已添加到 {{{ServerName}}}\u0026#34;, {{else}} \u0026#34;title\u0026#34;: \u0026#34;{{{Name}}} ({{Year}}) 已添加到 {{{ServerName}}}\u0026#34;, {{/if_equals}} {{/if_equals}} \u0026#34;text\u0026#34;: \u0026#34;**媒体添加通知** \\n\\n {{#if_equals ItemType \u0026#39;Season\u0026#39;}} 名称：{{{SeriesName}}} S{{SeasonNumber00}} {{{Name}}}\\n {{else}} {{#if_equals ItemType \u0026#39;Episode\u0026#39;}} 名称：{{{SeriesName}}} S{{SeasonNumber00}}E{{EpisodeNumber00}} {{{Name}}}\\n {{else}} 名称：{{{Name}}} ({{Year}})\\n {{/if_equals}} {{/if_equals}} 链接： {{~#if_exist Provider_imdb~}} [IMDb](https://www.imdb.com/title/{{Provider_imdb}}/)\\n {{~/if_exist~}} {{~#if_exist Provider_tmdb~}} {{~#if_equals ItemType \u0026#39;Movie\u0026#39;~}} [TMDb](https://www.themoviedb.org/movie/{{Provider_tmdb}})\\n {{~else~}} [TMDb](https://www.themoviedb.org/tv/{{Provider_tmdb}})\\n {{~/if_equals~}} {{~/if_exist~}} {{~#if_exist Provider_opendouban~}} [豆瓣](https://movie.douban.com/subject/{{Provider_opendouban}}/)\\n {{~/if_exist~}} [Jellyfin]({{ServerUrl}}/web/index.html#!/details?id={{ItemId}}\u0026amp;serverId={{ServerId}})\\n\\n {{#if_equals ItemType \u0026#39;Episode\u0026#39;}} 时长：{{RunTime}}\\n\\n {{else}} {{#if_equals ItemType \u0026#39;Movie\u0026#39;}} 时长：{{RunTime}}\\n\\n {{/if_equals}} {{/if_equals}} {{~#if_exist Overview~}} 简介：{{Overview}} {{~else~}} 简介：(无) {{~/if_exist~}}\u0026#34; {{/if_equals}} {{#if_equals NotificationType \u0026#39;PlaybackStart\u0026#39;}} \u0026#34;title\u0026#34;: \u0026#34;{{{NotificationUsername}}} 开始播放\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;**开始播放通知** \\n\\n 用户：{{{NotificationUsername}}}\\n {{#if_equals ItemType \u0026#39;Episode\u0026#39;}} 剧集：{{{SeriesName}}} ({{Year}}) S{{SeasonNumber00}}E{{EpisodeNumber00}} - {{{Name}}}\\n {{else}} 电影：{{{Name}}} ({{Year}})\\n {{/if_equals}} 起点：{{PlaybackPosition}}\\n 设备：{{DeviceName}}\\n 终端：{{ClientName}}\\n\\n {{~#if_exist Overview~}} 简介：{{Overview}} {{~/if_exist~}}\u0026#34; {{/if_equals}} {{#if_equals NotificationType \u0026#39;PlaybackStop\u0026#39;}} \u0026#34;title\u0026#34;: \u0026#34;{{{NotificationUsername}}} 停止播放\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;**停止播放通知** \\n\\n 用户：{{{NotificationUsername}}}\\n {{#if_equals ItemType \u0026#39;Episode\u0026#39;}} 剧集：{{{SeriesName}}} ({{Year}}) S{{SeasonNumber00}}E{{EpisodeNumber00}} - {{{Name}}}\\n {{else}} 电影：{{{Name}}} ({{Year}})\\n {{/if_equals}} 设备：{{DeviceName}}\\n 终端：{{ClientName}}\u0026#34; {{/if_equals}} } } 点击Add Request Header，并新增一组：Key: Content-Type, Value: application/json 保存好配置，接下来，只要Jellyfin中有新的媒体添加进来，或者选定用户开始/停止播放媒体，你则会收到通知。 参考资料 jellyfin-plugin-webhook, templates, handlebars.\n","date":"2022-12-28T00:00:00+08:00","image":"https://evine.win/p/jellyfin-webhook-to-dingtalk/pic1_hu1918198686117055320.png","permalink":"https://evine.win/p/jellyfin-webhook-to-dingtalk/","title":"Jellyfin使用Webhook发送通知到钉钉"},{"content":" 本文为《PVE安装Kodi》系列文章的一部分。\nPVE 直接安装最新版 Kodi 为Kodi适配遥控器 修改Kodi字幕字体 修改Kodi皮肤字体 屏蔽Kodi的关机、重启按钮 设置Kodi启动的前置条件 像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停 kodi-send使用相关说明 转换遥控器的退出键为返回键 说明 kodi-send命令是Kodi自带命令行工具，可以安全的操控Kodi，除了下文使用的Quit指令，还有很多指令可以使用，方便想要自动化操作的人来使用，具体可用的指令见：Action_IDs 及 List_of_built-in_functions 。\n安装 请先按照 PVE 直接安装最新版 Kodi 教程添加好deb-multimedia软件源。\nkodi-send命令需要安装kodi-eventclients-common（如果未启用deb-multimedia源，则需要安装debian官方源中的kodi-eventclients-kodi-send）：\n1 apt install kodi-eventclients-common 如果是从backports源中安装的Kodi，那么也要从backports源中安装kodi-eventclients-common（假如是PVE 7，对应debian的bullseys版本）：\n1 apt install -t bullseye-backports kodi-eventclients-common 设置 如需要使用kodi-send命令，需要在“Kodi设置-\u0026gt;服务-\u0026gt;控制”处勾选“允许通过本机应用远程控制”。\n使用 输入kodi-send --help即可查看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 Usage kodi-send [OPTION] --action=ACTION kodi-send [OPTION] --button=BUTTON Example kodi-send --host=192.168.0.1 --port=9777 --action=\u0026#34;Quit\u0026#34; Options -?, --help Will bring up this message --host=HOST Choose what HOST to connect to (default=localhost) --port=PORT Choose what PORT to connect to (default=9777) --keymap=KEYMAP Choose which KEYMAP to use for key presses (default=KB) --button=BUTTON Sends a key press event to Kodi, this option can be added multiple times to create a macro -a ACTION, --action=ACTION Sends an action to XBMC, this option can be added multiple times to create a macro -d T, --delay=T Waits for T ms, this option can be added multiple times to create a macro 如需对本机安装的Kodi执行退出，如果Kodi是默认的状态，直接输入以下命令即可（-a/--action二者都可以，带不带=都行）：\n1 2 kodi-send -a \u0026#34;Quit\u0026#34; kodi-send --action=\u0026#34;Quit\u0026#34; 或者只是调出退出菜单，而不是直接退出（如果遥控器的电源键没有被evsieve劫持的话，电源键在Kodi中倒是原本就是调出退出菜单，不过被evsieve劫持之后就得就这种方式曲线还原了）：\n1 2 3 4 5 6 7 8 9 10 11 # 直接调出退出菜单，只能调出，无法切出 kodi-send -a \u0026#34;ActivateWindow(shutdownmenu)\u0026#34; # 用命令模拟按下sleep/power按键，以下两个命令作用同上，只能调出，无法切出 kodi-send --button=\u0026#34;sleep\u0026#34; kodi-send --button=\u0026#34;power\u0026#34; # 用命令模拟按下键盘的s键，键盘的s键作用也是调出退出菜单 # 相比上面的几个命令，当退出菜单已经调出时再次运行本命令可以切出退出菜单 # 而若是Kodi正处于输入文字的界面时，此命令只会真的打出“s”，调不出退出菜单 kodi-send --button=\u0026#34;s\u0026#34; 注：以上命令均在Kodi的keymaps未作任何调整的情况下运行的。其他指令请见：Action_IDs 及 List_of_built-in_functions，全部按键见：Keyboard_controls 。\n其他应用场景 针对《PVE 直接安装最新版 Kodi》中的/etc/systemd/system/kodi.service服务，可以修改ExecStop这一行为：\n1 ExecStop = /usr/bin/kodi-send --action=\u0026#34;Quit\u0026#34; 针对《像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停》一文中的/usr/local/bin/kodi-power.sh脚本，可以修改systemctl stop kodi.service（就是原本的关闭Kodi的指令）这一行为下面任何一句命令，这样也算是在电源键被evsieve劫持之后曲线还原了。\n1 2 3 4 5 6 7 8 9 # 直接退出 kodi-send --action=\u0026#34;Quit\u0026#34; # 或者只是调出退出菜单，而不是直接退出（根据上一节的说明选其一即可） kodi-send -a \u0026#34;ActivateWindow(shutdownmenu)\u0026#34; kodi-send --action=\u0026#34;ActivateWindow(shutdownmenu)\u0026#34; kodi-send --button=\u0026#34;sleep\u0026#34; kodi-send --button=\u0026#34;power\u0026#34; kodi-send --button=\u0026#34;s\u0026#34; ","date":"2022-12-21T00:00:00+08:00","image":"https://evine.win/p/kodi-send-help/pic1_hu15552033319872853968.png","permalink":"https://evine.win/p/kodi-send-help/","title":"kodi-send使用相关说明"},{"content":"官方教程中提供了一种做法，也就是提供buildkitd的配置文件后再创建builder：\n1 2 3 # 宿主上新建`$HOME/.docker/buildx/buildkitd.default.toml`，比如限制同时最多4个进程 [worker.oci] max-parallelism = 4 然后创建builder：\n1 2 3 $ docker buildx create --use \\ --name mybuilder \\ --driver docker-container 但这种方式对于同时构建多个平台的镜像起不到限制的作用，所以这里再提供一种不依靠docker本身，而是使用cgroup2的功能来实现：\n1 2 3 4 5 6 7 8 9 10 11 ## 创建builder docker run --privileged --rm tonistiigi/binfmt --install all \u0026amp;\u0026gt;/dev/null docker buildx create --name builder --use 2\u0026gt;/dev/null || docker buildx use builder docker buildx inspect --bootstrap ## 限制 docker buildx CPU使用率 ## CPU每线程上限为100%，CPU多个线程的上限就是线程数乘以100%，比如16线程的上限就是1600% ## 如果有16个核心，那么设置800%就是16个核心的一半使用率，整体上就是50%（800%/1600%=8/16=50%） ## 而如果有32个核心，那么设置800%相对于全部核心，整体上就是限制在25%（800%/3200%=8/32=25%） ## 需要自行先安装好 jq systemctl set-property docker-$(docker inspect buildx_buildkit_builder0 | jq -r .[0].Id).scope CPUQuota=800% ","date":"2022-11-26T00:00:00+08:00","image":"https://evine.win/p/docker-buildx-limit-cpu-usage/docker-poster_hu14098955999488624441.jpg","permalink":"https://evine.win/p/docker-buildx-limit-cpu-usage/","title":"docker buildx 跨平台构建镜像时限制CPU使用率"},{"content":" 本文为《PVE安装Kodi》系列文章的一部分。\nPVE 直接安装最新版 Kodi 为Kodi适配遥控器 修改Kodi字幕字体 修改Kodi皮肤字体 屏蔽Kodi的关机、重启按钮 设置Kodi启动的前置条件 像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停 kodi-send使用相关说明 转换遥控器的退出键为返回键 如果Kodi依赖其他服务，比如需要访问smb共享等等，可以在前文设置的/etc/systemd/system/kodi.service中ExecStart这一行前面添加一行：\n1 ExecStartPre = /usr/local/bin/kodi-pre.sh /usr/local/bin/kodi-pre.sh需要可执行权限，内容提供一个参考（下面的示例是先判断和Kodi处于同一主机下的Jellyfin容器是否已经处于running状态、健康状态是否是healthy，并且远端10.0.0.13的名为multimedia的samba共享是否已经可以挂载了），请根据你所需要的前置条件进行修改（请直接在Linux环境中创建nano /usr/local/bin/kodi-pre.sh，不要在Windows环境中创建）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #!/usr/bin/env bash while :; do jellyfin_state=$(/usr/bin/docker inspect jellyfin | /usr/bin/jq .[].State) jellyfin_status=$(echo \u0026#34;$jellyfin_state\u0026#34; | /usr/bin/jq -r .Status) jellyfin_health=$(echo \u0026#34;$jellyfin_state\u0026#34; | /usr/bin/jq -r .Health.Status) smb_status=$(/usr/bin/smbclient -N -L //10.0.0.13 | /usr/bin/grep \u0026#39;multimedia\u0026#39;) if [[ $jellyfin_status == running \u0026amp;\u0026amp; $jellyfin_health == healthy \u0026amp;\u0026amp; -n $smb_status ]]; then echo \u0026#34;Jellyfin is ready, samba is ready.\u0026#34; break else echo \u0026#34;Jellyfin or samba is not ready, wait 30 second.\u0026#34; /usr/bin/sleep 30 fi done ","date":"2022-11-24T00:00:00+08:00","image":"https://evine.win/p/kodi-set-pre-condition/kodi-poster_hu6896014991795686649.jpg","permalink":"https://evine.win/p/kodi-set-pre-condition/","title":"设置Kodi启动的前置条件"},{"content":" 本文为《PVE安装Kodi》系列文章的一部分。\nPVE 直接安装最新版 Kodi 为Kodi适配遥控器 修改Kodi字幕字体 修改Kodi皮肤字体 屏蔽Kodi的关机、重启按钮 设置Kodi启动的前置条件 像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停 kodi-send使用相关说明 转换遥控器的退出键为返回键 前言 在《PVE 直接安装最新版 Kodi》一文的评论中，有网友提出能不能像操控电视盒子/LibreELEC/CoreELCE一样用遥控器操控PVE中直装的Kodi，实现打开和关闭Kodi，这是个好想法，我也认为这样会大方便PVE中直装的Kodi的使用，所以学习了相关udev、udevadm、evtest、input、input remap相关知识，终于实现了这个非常便于使用的功能。\n参考资料 udev, udevadm, evtest, input_remap_utilities, evsieve\n思路 用遥控器操控PVE中直装的Kodi，实现打开和关闭Kodi，这个场景需要在无桌面环境下，胁持遥控器的电源键，让它的作用变更为打开/关闭Kodi，所以只是将电源键映射为其他键是不行的，而是需要胁持遥控器的电源键，让它变更为运行某个脚本，然后由脚本实现打开/关闭Kodi。\n根据 input_remap_utilities 列出的几个按键映射工具，只有 evsieve 可以在无桌面环境下胁持按键并运行指定脚本，实现上述场景。\n准备工作 以下相关命令均为root用户执行的。\n如果需要新建文件，请直接在Linux环境中使用nano XXXX创建，请不要在Windows环境中创建后再上传。\n所有的输入设备都由udev程序识别并保存在/dev/input下，通过输入ls -l /dev/input可以查看到许多eventX的设备。设备的编号会随着外设的插入或卸载以及开关机的变化而变化，也就是说电源键所在的输入设备的eventX中X这个编号不是固定的，所以我们不能直接使用/dev/input/eventX来作为后续要胁持的输入设备。运行ls -l /dev/input/by-id，udev会在这个目录下创建易于识别的、唯一的、不随外设的插入卸载或开关机而变化的软连接，无论X如何变化，它们都将指向正确的设备。\n我的遥控器是自带接收器的2.4G无线遥控器，插上接收器，通过evtest程序先找出遥控器电源键在什么设备上。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # 安装evtest apt install evtest # 运行evtest evtest --grab # evtest会列出所有可用的输入设备，可以看到我的遥控器有event5-event8共4个设备 # 你可以选择具体的编号来进行测试，找到每个设备分别能控制哪些按键 # 经过测试，我发现我遥控器的电源键在event8，也就是2.4G Composite Devic System Control这个设备 No device specified, trying to scan all of /dev/input/event* Available devices: /dev/input/event0: Power Button /dev/input/event1: AT Translated Set 2 keyboard /dev/input/event2: VirtualPS/2 VMware VMMouse /dev/input/event3: VirtualPS/2 VMware VMMouse /dev/input/event4: QEMU QEMU USB Tablet /dev/input/event5: 2.4G Composite Devic /dev/input/event6: 2.4G Composite Devic Mouse /dev/input/event7: 2.4G Composite Devic Consumer Control /dev/input/event8: 2.4G Composite Devic System Control /dev/input/event9: PC Speaker Select the device event number [0-9]:8 # 手动输入要测试的设备编号，如果不清楚电源键在什么设备上，你可以一个一个试出来 Input device ID: bus 0x3 vendor 0x627 product 0x697d version 0x110 Input device name: \u0026#34;2.4G Composite Devic System Control\u0026#34; Supported events: Event type 0 (EV_SYN) Event type 1 (EV_KEY) Event code 116 (KEY_POWER) Event code 142 (KEY_SLEEP) Event code 143 (KEY_WAKEUP) Event type 4 (EV_MSC) Event code 4 (MSC_SCAN) Properties: Testing ... (interrupt to exit) # 按下电源键，evtest输出以下结果，没有反应表示设备择取不对 Event: time 1669209045.421999, type 4 (EV_MSC), code 4 (MSC_SCAN), value 10081 Event: time 1669209045.421999, type 1 (EV_KEY), code 116 (KEY_POWER), value 1 Event: time 1669209045.421999, -------------- SYN_REPORT ------------ Event: time 1669209045.422021, type 1 (EV_KEY), code 116 (KEY_POWER), value 0 Event: time 1669209045.422021, -------------- SYN_REPORT ------------ # Ctrl+C退出 通过测试，我知道了我遥控器的电源键的键码为116，键名为KEY_POWER，去掉KEY_，键值转换为小写power这个值在后面会用到。不出意外，一般遥控器的电源键的键值都是power。\n现在来找一下event8这个设备在/dev/input/by-id下的软连接叫什么，运行ls -l /dev/input/by-id/：\n1 2 3 4 5 6 7 total 0 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-0627_2.4G_Composite_Devic-event-if01 -\u0026gt; ../event7 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-0627_2.4G_Composite_Devic-event-kbd -\u0026gt; ../event5 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-0627_2.4G_Composite_Devic-if01-event-mouse -\u0026gt; ../event6 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-0627_2.4G_Composite_Devic-if01-mouse -\u0026gt; ../mouse3 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-QEMU_QEMU_USB_Tablet_28754-0000:00:01.2-1-event-mouse -\u0026gt; ../event4 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-QEMU_QEMU_USB_Tablet_28754-0000:00:01.2-1-mouse -\u0026gt; ../mouse2 这\u0026hellip;\u0026hellip;udev没有识别出来\u0026hellip;\u0026hellip;准确的讲，是因为udev的默认规则/usr/lib/udev/rules.d/60-persistent-input.rules无法区分2.4G Composite Devic Consumer Control和2.4G Composite Devic System Control这两个设备，现象是每次关机再开机或每次卸载再插入接收器后，usb-0627_2.4G_Composite_Devic-event-if01这个设备一会儿指向2.4G Composite Devic Consumer Control，一会儿指向2.4G Composite Devic System Control，所以我需要修改一下udev的规则，让它能够准确识别出2.4G Composite Devic System Control。可能其他遥控器不存在此问题，需要你自行测试一下此问题存在不存在。\n现在来让udev能准确识别2.4G Composite Devic System Control，运行udevadm info --attribute-walk --name=/dev/input/event8（其中event8是根据上面evtest测试后知道的），输出内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 Udevadm info starts with the device specified by the devpath and then walks up the chain of parent devices. It prints for every device found, all possible attributes in the udev rules key format. A rule to match, can be composed by the attributes of the device and the attributes from one single parent device. looking at device \u0026#39;/devices/pci0000:00/0000:00:1e.0/0000:01:1b.0/usb2/2-1/2-1:1.1/0003:0627:697D.0003/input/input9/event8\u0026#39;: KERNEL==\u0026#34;event8\u0026#34; SUBSYSTEM==\u0026#34;input\u0026#34; DRIVER==\u0026#34;\u0026#34; ATTR{power/async}==\u0026#34;disabled\u0026#34; ATTR{power/control}==\u0026#34;auto\u0026#34; ATTR{power/runtime_active_kids}==\u0026#34;0\u0026#34; ATTR{power/runtime_active_time}==\u0026#34;0\u0026#34; ATTR{power/runtime_enabled}==\u0026#34;disabled\u0026#34; ATTR{power/runtime_status}==\u0026#34;unsupported\u0026#34; ATTR{power/runtime_suspended_time}==\u0026#34;0\u0026#34; ATTR{power/runtime_usage}==\u0026#34;0\u0026#34; looking at parent device \u0026#39;/devices/pci0000:00/0000:00:1e.0/0000:01:1b.0/usb2/2-1/2-1:1.1/0003:0627:697D.0003/input/input9\u0026#39;: KERNELS==\u0026#34;input9\u0026#34; SUBSYSTEMS==\u0026#34;input\u0026#34; DRIVERS==\u0026#34;\u0026#34; ATTRS{capabilities/abs}==\u0026#34;0\u0026#34; ATTRS{capabilities/ev}==\u0026#34;13\u0026#34; ATTRS{capabilities/ff}==\u0026#34;0\u0026#34; ATTRS{capabilities/key}==\u0026#34;c000 10000000000000 0\u0026#34; ATTRS{capabilities/led}==\u0026#34;0\u0026#34; ATTRS{capabilities/msc}==\u0026#34;10\u0026#34; ATTRS{capabilities/rel}==\u0026#34;0\u0026#34; ATTRS{capabilities/snd}==\u0026#34;0\u0026#34; ATTRS{capabilities/sw}==\u0026#34;0\u0026#34; ATTRS{id/bustype}==\u0026#34;0003\u0026#34; ATTRS{id/product}==\u0026#34;697d\u0026#34; ATTRS{id/vendor}==\u0026#34;0627\u0026#34; ATTRS{id/version}==\u0026#34;0110\u0026#34; ATTRS{inhibited}==\u0026#34;0\u0026#34; ATTRS{name}==\u0026#34;2.4G Composite Devic System Control\u0026#34; ATTRS{phys}==\u0026#34;usb-0000:01:1b.0-1/input1\u0026#34; ATTRS{power/async}==\u0026#34;disabled\u0026#34; ATTRS{power/control}==\u0026#34;auto\u0026#34; ATTRS{power/runtime_active_kids}==\u0026#34;0\u0026#34; ATTRS{power/runtime_active_time}==\u0026#34;0\u0026#34; ATTRS{power/runtime_enabled}==\u0026#34;disabled\u0026#34; ATTRS{power/runtime_status}==\u0026#34;unsupported\u0026#34; ATTRS{power/runtime_suspended_time}==\u0026#34;0\u0026#34; ATTRS{power/runtime_usage}==\u0026#34;0\u0026#34; ATTRS{properties}==\u0026#34;0\u0026#34; ATTRS{uniq}==\u0026#34;\u0026#34; ...下面其他信息此处略去 通过多次运行udevadm info --attribute-walk --name=/dev/input/eventX（X更换为不同的设备编号）可知，我的设备2.4G Composite Devic System Control可以通过ATTRS{name}这个属性即可以进行唯一识别。参考 udev 这个链接，新建/etc/udev/rules.d/01-system-control.rules，内容如下：\n1 ATTRS{name}==\u0026#34;2.4G Composite Devic System Control\u0026#34;, SYMLINK+=\u0026#34;input/by-id/usb-0627_2.4G_Composite_Devic-System-Control\u0026#34; 这种方式是写死的，只针对这一个遥控器有效，复杂的规则咱也写不来\u0026hellip;当然如果你想采用更智能的识别方式，可以参考 Writing udev rules 和 编写udev规则。\n其中SYMLINK+=\u0026quot;input/by-id/usb-0627_2.4G_Composite_Devic-System-Control\u0026quot;是指让udev在/dev/input/by-id下自动创建usb-0627_2.4G_Composite_Devic-System-Control，其指向2.4G Composite Devic System Control这个设备。软连接名称你可以自行定义。\n现在重启下或者重插一下接收器，终于可以识别出来了：\n1 2 3 4 5 6 7 8 9 10 11 ls -l /dev/input/by-id ## 生成了`usb-0627_2.4G_Composite_Devic-System-Control`这个软连接 total 0 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-0627_2.4G_Composite_Devic-event-if01 -\u0026gt; ../event7 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-0627_2.4G_Composite_Devic-event-kbd -\u0026gt; ../event5 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-0627_2.4G_Composite_Devic-System-Control -\u0026gt; ../event8 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-0627_2.4G_Composite_Devic-if01-event-mouse -\u0026gt; ../event6 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-0627_2.4G_Composite_Devic-if01-mouse -\u0026gt; ../mouse3 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-QEMU_QEMU_USB_Tablet_28754-0000:00:01.2-1-event-mouse -\u0026gt; ../event4 lrwxrwxrwx 1 root root 9 Nov 23 22:40 usb-QEMU_QEMU_USB_Tablet_28754-0000:00:01.2-1-mouse -\u0026gt; ../mouse2 设置按键胁持 以下相关命令均为root用户执行的。\n如果需要新建文件，请直接在Linux环境中使用nano XXXX创建，请不要在Windows环境中创建后再上传。\n下载我为PVE 7.X预编译好的 evsieve，其他版本不保证可用，如果下载不了，可以按照官方教程自己编译。我会随着Debian和evsieve版本的升级一直更新该文件，请及时在这个仓库查看更新情况：devome/files@github\n1 2 3 4 5 wget https://raw.githubusercontent.com/devome/files/master/evsieve/evsieve -O /usr/local/bin/evsieve chmod +x /usr/local/bin/evsieve ## 安装evsieve的运行依赖 apt install libevdev2 按照《PVE 直接安装最新版 Kodi》安装好Kodi，建议按非root用户设置好/etc/systemd/system/kodi.service，注意含有ExecStart和ExecStop这两行。如果你不需要Kodi开机自动启动，那么创建好这个文件就好了，不需要运行systemctl enable --now kodi.service。\n新建一个用来自动判断是启动Kodi还是关闭Kodi的脚本/usr/local/bin/kodi-power.sh，后续由evsieve来使用，内容如下：\n1 2 3 4 5 6 7 8 9 #!/usr/bin/env bash export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin if [[ -z $(ps -ef | grep \u0026#34;kodi.bin\u0026#34; | grep -v \u0026#34;grep\u0026#34;) ]]; then ## 如果kodi还没有启动，那么就启动它 systemctl start kodi.service else ## 如果kodi已经启动了，那么就停止它 systemctl stop kodi.service fi 注：停止Kodi这一行，相比使用systemctl stop kodi.service，更推荐使用kodi-send，详见：kodi-send使用相关说明。\n注意增加可执行权限：chmod +x /usr/local/bin/kodi-power.sh。\n根据 evsieve 的说明，在运行evsieve时，它所要胁持的设备必须已经插入了，但是我又希望evsieve能够开机自动运行，所以我需要在正式运行前先确保2.4G Composite Devic System Control这个设备已经插入。这项工作就交给脚本来判断吧，新建/usr/local/bin/evsieve.sh，内容如下（注意按照注释修改target_hijack_input_device和target_hijack_button）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/usr/bin/env bash export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin ## 要胁持的目标设备的绝对路径，请注意修改成自己的 ## 不要直接写/dev/input/eventX，而要写/dev/input/by-id下的设备 target_hijack_input_device=\u0026#34;/dev/input/by-id/usb-0627_2.4G_Composite_Devic-System-Control\u0026#34; ## 要胁持的按键的键名，请注意修改成你获取到的，不出意外，一般遥控器的电源键的键值都是power target_hijack_button=\u0026#34;power\u0026#34; ###### 以下无需修改 ###### ## 先检测 target_hijack_input_device 是否已经存在 while :; do if [[ -L \u0026#34;$target_hijack_input_device\u0026#34; ]]; then break else echo \u0026#34;The \u0026#39;$target_hijack_input_device\u0026#39; is not inserted, wait 2 seconds...\u0026#34; sleep 2 fi done ## 执行电源键胁持，当按下指定键时，转换为运行脚本/usr/local/bin/kodi-power.sh，详细用法请见：https://github.com/KarsMulder/evsieve exec evsieve \\ --input \u0026#34;$target_hijack_input_device\u0026#34; grab persist=reopen \\ --hook key:$target_hijack_button exec-shell=\u0026#34;/usr/local/bin/kodi-power.sh\u0026#34; \\ --block key:$target_hijack_button 该脚本同样需要可执行权限：chmod +x /usr/local/bin/evsieve.sh。\n注意：如果在进行 evtest 时，电源键所在的设备组在 Event type 1 下支持的 Event code 不仅仅只有 KEY_POWER KEY_SLEEP KEY_WAKEUP这三个，那么一般情况下这个设备组还有其他按键，这时不能完全屏蔽掉整个设备，需要将上述脚本中最后四行改成下面这样。这种情况一般出现在蓝牙遥控器上面。\n1 2 3 4 5 exec evsieve \\ --input \u0026#34;$target_hijack_input_device\u0026#34; grab persist=reopen \\ --hook key:$target_hijack_button exec-shell=\u0026#34;/usr/local/bin/kodi-power.sh\u0026#34; \\ --block key:$target_hijack_button \\ --output 新建/etc/systemd/system/evsieve.service，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [Unit] Description = Run evsieve Requires = systemd-udevd.service After = systemd-udevd.service Wants = systemd-udevd.service [Service] User = root Group = root ExecStart = /usr/local/bin/evsieve.sh ExecStop = /usr/bin/killall --user root --exact --wait evsieve TimeoutStartSec = infinity Restart = on-abort [Install] WantedBy = multi-user.target 让evsieve.service开机启动启动。这个必须得开机自动启动，要不然胁持不了。运行并确保evsieve.service已经运行好后，按一下遥控器的电源键来试一试效果吧。\n注意：因为Kodi程序比较大，无论是启动Kodi，还是关闭Kodi，系统都需要一定时间来处理，所以不要连续按电源键，这样只会让系统混乱。\n注意：如果evsieve.service没有正常启动，可能按下电源键会让PVE关机。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## 设置开机自动启动，并立即运行起来 systemctl enable --now evsieve.service ## 再看看是不是evsieve.service是不是启动好了 systemctl status evsieve.service ## 如果像这样就表示启动好啦 evsieve.service - Run evsieve Loaded: loaded (/etc/systemd/system/evsieve.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-11-24 18:11:27 CST; 36min ago Main PID: 1249 (evsieve) Tasks: 2 (limit: 72123) Memory: 1.8M CPU: 59ms CGroup: /system.slice/evsieve.service └─1249 evsieve --input /dev/input/by-id/usb-0627_2.4G_Composite_Devic-System-Control grab persist=reopen --hook key:power exec-shell=/usr/local/bin/kodi-power.sh --block key:power 11月 24 18:11:27 pve systemd[1]: Started Run evsieve. 有些遥控器的返回键不是真正的返回键，而是退出键，会直接退出到主菜单，而不是返回到上一层。如果不习惯这样的操作方式，那么我们可以仍然借助evsieve这个工具来实现按键的转换。详见 转换遥控器的退出键为返回键。\n总结 通过本教程，PVE直接安装Kodi也变得很好用了，就像使用电视盒子/LibreELEC/CoreELEC一样，实现遥控器启动/停止。\n","date":"2022-11-24T00:00:00+08:00","image":"https://evine.win/p/kodi-start-stop-by-remote-controller/kodi-poster_hu6896014991795686649.jpg","permalink":"https://evine.win/p/kodi-start-stop-by-remote-controller/","title":"像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停"},{"content":" 关键词：PVE | Proxmox VE | RAID | RAID0 | LVM | LVM-thin | 缓存 | cache | HDD | SSD\n前言 最近在查阅资料各种资料，看看PVE单服务器系统中，能用什么样的方式，提升LVM-thin存储的IO性能。有多服务器条件的当然是上CEPH了，没有多服务器的条件而内存又比较充足的情况下使用ZFS也不错。但我两种条件都不具备。\n作为垃圾佬，怎么舍得再额外购置硬件多花钱呢。垃圾佬当然不愿意再购买新硬盘了，掏出多年前给台式机装系统的两块SATA接口的固态硬盘，以及以前台式机用的两块机械硬盘，准备将两块SSD组raid0后作为缓存池，为两块HDD以raid0组后创建的LVM-thin提供读写缓存服务。\n硬盘类型 型号 硬盘大小 通电时长 出厂时间 SSD Samsung 840 EVO 120G 28744h 2014年3月 SSD Samsung 850 EVO 120G 22981h 2015年5月 HDD WD20EZRX 2T 55700h 2013年2月 HDD HGST HUA723020ALA640 2T 19267h 2013年12月 和我的使用场景、硬件条件一模一样几乎是不可能的，也就几乎不可能有人能够完全照搬我的操作过程，所以本文也仅是提供一种思路，LVM依靠它已经提供的各种功能，可以实现各种你想得到想不到的玩法。这里举三个例子：\n2块2T的HDD、1块3T的HDD，3块HDD分别创建一个2T的分区，共3个2TiB的分区组建6T大小3个PV的raid0的LVM或LVM-thin；再将3T盘没有用到的1T空间单独再创建个dir存储，用于保存备份文件、镜像文件等。\n1块256G的nvme磁盘，安装系统已经占用了50G，余下的空间大又不大，小又不小，单独用好像也干不了什么太多的事。系统已经默认创建了local-lvm，但是可以将local-lvm删除，然后将产生的约200G空间作为其他HDD磁盘的缓存池，提升IO性能。\n4块4T的HDD组raid5后再转换为LVM，然后一块256G的nvme磁盘作为其缓存池。\n有关概念 PV(physical volume)：物理卷，在逻辑卷管理系统最底层，可为整个物理硬盘或实际物理硬盘上的分区。\nVG(volume group)：卷组，建立在物理卷上，一卷组中至少要包括一物理卷，卷组建立后可动态的添加卷到卷组中，一个逻辑卷管理系统工程中可有多个卷组。\nLV(logical volume)：逻辑卷，建立在卷组基础上，卷组中未分配空间可用于建立新的逻辑卷，逻辑卷建立后可以动态扩展和缩小空间。\nPE(physical extent)：物理区域，是物理卷中可用于分配的最小存储单元（本文采用默认值4MiB），物理区域大小在建立卷组时指定，一旦确定不能更改，同一卷组所有物理卷的物理区域大小需一致，新的PV加入到VG后，PE的大小自动更改为VG中定义的PE大小。\nLE(logical extent)：逻辑区域，是逻辑卷中可用于分配的最小存储单元，逻辑区域的大小取决于逻辑卷所在卷组中的物理区域的大小。\n网上有很多有关概念的详细介绍，这里不再多说。\n创建具有缓存池的LVM-thin存储 这里需要大致先说明一下我的思路，我打算将HDD全部空间组raid0，然后用作数据LV；将SSD全部空间组raid0，然后用作元数据LV和缓存池LV，最终的存储类型是LVM-thin。分别如下：\n数据LV：也就是存储LVM-thin原始数据的LV，所有数据最终需要写入的地方，我将在HDD上创建它。\n元数据LV：LVM-thin的特色，相比LVM直接按卷大小预先分配所需空间，LVM-thin则是需要向卷内写入数据时才按实际写入数据量大小分配所需空间。LVM-thin需要用来索引实际数据的元数据metadata空间，就是元数据LV。为了提升数据索引速度，我将在SSD上创建它。\n缓存池LV：为了提升访问数据LV中数据的IO速度，使用SSD为它创建缓存池，这样可以将经常读取的数据加载到缓存池中，后续再读取这些数据会提升IO；同时要写入数据时也先写入缓存池，写入也可以更快。缓存池LV也分为数据LV和元数据LV两部分。\n缓存池数据LV：临时存储缓存数据的地方，我将在SSD上创建它。\n缓存池元数据LV：索引缓存数据的元数据存储的地方，我也将在SSD上创建它。\n还有额外的备用池元数据LV，后文遇到时再作介绍。\n如果直接在PVE的WEBUI中来创建，无法实现我所设想的思路，所以只能通过命令行来创建，然后再经过多次转换，来转换为我所需要的LVM-thin。\n先看看磁盘的识别情况 1 lsblk 从输出可见，/dev/sdb和/dev/sdc是两块HDD，/dev/sdd和/dev/sde是两块SSD：\n1 2 3 4 5 6 7 8 9 10 sda 8:0 0 32G 0 disk ├─sda1 8:1 0 1007K 0 part ├─sda2 8:2 0 512M 0 part └─sda3 8:3 0 31.5G 0 part ├─pve-swap 253:0 0 2G 0 lvm [SWAP] └─pve-root 253:1 0 29.5G 0 lvm / sdb 8:16 0 1.8T 0 disk sdc 8:32 0 1.8T 0 disk sdd 8:48 0 111.8G 0 disk sde 8:64 0 111.8G 0 disk 对磁盘初始化 给2块SSD、2块HDD磁盘全部以GPT进行初始化，每个磁盘只分一个区，以下以/dev/sdb为例（不分区直接创建整盘PV也可以）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## 进入fdisk命令行 fdisk /dev/sdb ## 分别按g、n，sector采用默认的值直接回车，最后 wq 保存并退出 Command (m for help): g Created a new GPT disklabel (GUID: 798FC3B9-A99E-B245-9A2E-C02B9A2D0836). Command (m for help): n Partition number (1-128, default 1): First sector (2048-41943006, default 2048): Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-41943006, default 41943006): Created a new partition 1 of type \u0026#39;Linux filesystem\u0026#39; and of size 20 GiB. Command (m for help): wq The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. 全部分好区再输入lsblk检查一下： 1 lsblk 输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 32G 0 disk ├─sda1 8:1 0 1007K 0 part ├─sda2 8:2 0 512M 0 part └─sda3 8:3 0 31.5G 0 part ├─pve-swap 253:0 0 2G 0 lvm [SWAP] └─pve-root 253:1 0 29.5G 0 lvm / sdb 8:16 0 1.8T 0 disk └─sdb1 8:17 0 1.8T 0 part sdc 8:32 0 1.8T 0 disk └─sdc1 8:33 0 1.8T 0 part sdd 8:48 0 111.8G 0 disk └─sdd1 8:49 0 111.8G 0 part sde 8:64 0 111.8G 0 disk └─sde1 8:65 0 111.8G 0 part 创建PV 1 pvcreate /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1 输出：\n1 2 3 4 Physical volume \u0026#34;/dev/sdb1\u0026#34; successfully created. Physical volume \u0026#34;/dev/sdc1\u0026#34; successfully created. Physical volume \u0026#34;/dev/sdd1\u0026#34; successfully created. Physical volume \u0026#34;/dev/sde1\u0026#34; successfully created. 创建VG 采用默认的4M大小的PE，创建名叫hybrid的VG：\n1 vgcreate hybrid /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1 输出：\n1 Volume group \u0026#34;hybrid\u0026#34; successfully created 创建数据LV 给两块HDD组raid0，用完它们的全部空间创建名叫data的数据LV：\n1 lvcreate --type raid0 --name data --extents 100%FREE --stripesize 256k hybrid /dev/sdb1 /dev/sdc1 输出：\n1 Logical volume \u0026#34;data\u0026#34; created. RAID的Stripe Size大小可以设置为8KiB、16KiB、32KiB、64KiB、128KiB和256KiB，如不设置此参数则默认采用64KiB。\n对于数据库应用，Stripe Size在4-16KiB之间被证明效果比较好；对于Web服务器以及文件打印服务器，建议Stripe Size设置为16-64KiB；对于大文件环境，比如流媒体，建议Stripe Size设置为128KiB以上。\n我的主要是大文件，所以我设置Stripe Size为256KiB。并且我的使用场景下，主要目的是提升IO，反而对数据损坏这个情况不关心，坏了就坏了，所以我采用的是raid0，和我使用场景不一致的不要采用raid0以及256KiB的Stripe Size。\n创建元数据LV和缓存池元数据LV 我最终要创建的存储类型是LVM-thin，这种薄存储类型需要另外的空间存储元数据metadata，如果直接在HDD上创建LVM-thin，系统会自动在HDD上创建其对应的元数据LV。但我们现在创建的是raid0类型的LVM，默认不带元数据LV，并且另一方面，我希望能在SSD上创建元数据所需要的LV，这样还可以提升数据索引速度，所以我需要手动在SSD上创建最终的LVM-thin存储所需要的元数据LV。\n并且，我们后面将SSD作为缓存池cachepool时，缓存池它本身也需要存储元数据，所以这里也需要为缓存池创建缓存池元数据LV。\n另外，我有两块SSD，我希望能最大化的提升IO，所以这两块SSD之间也需要组raid0。\n首先为最终要创建的LVM-thin存储创建名叫meta_thinpool的元数据LV，创建时它默认是数据LV大小的0.1%，我取约0.3%，创建11.5GiB的元数据LV（不能超过15.81GiB）。\n存储元数据的raid0组Stripe Size我就保持默认的64KiB吧（不添加\u0026ndash;stripesize即使用默认值）。\n1 lvcreate --type raid0 --name meta_thinpool --size 11.5G hybrid /dev/sdd1 /dev/sde1 输出\n1 2 Using default stripesize 64.00 KiB. Logical volume \u0026#34;meta_thinpool\u0026#34; created. 再为后面马上要创建的的缓存池LV创建名叫meta_cachepool的缓存池元数据LV，raid0组也使用默认的Stripe Size，大小就取528M（大约也是缓存池LV的0.3%）吧。\n1 lvcreate --type raid0 --name meta_cachepool --size 528M hybrid /dev/sdd1 /dev/sde1 有关元数据LV大小应该设置多大，可以查看官方建议：lvmthin.7.en#Size_of_pool_metadata_LV\n输出\n1 2 Using default stripesize 64.00 KiB. Logical volume \u0026#34;meta_cachepool\u0026#34; created. 创建缓存池数据LV 在SSD上已经创建好了两个metadata的LV，占了一点空间，为了最大化利用磁盘空间，先把两块SSD余下的空间全部分配给缓存池数据LV。不过如果后续进行lvconvert转换存储类型操作时，如未设置关闭自动创建备用池元数据LV（即命令中添加--poolmetadataspare n，在PVE的WEBUI中创建LVM-thin，系统也会默认创建备用池元数据LV），在进行转换操作时就需要额外的等同于hybrid/meta_thinpool大小（我这里就是11.5GiB）的空间。我打算让其自动创建备用池元数据LV，所以我需要预留11.5GiB（即2944个PE）。\n如果已经在LVM-thin创建了虚拟磁盘，没有任何剩余空间的话，后续再调整就不太好调整了，所以如果不太放心的话，你多保留一些空间不完全创建LV也是可以的。\n为了最大化的提升IO性能，缓存池也采用raid0。同样采用默认的Stripe Size。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 ## 先检查一下hybrid这个VG还剩下多少个PE vgdisplay hybrid ## 从输出可以看出还剩下54144个PE --- Volume group --- VG Name hybrid System ID Format lvm2 Metadata Areas 4 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 3 Open LV 0 Max PV 0 Cur PV 4 Act PV 4 VG Size \u0026lt;3.86 TiB PE Size 4.00 MiB Total PE 1010894 Alloc PE / Size 956750 / \u0026lt;3.65 TiB Free PE / Size 54144 / 211.50 GiB VG UUID 13c6EC-n2E4-nQvh-hD5J-q8F1-Hl73-77pkji ## 为后面的转换预留2944个PE即11.5GiB用作备用池元数据LV，其他的共51200个PE创建缓存池数据LV lvcreate --type raid0 --name cache --extents 51200 hybrid /dev/sdd1 /dev/sde1 ## 输出 Using default stripesize 64.00 KiB. Logical volume \u0026#34;cache\u0026#34; created. 转换存储类型 转换hybrid/cache这个LV的类型为缓存池cache-pool，设置chunksize为256KiB，指定缓存池元数据LV为之前已经在SSD上以raid0创建的hybrid/meta_cachepool： 1 lvconvert --type cache-pool --poolmetadata hybrid/meta_cachepool --chunksize 256 hybrid/cache 这一步操作中chunksize的值应该参考下方说明中lvmcache有关的说明进行设置。输出如下，这样，缓存池元数据LVhybrid/meta_cachepool和缓存池数据LVhybrid/cache就合并成新的缓存池LV了。\n1 2 3 4 WARNING: Converting hybrid/cache and hybrid/meta_cachepool to cache pool\u0026#39;s data and metadata volumes with metadata wiping. THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.) Do you really want to convert hybrid/cache and hybrid/meta_cachepool? [y/n]: y Converted hybrid/cache and hybrid/meta_cachepool to cache pool. 有关chunksize的说明\nThe size of chunks in a snapshot, cache pool or thin pool. For snapshots, the value must be a power of 2 between 4KiB and 512KiB and the default value is 4. For a cache pool the value must be between 32KiB and 1GiB and the default value is 64. For a thin pool the value must be between 64KiB and 1GiB and the default value starts with 64 and scales up to fit the pool metadata size within 128MiB, if the pool metadata size is not specified. The value must be a multiple of 64KiB. See lvmthin(7) and lvmcache(7) for more information. 机翻：快照、缓存池或精简池中的块大小。对于快照，该值必须是2的幂，介于4KB和512KB之间，默认值为4。对于缓存池，该值须介于32KiB和1GiB之间，并且默认值为64。对于精简池，该数值必须介于64KiB和1GiB之间，如果未指定池元数据大小，则默认值从64开始，并按比例放大以适应128MiB内的池元数据大小。该值必须是64KiB的倍数。有关更多信息，请参见lvmthin和lvmcache。\nlvmthin：\nWhen a thin pool is used primarily for the thin provisioning feature, a larger value is optimal. To optimize for many snapshots, a smaller value reduces copying time and consumes less space. 机翻：当精简池主要用于精简资源调配功能时，最好使用较大的值。要优化多个快照，较小的值可以减少复制时间并消耗更少的空间。\nlvmcache：\nUsing a chunk size that is too large can result in wasteful use of the cache, in which small reads and writes cause large sections of an LV to be stored in the cache. It can also require increasing migration threshold which defaults to 2048 sectors (1 MiB). Lvm2 ensures migration threshold is at least 8 chunks in size. This may in some cases result in very high bandwidth load of transfering data between the cache LV and its cache origin LV. However, choosing a chunk size that is too small can result in more overhead trying to manage the numerous chunks that become mapped into the cache. Overhead can include both excessive CPU time searching for chunks, and excessive memory tracking chunks. 机翻：使用过大的块大小可能会导致缓存的浪费使用，在这种情况下，较小的读取和写入会导致LV的较大部分存储在缓存中。它还可能需要增加迁移阈值，默认为2048个扇区（1个MiB）。Lvm2确保迁移阈值的大小至少为8个块。在某些情况下，这可能导致在高速缓存LV与其高速缓存源LV之间传输数据的非常高的带宽负载。然而，选择太小的块大小可能会导致管理映射到缓存中的大量块的更多开销。开销可能包括过多的CPU时间搜索块，以及过多的内存跟踪块。\n把之前在HDD上创建的hybrid/data这个LV的类型转换为带缓存池LV（hybrid/cache）的存储类型，指定缓存池为刚刚合并后的缓存池LVhybrid/cache，设置缓存模式为writeback： 1 lvconvert --type cache --cachepool hybrid/cache --cachemode writeback hybrid/data 输出如下，这样，数据LVhybrid/data就和缓存池LVhybrid/cache合并成新的带缓存池的LVM存储hybrid/data了，这个时候它还不是LVM-thin存储。\n1 2 3 Do you want wipe existing metadata of cache pool hybrid/cache? [y/n]: y WARNING: Data redundancy could be lost with writeback caching of raid logical volume! Logical volume hybrid/data is now cached. 缓存模式可选择如下，我都raid0了，已经无所畏惧了，所以我选择writeback，数据丢了就丢了吧：\nwriteback: writeback considers a write complete as soon as it is stored in the cache pool.\nwritethough: writethough considers a write complete only when it has been stored in both the cache pool and on the origin LV. While writethrough may be slower for writes, it is more resilient if something should happen to a device associated with the cache pool LV.\npassthrough: With passthrough, all reads are served from the origin LV (all reads miss the cache) and all writes are forwarded to the origin LV; additionally, write hits cause cache block invalidates. See lvmcache(7) for more information.\n再把刚刚合并的带缓存池的LVM存储hybrid/data与之前创建的元数据LVhybrid/meta_thinpool合并转换为最终需要的LVM-thin存储： 1 lvconvert --type thin-pool --poolmetadata hybrid/meta_thinpool hybrid/data 有关chunksize的具体说明见上方，这一步操作中chunksize的值应该参考上方说明中lvmthin有关的说明进行设置。如采用默认64KiB的chunksize，最大可支持15.81TiB的LVM-thin。我的输出如下：\n1 2 3 4 5 Thin pool volume with chunk size 64.00 KiB can address at most 15.81 TiB of data. WARNING: Converting hybrid/data and hybrid/meta_thinpool to thin pool\u0026#39;s data and metadata volumes with metadata wiping. THIS WILL DESTROY CONTENT OF LOGICAL VOLUME (filesystem etc.) Do you really want to convert hybrid/data and hybrid/meta_thinpool? [y/n]: y Converted hybrid/data and hybrid/meta_thinpool to thin pool. 检查 最后，我们来看看LV和物理磁盘的情况\n1 lvs -a -o lv_full_name,parent,lv_size,modules,devices 输出如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 LV Parent LSize Modules Devices hybrid/cache_cpool 200.00g cache,raid cache_cpool_cdata(0) hybrid/cache_cpool_cdata [cache_cpool] 200.00g raid cache_cpool_cdata_rimage_0(0),cache_cpool_cdata_rimage_1(0) hybrid/cache_cpool_cdata_rimage_0 [cache_cpool_cdata] 100.00g /dev/sdd1(1538) hybrid/cache_cpool_cdata_rimage_1 [cache_cpool_cdata] 100.00g /dev/sde1(1538) hybrid/cache_cpool_cmeta [cache_cpool] 528.00m raid cache_cpool_cmeta_rimage_0(0),cache_cpool_cmeta_rimage_1(0) hybrid/cache_cpool_cmeta_rimage_0 [cache_cpool_cmeta] 264.00m /dev/sdd1(0) hybrid/cache_cpool_cmeta_rimage_1 [cache_cpool_cmeta] 264.00m /dev/sde1(0) hybrid/data \u0026lt;3.64t cache,raid,thin-pool data_tdata(0) hybrid/data_tdata data \u0026lt;3.64t cache,raid data_tdata_corig(0) hybrid/data_tdata_corig \u0026lt;3.64t raid data_tdata_corig_rimage_0(0),data_tdata_corig_rimage_1(0) hybrid/data_tdata_corig_rimage_0 [data_tdata_corig] \u0026lt;1.82t /dev/sdb1(0) hybrid/data_tdata_corig_rimage_1 [data_tdata_corig] \u0026lt;1.82t /dev/sdc1(0) hybrid/data_tmeta data 11.50g raid data_tmeta_rimage_0(0),data_tmeta_rimage_1(0) hybrid/data_tmeta_rimage_0 [data_tmeta] 5.75g /dev/sdd1(66) hybrid/data_tmeta_rimage_1 [data_tmeta] 5.75g /dev/sde1(66) hybrid/lvol0_pmspare 11.50g /dev/sdd1(27138) hybrid/lvol0_pmspare 11.50g /dev/sde1(27138) pve/root \u0026lt;29.50g /dev/sda3(512) pve/swap 2.00g /dev/sda3(0) 从输出中的Layout和Devices字段可以看出，hybrid/data这个综合了raid0、缓存池和具有thin功能的LVM-thin，内部的各个下级LV：\n它的数据LVdata_tdata大小是3.64TiB，其实就是两块HDD大小之和（2T盘的实际大小是1.82TiB），它的原始（orig）数据LV是data_tdata_corig，而data_tdata_corig是由两块HDD的/dev/sdb1和/dev/sdc1分区组的raid0（data_tdata_corig_rimage_0和data_tdata_corig_rimage_1）；\n它所需要的元数据LV（即data_tmeta）大小是11.5GiB，也是raid0组，这个raid0组位于两块SSD上，即data_tmeta_rimage_0和data_tmeta_rimage_1；\n它有一个缓存池LVcache_cpool，而缓存池LVcache_cpool本身又分为数据和元数据两部分：\n缓存池数据LV是cache_cpool_cdata，总大小200GiB，是位于两块SSD上的cache_cpool_cdata_rimage_0和cache_cpool_cdata_rimage_1组成的raid0；\n缓存池元数据LV是cache_cpool_cmeta，总大小528MiB，也是由位于两块SSD上的cache_cpool_cmeta_rimage_0和cache_cpool_cmeta_rimage_1组成的raid0。\n转换存储类型还生成了lvol0_pmspare，这个是自动创建的备用池元数据LV，备用池元数据LV是在修复池时可以使用的保留空间。它的大小等同于最大的元数据LV大小（我创建的两个元数据LV中较大的是11.5GiB）。如想关闭自动创建这种类型的LV，需要在与元数据LV有关的两次转换命令lvconvert中添加--poolmetadataspare n。如果设置了不自动创建，那么前面的存储类型转换时也就不需要提前预留空间。虽然看起来有两个（因为我进行了两次与元数据有关的转换lvconvert），但实际上是在两块SSD上总共占用11.5GiB，每块SSD各5.75GiB。 每块SSD上的LV有：缓存池数据LV（cache_cpool_cdata）100GiB，缓存池元数据LV（cache_cpool_cmeta）264MiB，元数据LV（data_tmeta）5.75GiB，备用池元数据LV（lvol0_pmspare）5.75GiB。以上总计111.76GiB，这就是120G的SSD的真实大小。\n这样，将元数据LV、缓存池数据LV、缓存池元数据LV全部放在SSD上以提升IO性能，两块HDD组成数据LV以保存原始数据，那么HDD大小之和3.64TiB就是这个LVM-thin存储的最终大小。\n再以另外一个角度来看：\n1 lsblk 从输出也可以看到HDD上只有data，两个metadata和cache全部位于SSD：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 32G 0 disk ├─sda1 8:1 0 1007K 0 part ├─sda2 8:2 0 512M 0 part └─sda3 8:3 0 31.5G 0 part ├─pve-swap 253:0 0 2G 0 lvm [SWAP] └─pve-root 253:1 0 29.5G 0 lvm / sdb 8:16 0 1.8T 0 disk └─sdb1 8:17 0 1.8T 0 part └─hybrid-data_tdata_corig_rimage_0 253:11 0 1.8T 0 lvm └─hybrid-data_tdata_corig 253:13 0 3.6T 0 lvm └─hybrid-data_tdata 253:14 0 3.6T 0 lvm └─hybrid-data 253:15 0 3.6T 0 lvm sdc 8:32 0 1.8T 0 disk └─sdc1 8:33 0 1.8T 0 part └─hybrid-data_tdata_corig_rimage_1 253:12 0 1.8T 0 lvm └─hybrid-data_tdata_corig 253:13 0 3.6T 0 lvm └─hybrid-data_tdata 253:14 0 3.6T 0 lvm └─hybrid-data 253:15 0 3.6T 0 lvm sdd 8:48 0 111.8G 0 disk └─sdd1 8:49 0 111.8G 0 part ├─hybrid-data_tmeta_rimage_0 253:2 0 5.8G 0 lvm │ └─hybrid-data_tmeta 253:4 0 11.5G 0 lvm │ └─hybrid-data 253:15 0 3.6T 0 lvm ├─hybrid-cache_cpool_cdata_rimage_0 253:5 0 100G 0 lvm │ └─hybrid-cache_cpool_cdata 253:7 0 200G 0 lvm │ └─hybrid-data_tdata 253:14 0 3.6T 0 lvm │ └─hybrid-data 253:15 0 3.6T 0 lvm └─hybrid-cache_cpool_cmeta_rimage_0 253:8 0 264M 0 lvm └─hybrid-cache_cpool_cmeta 253:10 0 528M 0 lvm └─hybrid-data_tdata 253:14 0 3.6T 0 lvm └─hybrid-data 253:15 0 3.6T 0 lvm sde 8:64 0 111.8G 0 disk └─sde1 8:65 0 111.8G 0 part ├─hybrid-data_tmeta_rimage_1 253:3 0 5.8G 0 lvm │ └─hybrid-data_tmeta 253:4 0 11.5G 0 lvm │ └─hybrid-data 253:15 0 3.6T 0 lvm ├─hybrid-cache_cpool_cdata_rimage_1 253:6 0 100G 0 lvm │ └─hybrid-cache_cpool_cdata 253:7 0 200G 0 lvm │ └─hybrid-data_tdata 253:14 0 3.6T 0 lvm │ └─hybrid-data 253:15 0 3.6T 0 lvm └─hybrid-cache_cpool_cmeta_rimage_1 253:9 0 264M 0 lvm └─hybrid-cache_cpool_cmeta 253:10 0 528M 0 lvm └─hybrid-data_tdata 253:14 0 3.6T 0 lvm └─hybrid-data 253:15 0 3.6T 0 lvm 添加存储 把创建好的LVM-thin存储添加到PVE，就大功告成了：\n顺便再看看磁盘空间有没有100%利用完全：\n参考资料 lvm, pvcreate, vgcreate, lvcreate, lvconvert, lvreduce, lvremove, lvs, lvmraid, lvmthin, lvmcache\n在上述参考资料链接下方可以看见全部命令的帮助文档，同时也可以直接在PVE命令行中输入man \u0026lt;cmd\u0026gt;来查阅上述文档。\n","date":"2022-09-01T00:00:00+08:00","image":"https://evine.win/p/pve-create-lvm-thin-with-cachepool/pic3_hu4277152815947986840.png","permalink":"https://evine.win/p/pve-create-lvm-thin-with-cachepool/","title":"PVE基于raid0创建LVM-thin并添加固态磁盘作为缓存池"},{"content":" 本文为《PVE安装Kodi》系列文章的一部分。\nPVE 直接安装最新版 Kodi 为Kodi适配遥控器 修改Kodi字幕字体 修改Kodi皮肤字体 屏蔽Kodi的关机、重启按钮 设置Kodi启动的前置条件 像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停 kodi-send使用相关说明 转换遥控器的退出键为返回键 如果在PVE系统中安装Kodi，并且是以root用户启动Kodi（如果是非root用户，那么可以无视本篇文章），那么Kodi具有很高的权限，可以关机、重启主机等等，这就需要防止不小心用遥控器或者键盘把PVE系统给关闭了。修改之处主要分为两部分：\n1. 屏蔽键盘的s键、屏蔽遥控器的电源键 注意，下面的方法只是屏蔽掉键盘的s键（可以呼出关机菜单），以及遥控器的电源键的功能，但实际上Kodi还有具有关闭主机的权限的，通过Yatse、Kore等手机软件直接呼出关机菜单仍然可以实现关机或重启。\n注意，下面的方法只是屏蔽掉键盘的s键（可以呼出关机菜单），以及遥控器的电源键的功能，但实际上Kodi还有具有关闭主机的权限的，通过Yatse、Kore等手机软件直接呼出关机菜单仍然可以实现关机或重启。\n注意，下面的方法只是屏蔽掉键盘的s键（可以呼出关机菜单），以及遥控器的电源键的功能，但实际上Kodi还有具有关闭主机的权限的，通过Yatse、Kore等手机软件直接呼出关机菜单仍然可以实现关机或重启。\nkeymaps的WIKI见：https://kodi.wiki/view/Keymap ，keymaps默认文件位于：/usr/share/kodi/system/keymaps，这里的文件可以被你自己的配置覆盖掉对应按键的作用。新建~/.kodi/userdata/keymaps/disable_keyboard_shutdown.xml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;keymap\u0026gt; \u0026lt;global\u0026gt; \u0026lt;keyboard\u0026gt; \u0026lt;s\u0026gt;\u0026lt;/s\u0026gt; \u0026lt;power\u0026gt;\u0026lt;/power\u0026gt; \u0026lt;sleep\u0026gt;\u0026lt;/sleep\u0026gt; \u0026lt;/keyboard\u0026gt; \u0026lt;/global\u0026gt; \u0026lt;LoginScreen\u0026gt; \u0026lt;keyboard\u0026gt; \u0026lt;end mod=\u0026#34;ctrl\u0026#34;\u0026gt;\u0026lt;/end\u0026gt; \u0026lt;/keyboard\u0026gt; \u0026lt;/LoginScreen\u0026gt; \u0026lt;Home\u0026gt; \u0026lt;keyboard\u0026gt; \u0026lt;end mod=\u0026#34;ctrl\u0026#34;\u0026gt;\u0026lt;/end\u0026gt; \u0026lt;backspace mod=\u0026#34;longpress\u0026#34;\u0026gt;\u0026lt;/backspace\u0026gt; \u0026lt;/keyboard\u0026gt; \u0026lt;/Home\u0026gt; \u0026lt;/keymap\u0026gt; 2. 在Kodi界面中隐藏关机、重启等按钮 最后，为了保证在Kodi界面中也只能看见退出，并且看不到关机、重启等按钮（注意：这只是在界面中隐藏掉而已，Kodi本身还是有关机、重启的权限的），可以在皮肤设置中将相关按钮隐藏掉，比如使用的Aeon Nox: SiLVO皮肤的话，可以在进入系统设置 -\u0026gt; 皮肤设置 -\u0026gt; 主菜单设置后这样操作：\n在上图中的“管理子菜单”按钮下，以及在主菜单“系统”的“管理子菜单”下，也要将“关闭系统电源”“重启”“待机”“休眠”“注销”给禁用了，这里本文就不截图了。\n最后的效果，主菜单中也只有退出按钮了。\n","date":"2022-07-23T00:00:00+08:00","image":"https://evine.win/p/kodi-disable-shutdown/pic5_hu11881754292387580250.png","permalink":"https://evine.win/p/kodi-disable-shutdown/","title":"屏蔽Kodi的关机、重启按钮"},{"content":" 本文为《PVE安装Kodi》系列文章的一部分。\nPVE 直接安装最新版 Kodi 为Kodi适配遥控器 修改Kodi字幕字体 修改Kodi皮肤字体 屏蔽Kodi的关机、重启按钮 设置Kodi启动的前置条件 像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停 kodi-send使用相关说明 转换遥控器的退出键为返回键 操作流程 将ttf字体文件放在下面列出的对应的皮肤目录下的fonts子文件夹中：\n~/.kodi/addons/skin.XXXX（用户自己安装的皮肤） /usr/share/kodi/addons/skin.XXXX（系统自带的皮肤） 并在皮肤的配置子目录（不同皮肤的配置子目录不一样，比如skin.estuary在xml子目录下，skin.aeon.nox.silvo在16x9或其他比例的目录下）中找到Font.xml，复制一组完整的fontset（从\u0026lt;fontset\u0026gt;到\u0026lt;/fontset\u0026gt;），然后将新增加的这组fontset的字体文件名改成你放进去的字体文件名，并保存即可（自行做好原始文件备份）。\n1 2 3 4 5 6 7 8 9 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;fonts\u0026gt; \u0026lt;fontset id=\u0026#34;Default\u0026#34; idloc=\u0026#34;31390\u0026#34;\u0026gt; ...原有的fontset，应该有多组... \u0026lt;/fontset\u0026gt; \u0026lt;fontset id=\u0026#34;FZZYJT\u0026#34;\u0026gt; ...新增加的fontset... \u0026lt;/fontset\u0026gt; \u0026lt;/fonts\u0026gt; 编辑保存好后重启Kodi即可在皮肤设置中选择新增加的字体。 注：每次更新Kodi后需要再次设置。\n","date":"2022-07-23T00:00:00+08:00","image":"https://evine.win/p/kodi-change-interface-font/kodi-poster_hu6896014991795686649.jpg","permalink":"https://evine.win/p/kodi-change-interface-font/","title":"修改Kodi皮肤字体"},{"content":" 本文为《PVE安装Kodi》系列文章的一部分。\nPVE 直接安装最新版 Kodi 为Kodi适配遥控器 修改Kodi字幕字体 修改Kodi皮肤字体 屏蔽Kodi的关机、重启按钮 设置Kodi启动的前置条件 像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停 kodi-send使用相关说明 转换遥控器的退出键为返回键 如需要修改字幕字体，将你的ttf字体文件放在~/.kodi/media/Fonts之下（如果是非root用户，注意修改字体文件所有者），然后在Kodi设置中 播放器 -\u0026gt; 语言 -\u0026gt; 文本字幕字体 中选择即可，注意该字体仅对文本类字幕有效，即ass/ssa/srt后缀，其他字幕格式是无效的。\n","date":"2022-07-18T00:00:00+08:00","image":"https://evine.win/p/kodi-change-subtitle-font/kodi-poster_hu6896014991795686649.jpg","permalink":"https://evine.win/p/kodi-change-subtitle-font/","title":"修改Kodi字幕字体"},{"content":" 本文为《PVE安装Kodi》系列文章的一部分。\nPVE 直接安装最新版 Kodi 为Kodi适配遥控器 修改Kodi字幕字体 修改Kodi皮肤字体 屏蔽Kodi的关机、重启按钮 设置Kodi启动的前置条件 像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停 kodi-send使用相关说明 转换遥控器的退出键为返回键 前言 虽然安装好Kodi后，可以在手机上使用Yatse、Kore等软件来遥控Kodi（当然这需要在Kodi设置中启用“允许通过 HTTP 远程控制”），但家人、朋友怎么办，难道为每个人都装一下？所以还是需要有一个实体遥控器来控制Kodi。\n注意事项 如果没有打开Kodi，遥控器的电源键按下会关闭PVE系统，推荐适配遥控器之后按照《像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停》一文进行按键劫持，并可以实现遥控器来启动/关闭Kodi。\n适配遥控器 当然主要有两种方式（另外还有红外遥控器，这个不好用，就不写了），一是2.4G无线遥控器，一是蓝牙遥控器，经过本人踩坑，我更推荐2.4G无线遥控器（2023年8月补充说明：Linux内核支持关闭USB设备进入suspend状态的功能，也可以实现蓝牙遥控器永不断连）。总得说来，二者都可以非常舒服地使用，对比如下：\n蓝牙遥控器即使设置好了永远保持连接，但毕竟需要蓝牙适配器和蓝牙遥控器两个配合，事实上在我的环境中5分钟左右遥控器没有动作二者就失联了，总是需要多按几次遥控器才会有反应。2.4G无线遥控器自带接收器，不存在断连问题。\n2.4G无线飞鼠遥控器点出鼠标。\n2.4G飞鼠遥控器成本25块左右，而蓝牙适配器加蓝牙遥控器加起来要50块左右，前者更划算一点。\n蓝牙可以连接多个设备，而2.4G无线遥控器和接收器就只能一对一。\n蓝牙设备可以设置永不断连，但似乎不能劫持电源键，2.4G无线遥控器可以正常劫持。\n无线遥控器 谈不上适配，如果是直接在PVE中安装Kodi，插上USB接收器就能用了。如果是直通显卡和声卡给 LibreELEC/CoreELEC 虚拟机的话，就设置下USB接口直通。其他方式安装的Kodi/LibreELEC/CoreELEC，只要该系统能访问USB接口，就可以用这种方式。\n购买关键词：遥控器 2.4G 飞鼠 空中鼠标 空中键鼠 Air Mouse 键鼠，注意要自带接收器的。\n蓝牙遥控器 注：我购买的是胜为蓝牙适配器5.0和小米蓝牙语音遥控器这两样东西。但我现在不推荐用这种方式，除非你需要连接多个蓝牙设备才考虑。（2023年8月补充说明：Linux内核支持关闭USB设备进入suspend状态的功能，也可以实现蓝牙遥控器永不断连。）\n以下为蓝牙遥控器适配流程：\n以下相关命令均为root用户执行的。 如果需要新建文件，请直接在Linux环境中使用nano XXXX创建，请不要在Windows环境中创建后再上传。\n在USB接口上插入蓝牙适配器，可以在PVE打开的情况下插入。插入后可以命令检测一下：\n1 2 lsusb | grep bluetooth -i Bus 003 Device 003: ID 0a12:0001 Cambridge Silicon Radio, Ltd Bluetooth Dongle (HCI mode) 安装蓝牙管理器：\n1 apt install -y bluetooth 适配遥控器，请自行将以下的mac地址更改你的设备的mac地址：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 ## 进入蓝牙管理器 $ bluetoothctl [NEW] Controller 00:10:20:30:40:50 hostname [default] ## 设置agent [bluetooth]# default-agent Default agent request successful ## 开启蓝牙适配器 [bluetooth]# power on Changing power on succeeded [CHG] Controller 00:10:20:30:40:50 Powered: yes ## 使蓝牙遥控器进入待配对状态，比如我购买的小米蓝牙语音遥控器是同时按住遥控器上的主页键和菜单键不放，其他遥控器根据其说明操作 ## 然后再让蓝牙适配器开始扫描，要配对好后再松开遥控器 [bluetooth]# scan on Discovery started [CHG] Controller 00:10:20:30:40:50 Discovering: yes [NEW] Device 00:12:34:56:78:90 device name [CHG] Device 00:12:34:56:78:90 LegacyPairing: yes ## 扫描到你的蓝牙遥控器后，开始配对，配对完成就可以松开遥控器了 [bluetooth]# pair 00:12:34:56:78:90 Attempting to pair with 00:12:34:56:78:90 [CHG] Device 00:12:34:56:78:90 Connected: yes [CHG] Device 00:12:34:56:78:90 Paired: yes Pairing successful ## 配对并连接成功后提示符会变成这样 [小米蓝牙语音遥控器]# ## 可以信任该遥控器 [小米蓝牙语音遥控器]# trust 00:12:34:56:78:90 # 如想了解更多信息，请自行查看帮助 [小米蓝牙语音遥控器]# help ## 退出蓝牙管理器 [小米蓝牙语音遥控器]# exit ~~让遥控器一直保持连接不断开，修改/etc/bluetooth/main.conf，找到对应的行取消注释并修改为以下内容：~~让遥控器不断连，实际上是不让USB设备进入suspend状态（遥控器并没有真正的断开蓝牙适配器），首先修改/etc/bluetooth/input.conf，设置IdleTimeout为0：\n1 2 [General] IdleTimeout=0 然后根据内核帮助文档 Power Management for USB，修改Linux启动参数。\n方式一，重启后生效。修改内核启动参数，如果是传统方式安装的PVE/Linux，修改/etc/default/grub的GRUB_CMDLINE_LINUX_DEFAULT行，如果是ZFS安装的PVE/Linux，修改/etc/kernel/cmdline的root行，增加一个参数usbcore.autosuspend=-1，然后运行下列命令更新内核： 1 update-grub \u0026amp;\u0026amp; update-initramfs -u -k all 方式二，重启后生效。新建/etc/modprobe.d/disable_usbcore_autosuspend.conf，内容如下： 1 options usbcore autosuspend=-1 方式三，仅本次启动有效，并且需要在运行下面命令之后插入的设备才会生效。 1 echo -1 \u0026gt;/sys/module/usbcore/parameters/autosuspend 上述修改是禁用所有USB设备自动挂起（毕竟是服务器，不需要挂起），但如果你确实需要针对某些设备保留自动挂起，而只针对遥控器禁用自动挂起，请参考 USB自动挂起 进行针对性的设置。\n在这里也简单的提一下 LibreELEC/CoreELEC 如何适配蓝牙遥控器，安装好适配器后，进入LibreELEC/CoreELEC系统设置菜单的蓝牙子菜单后，根据遥控器说明书使遥控器进入待配对状态，然后在LibreELEC/CoreELEC中开始扫描，扫描到后点击配对即可。\n红外遥控器 不好用，教程就不写了。\n再次提醒 如果没有打开Kodi，遥控器的电源键按下会关闭PVE系统，推荐适配遥控器之后按照《像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停》一文进行按键劫持，并可以实现遥控器来启动/关闭Kodi。\n","date":"2022-07-13T00:00:00+08:00","image":"https://evine.win/p/kodi-use-remote-controller/kodi-poster_hu6896014991795686649.jpg","permalink":"https://evine.win/p/kodi-use-remote-controller/","title":"为Kodi适配遥控器"},{"content":" 本文为原创教程，转载请注明来源及作者。 更新于2023年8月4日，以当前最新的PVE 8为示例。\n按照本教程，可以保持PVE全部套件稳定的同时，又能够使用最新版Kodi； 没有安装任何桌面系统或其他什么软件包，对PVE环境的影响可以忽略不计； 不用直通显卡，退出Kodi就是PVE的控制台，在出现故障时排故更容易，要是把显卡给直通给虚拟机了，PVE控制台上啥也看不到，如果这时ssh还出问题了的话，你根本就无法排故； 少了虚拟机这一层，减少了资源损耗，Kodi在PVE中运行初始只需要200M左右内存； 音频可以在Kodi中设置通过HDMI直通，支持7.1声道无压力，而如果采用直通核显及声卡给LibreELEC虚拟机的话，在LibreELEC中音频可能就无法通过HDMI直通，只能委屈巴巴的用2.0声道； 另外，如果使用蓝牙遥控器的话，反应速度比在虚拟机中直通蓝牙适配器要快，体验要好很多。 安装最新版Kodi 注：本文是以GBM模式安装的Kodi，这种模式目前也已支持HDR。\n不需要如同网上其他教程一般，安装xinit、xfce、lightdm、gnome等等一系列桌面系统才需要的软件包，直接安装Kodi就好了。尽量不装无关的包，这对PVE系统比较重要。\n并且网上的教程全是安装Debian官方仓库自带的Kodi，但因为Debian的特色，官方稳定仓库中的Kodi版本比较老。所以有的博主自作主张启用了Debian的sid不稳定仓库，以便使用新版Kodi，这对PVE环境来说是不可取的，不建议这么做。\n事实上在Debian稳定版本上也是可以安装最新版的Kodi的，主要来自一个专门负责维护多媒体软件的仓库：https://www.deb-multimedia.org，国内连接较差，不用担心，有一堆镜像站可以使用。以下基于PVE 8.x（Debian bookworm）并以北外镜像站为例（其他版本请修改bookworm为对应的版本号）：\n1 2 3 4 5 6 7 8 9 10 11 12 # 信任keyring cd ~ wget https://mirrors.bfsu.edu.cn/debian-multimedia/pool/main/d/deb-multimedia-keyring/deb-multimedia-keyring_2016.8.1_all.deb dpkg -i deb-multimedia-keyring_2016.8.1_all.deb # 添加仓库 echo \u0026#34;deb https://mirrors.bfsu.edu.cn/debian-multimedia bookworm main non-free\u0026#34; \u0026gt; /etc/apt/sources.list.d/multimedia.list echo \u0026#34;deb https://mirrors.bfsu.edu.cn/debian-multimedia bookworm-backports main\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list.d/multimedia.list # 安装最新稳定版Kodi apt update apt install -y va-driver-all pipewire-audio kodi # va-driver-all是硬解需要的，Kodi 20还需要额外安装pipewire，Kodi 19及以下版本应该不需要 注：各PVE对应的Debian版本号如下：\nPVE 5 -\u0026gt; Debian 9 -\u0026gt; stretch PVE 6 -\u0026gt; Debian 10 -\u0026gt; buster PVE 7 -\u0026gt; Debian 11 -\u0026gt; bullseye PVE 8 -\u0026gt; Debian 12 -\u0026gt; bookworm PVE 9 -\u0026gt; Debian 13 -\u0026gt; trixie（未来的版本号） 有的时候，在当前debian的版本中，deb-multimedia会将大版本升级后的Kodi放在backports源中，如果你发现你安装的Kodi不是当前最新版（见 官方，可以先查询一下看看是不是在backports源中，再来指定backports源安装。\n因为PVE 8可以直接安装到Kodi 20，所以以下内容以PVE 7从backports源安装最新版本为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 查看所有版本 apt update apt policy kodi # 输出 kodi: Installed: 5:19.5-dmo0+deb11u2 Candidate: 5:19.5-dmo0+deb11u2 Version table: 5:20.2-dmo~bpo11+1 100 100 https://mirrors.bfsu.edu.cn/debian-multimedia bullseye-backports/main amd64 Packages *** 5:19.5-dmo0+deb11u2 500 500 https://mirrors.bfsu.edu.cn/debian-multimedia bullseye/main amd64 Packages 100 /var/lib/dpkg/status 5:18.9-dmo0+deb10u1 500 500 https://mirrors.bfsu.edu.cn/debian-multimedia bullseye/main amd64 Packages 2:19.1+dfsg2-2+deb11u1 500 500 https://mirrors.bfsu.edu.cn/debian bullseye/main amd64 Packages # 上面的输出内容显示最新的版本位于bullseye-backports中，所以这时要安装最新版本需要指定backports源，如下 apt install -t bullseye-backports -y kodi 国内其他镜像站如清华TUNA、中科大USTC、腾讯云、国家互联网络信息中心、北交、南大等站点都是有deb-multimedia仓库的，改成你下载最快的镜像站点即可。\n设置开机启动 新建/etc/systemd/system/kodi.service，内容如下（请直接在Linux环境中创建，不要在Windows环境中创建）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Unit] Description = Kodi Media Center After = network-online.target polkit.service evsieve.service remote-fs.target systemd-user-sessions.service nss-lookup.target sound.target bluetooth.target upower.service mysqld.service lircd.service Wants = network-online.target polkit.service evsieve.service [Service] User = root Group = root ExecStart = /usr/bin/kodi ExecStop = /usr/bin/killall --user root --exact --wait kodi.bin TimeoutStartSec = infinity Restart = on-abort [Install] WantedBy = multi-user.target 注：ExecStop这一行，相比使用killall，更推荐使用kodi-send，详见：kodi-send使用相关说明。\n上面内容中是以root用户启动Kodi的，然后启用开机自动启动即可（无需重启PVE系统，如不启用则需要开机后手动启动），Kodi将在PVE通过HDMI/DP接口连接的显示器/电视机上显示出来：\n1 systemctl enable --now kodi.service 从系统信息中可以看到内核、分辨率、GPU、OPENGL、视窗系统等信息，可以看到视窗系统直接使用GBM，而非X11（下图是在PVE 8上安装的Kodi 20.2的截图，已经明确支持HDR了）：\n如何以非root用户运行Kodi 如果以root用户启动Kodi，那么Kodi具有很高的权限，可以关机、重启主机等等，而如果不赋予普通用户这些权限的话，普通用户就不能进行这些关机、重启系统的操作，所以以非root用户启动Kodi还是有必要的。\n下文均以用户名evine举例。你可以直接建立一个kodi专用账户，用户名可以就叫kodi。\n如果还没有这个用户的话就添加用户，注意家目录不能少\n1 2 3 4 5 # 常规用户evine useradd -m -d /home/evine -U -s /usr/bin/bash evine # 如果想建立的是kodi专用账户，也可以放在/var，并禁止登陆 useradd -m -d /var/lib/kodi -U -s /usr/sbin/nologin kodi 为普通用户设置密码，\n1 passwd evine # 替换为你自己创建的用户名，如果设置的shell是/usr/sbin/nologin可以忽略这一步 为用户添加video render audio和input的组权限\n注：如果还需要使用其他类型的设备，则进一步添加其对应的组权限，详见：HOW-TO:Install Kodi for Linux。\n1 usermod -a -G video,render,audio,input evine # 替换为你自己创建的用户名 有关用户组，可以参见：https://wiki.debian.org/SystemGroups ，解释一下添加的各用户组的用途：\nvideo：允许该普通用户使用显示器； render：允许该普通用户使用显卡硬解； audio：允许该普通用户使用音频设备； input：允许该普通用户使用输入设备，如键盘、鼠标、2.4G无线遥控器等。 如果已经设置了root用户的开机自动启动，需要先禁用它\n1 systemctl disable --now kodi.service 新建或修改/etc/systemd/system/kodi.service，内容如下（请直接在Linux环境中创建，不要在Windows环境中创建）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Unit] Description = Kodi Media Center After = network-online.target polkit.service evsieve.service remote-fs.target systemd-user- sessions.service nss-lookup.target sound.target bluetooth.target upower.service mysqld.service lircd.service Wants = network-online.target polkit.service evsieve.service [Service] User = evine # 依据你自己建立的账户修改 Group = evine # 依据你自己建立的账户修改 ExecStart = /usr/bin/kodi ExecStop = /usr/bin/killall --user evine --exact --wait kodi.bin # 依据你自己建立的账户修改 TimeoutStartSec = infinity Restart = on-abort [Install] WantedBy = multi-user.target 注：ExecStop这一行，相比使用killall，更推荐使用kodi-send，详见：kodi-send使用相关说明。\n启用开机自动启动（如不启用则需要开机后手动启动）\n1 systemctl enable --now kodi.service 注：如Kodi使用smb共享来访问媒体资源，或者是其他服务，可以在启动Koid前判断启动条件是否具备，详见本文最上方的相关教程。\n相关命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 启动Kodi systemctl start kodi.service # 重启Kodi systemctl restart kodi.service # 关闭Kodi，可以直接在Kodi界面中点击退出按钮，也可命令行关闭，关闭后就是PVE的控制台 systemctl stop kodi.service # 查看Kodi的运行状态 systemctl status kodi.service # 禁用Kodi开机自动启动 systemctl disable kodi.service # 未来升级Kodi，就直接运行apt命令就好了，简单方便 apt update \u0026amp;\u0026amp; apt upgrade 关于音频直通 如果你的HDMI/DP接收方支持直接解码某些音频，那么可以在Kodi系统设置系统 -\u0026gt; 音频中，勾选“允许直通输出”后，并在其下方继续勾选你的HDMI/DP接收方支持的音频格式（如果某个格式勾选后该格式的视频播放没有声音，那么就是你的接收方不支持直接解码该音频格式，就不要勾选该格式）。\n音频直通最高可以支持7.1全景声，而如果你用Kodi解码后再传递给HDMI/DP，有可能只能支持2.0或2.1声道（对，管你几声道通通转成二声道），这大大降低了视听感受。直通显卡和声卡给虚拟机LibreELEC的，我不确定是否可以实现音频直通，这至少在我的环境中无法实现。\n通过HDMI/DP直通的音频，在播放时无法在Kodi中控制音量，只能通过接收方控制。而某些不支持直通的音频，则是通过Kodi解码的，既可以通过Kodi控制音量，也可以通过接收方控制音量。\n通过HDMI/DP直通的音频，在解码信息（按键盘的o键，如想在遥控器上按出来，需要在Kodi中安装Keymap Editor插件来将某个按钮映射为此功能）上所有音频频道将显示RAW，而未直通的音频将显示正常的轨道信息。如下面图片所示：\n关于硬解 如果你是按照上述方式安装的Kodi，那么它将自动检测可以硬解的视频编码并自动设置好，如果你想要了解你的核显到底可以硬解什么编码，可以这样：\n1 2 3 4 5 ## 安装 apt install -y vainfo ## 检测 vainfo 成功硬解的视频，在解码信息上的硬件解码将显示活动，并且解码器使用的是vaapi系列解码器，如下面图片所示：\n《PVE安装Kodi》系列文章 如果你需要为Kodi配置摇控器，并让遥控器可以控制Kodi启动和停止，那么请参考下列教程。\nPVE 直接安装最新版 Kodi 为Kodi适配遥控器 修改Kodi字幕字体 修改Kodi皮肤字体 屏蔽Kodi的关机、重启按钮 设置Kodi启动的前置条件 像使用盒子／LibreELEC一样使用PVE直装的Kodi，实现遥控器启停 kodi-send使用相关说明 转换遥控器的退出键为返回键 总结 按上述流程，只主动安装了很少的软件包，根据dpkg-query -L kodi的输出可知，除去Kodi的可执行程序外，Kodi安装的文件主要集中在这几个文件夹：\n1 2 3 4 5 6 /usr/lib/x86_64-linux-gnu/kodi /usr/share/applications/ /usr/share/doc/kodi /usr/share/man/man1/ /usr/share/metainfo/ /usr/share/xsessions 同时，Kodi的配置文件主要存放在两个地方：\n1 2 /usr/share/kodi # 系统级配置 ~/.kodi # 用户级配置 这些文件对系统都谈不上有什么污染，对PVE套件本身一点影响都没有，整体上对PVE环境的影响是完全可控的。\n在最后，提醒一下，如果是以root用户启动的，千万要注意在Kodi中将关机、重启等影响PVE主机的命令都按照上面的教程屏蔽掉，要不然你懂的\u0026hellip;\n","date":"2022-07-12T00:00:00+08:00","image":"https://evine.win/p/kodi-install-in-pve/pic5_hu16723540888118778644.png","permalink":"https://evine.win/p/kodi-install-in-pve/","title":"PVE 直接安装最新版 Kodi"},{"content":" 本教程为原创教程，转载需注明来源及作者。\n关键词 爱快 IKUAI 防火墙 ACL 封禁 恶意IP 限制 来源IP 访问IP SSH WEBUI 远程控制 RDP Fail2BAN\n背景 我们转发了端口到公网的人都会面临一个难题，比如转发Windows的远程控制RDP，比如NAS的SSH服务或者其他WEBUI服务，老是有许多恶意IP来探测并尝试爆破。诚然，比如群晖会自带防火墙，Linux也可以使用fail2ban或者其他防火墙来实现自动封禁恶意IP，这些都是有效的手段。\n之前，我使用fail2ban来实现自动封禁恶意IP，后来发现每天都会在几十个IP被封禁，一段时间以后，当fail2ban的封禁数量上千后，由于机器性能差，fail2ban竟然占用了好多资源。后来换爱快按下载流程设置后，fail2ban清静了好多，机器性能也恢复了。而像把Windows的远程桌面端口转发出去，无论你是不是用的3389端口，可能每天都会有IP进行几万次爆破尝试。\n不过这里想要说明的是，以爱快作为主路由时一个更好的保护方式，就是充分利用爱快的IP分组，结合端口转发功能或ACL功能来实现。当然，这只是保护措施的一种，最重要的，不要使用弱密码，不要使用默认密码，SSH使用私钥而非密码等等。\n流程 下载（或者点击文件右上角的Copy raw content按钮复制下来保存为csv文件） 这个 文件（不定期更新），在爱快设置中 网络设置 -\u0026gt; 终端分组设置 -\u0026gt; IP分组处导入。\n限制访问来源\n方式1：使用安全设置 -\u0026gt; ACL规则（需要先设置好端口转发，使用ACL时，端口转发可以不限制任何来源），参考下面的方式，允许你所在地区的对应的运营商的IP转发到你所使用的端口（目的地址可以不填，如果要填可以填端口转发对应的目标设备IP，也可以填整个本地网络，如10.0.0.0/8、172.16.0.0/16或192.168.0.0/24，连接方向匹配为原始方向），而阻断其他所有IP访问对应的端口。\n方式2：某些旧版本爱快的ACL功能可能是失效的（你可以自行测试，比如阻断你所在省份后手机使用蜂窝网访问），这时只能在网络设置 -\u0026gt; 端口映射 -\u0026gt; 端口映射处，给每一条需要限制访问来源IP的条目选择对应的IP分组。\n说明 ACL功能失效的时候，使用端口映射功能来限制时，每一条需要限制访问来源的条目需要分别设置，所以需要限制的端口和不需要限制的端口需要分成两条； 需要限制访问来源的服务一般是WEBUI、RDP、SSH等（基本上都是tcp协议），像BT/PT软件（uTorrent, qBittorrent, transmission, deluge等等）等P2P的监听端口（tcp+udp协议）就不要限制访问来源IP； 爱快路由器自己的WEBUI端口不要限制，要不然万一你IP不在允许范围内，改都都不了； 建议允许访问的来源IP都选上未知的IP分组，尤其是中国移动，除了选择你所在省份，一定要选上未知移动。 IPv6 IPv6的ACL设置请在 这里 查看。\n","date":"2022-07-08T00:00:00+08:00","image":"https://evine.win/p/ikuai-set-ipv4-acl/pic1_hu11627214357832434103.png","permalink":"https://evine.win/p/ikuai-set-ipv4-acl/","title":"使用爱快来限制SSH／WEBUI／RDP的访问来源IP，保护内网设备不被攻击"},{"content":"以下内容以4.3.7为例。\n可用的UI主题清单：List-of-known-qBittorrent-themes\n本人制作的docker镜像：nevinee/qbittorrent\n可实现下载完成通知、宕机通知、tracker出错超出阈值通知、自动分类、tracker出错打标签、批量修改tracker、检测指定文件夹下未在qbittorrent客户端中做种的文件夹/文件、配合IYUUAutoReseed实现自动重新校验和自动恢复做种、指定设备上线时自动限速、多时段限速、导出做种文件清单、导出未做种文件清单等等等等，教程见这里\n匿名模式说明：Anonymous-Mode\nRSS正则表达式教程：https://www.jianshu.com/p/54e6137ea4e3\n可用的备用WebUI清单见：List-of-known-alternate-WebUIs\n","date":"2021-08-07T00:00:00+08:00","image":"https://evine.win/p/qbittorrent-settings/1%E8%A1%8C%E4%B8%BA_hu116757385035092624.png","permalink":"https://evine.win/p/qbittorrent-settings/","title":"qBittorrent 设置教程"}]